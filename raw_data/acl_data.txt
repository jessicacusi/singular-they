Number of hit	Text ID	Concordance line
1	2020_evalnlgeval_1_1	"Agency ( MeteoGalicia 4 ) . Of the three situations presented in each question , there were two in which the descriptive text had been created by the same subject and a third in which the creator was a different subject . The judge had to select the text that/IN <<< he/she >>> believed to be created by a different subject from the one who had written the other two . NLG triangle test with expert judges The panel of expert judges was made up of four members of the Non-Linear Physics Group of the University of Santiago de Compostela 6 . The"
2	2020_smm4h_1_10	"as a ternary classification task . The model is required to determine whether the user has a child and indicate that/IN the child has the birth defect mentioned in a tweet , and predict a label L , where L ∈ { refer to the users child and indicate that/IN <<< he/she >>> has the birth defect mentioned in the tweet -1 , ambiguous about whether someone is the users child and/or has the birth defect mentioned in the tweet -2 , merely mention birth defects -3 } . Sub-task Sentence Gold Label Sub-task 1 @username you can try vitamins for Olivia !"
3	2020_lrec_1_32	". The volunteer are required to review each Question : Answer pair and confirm the correctness of the answers by refering to the text provided . Volunteer ' s decision is shown in the rightmost column in the figure . As the volunteer is provided with text to refer , <<< he/she >>> is not required to have any prior background knowledge about the temple . By using the volunteer inputs as feedback , the classifiers learn to better extract answers of these nine questions from templerelated-text . Curated Corpus : We generated a corpus of 4933 facts on temples from the web"
4	W18_1304	"quantify over individuals . The Contextual Graph The contextual graph provides the existential commitments of the sentence . It introduces a top con- text ( or possible world ) which represents whatever the author of the sentence takes the described world to be like ; in other words , whatever <<< he/she >>> commits to be the "" "" true "" "" world . Below the top context additional contexts are introduced , corresponding to any alternative worlds introduced in the sentence . Each of these embedded contexts makes commitments about its own state of affairs , principally by claiming , through the"
5	2021_sdp_1_11	"It has become common practice for researchers to use slides as a visual aid in presenting research findings and innovations . Such slides usually contain bullet points that/IN the researchers believe to be important to show . These bullet points serve both as a reminder to the speaker ( when <<< he/she >>> is presenting ) and summaries for audiences to understand . Manually creating a set of high-quality slides from an academic paper is time-consuming . We propose a method that automatically selects salient sentences that could be included into the slides , with the purpose of reducing the time and effort"
6	W14_5119	"verbs Figure 5 shows the test in small phrase-level . This section which is an evaluation to test the memory of the learner on how much he/she remembers the experiment 1 and 2 . A set of 10 combinations of verbs and nouns are displayed for the learner , where <<< he/she >>> is required to listen to the four options of the audio and select the right audio combination of noun and verb . Retention after 2 days : This process was conducted again after 2 days to check the error in retention . Figure5 : Demonstration of testing phase of phrase-like"
7	2020_wnut_1_69	"the majority of its users wellinformed amidst a natural disaster or a pandemic like COVID-19 . One major advantage of sourcing information via social media is that/IN all information is updated in real-time . Any person with a social media account can post or share information instantly at the moment <<< he/she >>> witness a noteworthy event . This is a much faster way to obtain information compared to reading newspaper , watching the news on TV , or viewing other official source * Equal contribution with the first author of information since most tend to be updated only at mid-day or at"
8	W00_1012	"ongoing dialogue . The tactic of enticement consists in increasing B ' s wish to do D ; the tactic of persuasion consists in increasing B ' s belief of the usefulness of D for him/her , and the tactic of threatening consists in increasing B ' s understanding that/IN <<< he/she >>> must do D. Communicative tactics are directly related to the reasoning process of the partner . IrA is applying the tactics of enticement he/she should be able to imagine the reasoning process in B that is triggered by the input parameter wish . If B refuses to do D ,"
9	2021_acl_long_281	"the result is incorrect "" "" . Sentence 2 : "" "" According to my calculations we will finish in three days "" "" . Sentence 3 : "" "" [ He/she ] had several gallstones "" "" . Figure 4b , sentence 1 : "" "" For dessert [ <<< he/she >>> ] ate cheese with quince "" "" . Sentence 2 : "" "" We went to a cheese gastronomy days "" "" . Sentence 3 : "" "" [ He/She ] approached her and ran his hand over her chin "" "" . Figure 4c , sentence 1 : """
10	2020_nlpmc_1_6	"is in the top categories because it relates to the term ' water ' which can be considered a partial duplicate of category water . Initiative analysis focuses on the distribution of turns based on the person taking the lead in the conversation . A person takes the lead/initiative when <<< he/she >>> contributes to the conversation ( e. g. , by asking a question ) instead of only answering the questions or responding with fillers ( such as ' okay ' , ' umm ' ) . In turn , when a speaker takes initiative , the control of the conversation transfers"
11	L16_1224	". As not all teachers learned the tasks from participants , but from the experimenter , additional learners were required . Due to organisatory reasons five teachers explained the task to a ' knowing ' learner , who was already acquainted with the task but instructed to act as if <<< he/she >>> did not know the task . In this study , the focus is on the information transmitted by the teacher . Although we are aware that ' knowing ' learners react differently than naive learners , we argue that/IN for our research questions it is sufficient that/IN the teacher assumes"
12	W04_1607	"token . Examples of the output of the morphological analyzer are shown below where the left hand side represents the lower input string and the right hand side is the upper side output 1 : ‫ﻣﺴﺎﻓﺮﻳﻦ‬ ' travelers ' msâfryn msâfr+Noun+Pl ‫رﻓﺖ‬ ' he/she left ' rft rftn+Verb+Ind+Pret+3P+Sg ‫وﮐﻴﻠﺴﺖ‬ ' <<< he/she >>> is a lawyer ' vkylst vkyl+Noun&gt;bvdn+Verb+Ind+Pres+3P+Sg The rules are written as regular expressions and are represented as continuation paths within the lexc grammar . The morphological analyzer covers 1 Unless otherwise specified , the Persian examples are direct transliterations of the Persian script and do not include short vowels ,"
13	W10_1303	"relevance of utterances to the current situation , but it would also significantly aid the user in remember-ing where these messages are stored so that/IN they can be accessed . Essentially the user could direct the system to step through messages appropriate for each scene of a given script as <<< he/she >>> is actually experiencing the scene . The utterance-based system would have a "" "" now point "" "" which corresponds to the scene in which the user is currently located in the script . Utterances useful for the conversation during that scene are easily available using very few keystrokes ."
14	W12_1621	") in his/her image to the matcher , so that/IN the matcher would know which object has what name . As shown in Figure 1 , those secret names are displayed only on the director ' s screen but not the matcher ' s . Once the matcher believes that <<< he/she >>> correctly acquires the name of an target object , he/she will record the name by mouseclicking on the target and repeating the name . A task is considered complete when the matcher has recorded the names of all the target objects . Examples Consistent with previous findings ( Liu et"
15	E17_1026	"labelled as positive , negative , neutral or topic-related according to the context where it has been used . We provide an example for each label . Annotators The complete set of posts has been labelled by three different annotators . Each annotator is a very proficient English speaker and <<< he/she >>> has a different level of NLP background and topic knowledge from the others . We distinguish these two types of knowledge because they are equally important and necessary for annotating a dataset , especially in a movie domain . A topic expert can be very confident on understanding the meaning"
16	W19_7710	"central for S2 as well . Since Hungarian finite verbs have a way of marking not only the person and number of the subject but also the definiteness ( contextual recoverability ) of the object referent ( marked by DEF in the glosses ) , speaker B employs megvette ' <<< he/she >>> bought it ' without any dependents in her reduced answer in ( 1b ) . In this context , the verb is sufficient to convey the same message as the elaborate clause in ( 1a ) . I use the term clausal core to refer to a minimal unit in"
17	P83_1005	"a dog t otherwise unknown to our speaker and hls/her audience , just walked by the front porch , on which our protagonists are sitting . When the speaker utters the sentence he/she is exploiting a situation in which bo{h speaker and audience saw a lone dog stroll by ; <<< he/she >>> is not describing either that/IN particular recent situation or such a sltuation-type -there may have been many such ; the two of them often sit out on that porch , the neighborhood is full of dogs . Rather , the speaker is referring to a situation in which that dog"
18	2020_acl_main_72	"becomes favorable when the user prioritizes coverage than quickness , and +Fd(p ) becomes favorable when vice versa . As a possible use case of HB , the analyst may quickly find interesting perspectives by creating various dictionaries with one of the FWPS methods , and once finding those , <<< he/she >>> switches to a linear classifier to expand the promising dictionaries more . Conclusion To the best of our knowledge , this paper proposes the first formulation of interactive dictionary construction for text analytics , which clarifies the critical issues to resolve . In response to those issues , we provide"
19	2021_paclic_1_12	"a face threatening act , which would threaten readers ' negative face if they do not take the action as desired by the speaker . Therefore , since a reader ' s negative face may be threatened by the speaker ' s persuasion act , the reader would decide whether <<< he/she >>> accepts the speaker ' s viewpoints or not ( Taillard , 2002 ) . In order to let readers agree with speaker ' s suggestions to the largest scale , the speaker needs to be strategic while expressing his/her intentions on the statements . Hovland et al. ( 1953 )"
20	N06_3001	"the structural events to further improve the understanding of human communication . Some research results are summarized in this document and my future research plan is described . Introduction In human communication , ideas tend to unfold in a structured way . For example , for an individual speaker , <<< he/she >>> organizes his/her utterances into sentences . When a speaker makes errors in the dynamic speech production process , he/she may correct these errors using a speech repair scheme . A group of speakers in a meeting organize their utterances by following a floor control scheme . All these structures are"
21	W18_7106	"Sorani , Somali , Spanish and Tigrinya 5 . In the consent , we inform the learners about the project , and describe the management of personal information throughout the project , including the statement that/IN participation is entirely voluntary and the subject can opt out of continued involvement whenever <<< he/she >>> wants without the need to provide any explanation . Further , we state that/IN we will not disclose the person ' s name and we will remove personal information from the texts to guarantee anonymity . Since the agreement covers a period of a learner ' s involvement in the"
22	C92_2067	"handle a wide variety of types of text , it fails IX ) provide immediate help to adapt to the particular domain or field . ( 3 ) . It is not easy to achieve consistency and objectiveness . Even for the same person , it is very likely that/IN <<< he/she >>> would judge a translation result differently at different time , especially when the evaluation criteria are loosely defined . Based on the above problems with human inspection , some automatic approaches were proposed to eval-uate translation output quality . In [ Yu 91 ] , for example , a corpus"
23	P03_1033	"and Pan , 2000 ; Chu-Carroll , 2000 ; Lamel et al. , 1999 ) . Nevertheless , whether a particular response is cooperative or not depends on individual user ' s characteristics . For example , when a user says nothing , the appropriate response should be different whether <<< he/she >>> is not accustomed to using the spoken dialogue systems or he/she does not know much about the target domain . Unless we detect the cause of the silence , the system may fall into the same situation repeatedly . In order to adapt the system ' s behavior to individual"
24	J86_2002	"for a student under the attribute NATIONALITY is a member of the set ( U. K. U. S. A. Australia ... ) , he/she may be designated as coming from an English-speaking country . Finally , if the student has value U. K. , France , etc. for NATIONALITY , <<< he/she >>> may be considered to be from Europe . Distinguishing values correspond to key values that naturally divide the values in a domain into distinct classes . In this sense they are very similar to McCoy ' s ( 1982 ) "" "" very specific axioms "" "" , although how"
25	N19_4012	"the front-end design of our web application for creating a new post , where labels represent the sequence of actions . In this website , an author can first click on "" "" New Post "" "" ( step 1 ) to bring a new post view . Then , <<< he/she >>> can write content of an article in the corresponding text-area ( step 2 ) without specifying it ' s headline and highlights , i. e. , summary . By clicking "" "" NATS "" "" button ( step 3 ) and waiting for a few seconds , he/she will see"
26	C92_4182	"oka~sakf ' and "" "" atesakf ' for ' destination ' in Fig. 1 ) . In addition , there are particular phenomena of expression variations depending hi)on the particular dialogue . For exmnple , if a speaker is uttering his/her own address for tile concept ' address ' , <<< he/she >>> will use "" "" 3uusyo""""([my ] address ) , e. g. "" "" Juusyowa Oosaka-sht desu . "" "" ( My address is in Osaka~city . ) . On the other hand , if he/she is uttering tile other participant ' s address , he/she will use "" "" ."
27	W08_1407	"participant was asked to familiarize himor herself with the location of the image by analyzing the map and going through all 11 URLs . Then each participant decided on up to 5 different pieces of information he/she would like to know if he/she sees the image or information about something <<< he/she >>> relates with the image . The information we collected in this way is similar to ' information nuggets ' ( Voorhees , 2003 ) . Information nuggets are facts which help us assess automatic summaries by checking whether the summary contains the fact or not . In addition to this"
28	P84_1109	"the object of the underlying verb ( drive , transfer , detect , hold ) ; here too , a permanent connection is established . A truck driver is a person whose ( social ) function is to drive trucks , and that/IN person is still a truck driver when <<< he/she >>> drives a scooter . If you use an oil pump to pump your tomato juice , it still qualifies to be called an oil pump . But when the nouns are inverted , there is a change in meaning and , possibly , in acceptability . It is hard to"
29	W14_2710	"dynamics during the course of an interaction correlate with the power differences between its participants . We perform this study on the US presidential debates and show that/IN a candidate ' s power , modeled after their poll scores , affects how often he/she attempts to shift topics and whether <<< he/she >>> succeeds . We ensure the validity of topic shifts by confirming , through a simple but effective method , that/IN the turns that/IN shift topics provide substantive topical content to the interaction . Introduction Analyzing political speech has gathered great interest within the NLP community . Researchers have analyzed political"
30	L18_1044	"made : First , we decided to drop the Outcome from the PICO annotation task since it appeared to be too diverse to reach a reasonable inter-annotator agreement , i. e. only PIC was annotated . Second , we introduced a confidence selection where the annotator could state how confident <<< he/she >>> was , in his/her annotation . We offered three options : Low Confidence , Medium Confidence and High Confidence ( default ) . With the third prototype , we achieved acceptable agreements of around 45 % for the Intervention/Comparison , and 55 % for the Population , in a smallscale"
31	W00_1012	"ongoing dialogue . The tactic of enticement consists in increasing B ' s wish to do D ; the tactic of persuasion consists in increasing B ' s belief of the usefulness of D for him/her , and the tactic of threatening consists in increasing B ' s understanding that/IN <<< he/she >>> must do D. Communicative tactics are directly related to the reasoning process of the partner . IrA is applying the tactics of enticement he/she should be able to imagine the reasoning process in B that is triggered by the input parameter wish . If B refuses to do D ,"
32	Y15_1053	". Thus , it is necessary to select a subset of them , which is expected to include the news experts . Search for news experts will then be confined to this subset . There are two types of data that describe a user : his/her profile and the microblogs <<< he/she >>> posts . Profile information can be divided into three parts : ( i ) , Description : This part includes usernames and other descriptive data given by the users themselves . ( ii ) , Authority : Microblogging platforms provide verifications for some users , called verified accounts . Verification"
33	Y15_1007	"the experiment , so we collected 78 responses . Data Cleansing and Result Calculation We firstly checked the responses one by one and filtered out invalid ones . A response is considered invalid if 1 ) more than 15 words were skipped ( i. e. , the subject claimed that/IN <<< he/she >>> did n't know these words ) , or 2 ) less than three numbers of the 7-point rating scale were used . Only two invalid responses were identified , one was from a mainland subject , the other was from a Hong Kong subject . So there are a total"
34	Y15_1007	"for money . In order to ensure that/IN the participants are native Chinese speakers and to improve data quality , we use the following measures , ( 1 ) a participant must correctly answer the first two Chinese character identification questions in the section 2s of the questionnaires , and <<< he/she >>> must correctly answer at least one of the last two questions in these section 2s ; ( 2 ) If a participant do not satisfy the above conditions , he/she will not see Section 3s ; ( 3 ) each word stimulus in section 3s has an option which allows"
35	L18_1535	and POS to help with this task . • Scan the various AUTO entries provided for all regions . This might help him remember words that are possible candidates to add for the cities he/she is responsible for . • Delete all entries that are NOT relevant to the cities <<< he/she >>> is responsible for . • Apply the necessary changes for some entries that may need some minor fixes . • Add new words that are not on the AUTO list . • Think of more than one translation into his/her dialect and carefully specify the city . • Use external
36	2000_amta_workshop_3	"a synonymous counterpart to each phrasal verb . To do this , the learner should use not the original list of the illustrative sentences but its copy in which all the phrasal verbs are substituted with blanks . If the learner does not know the meaning of a synonym , <<< he/she >>> can ask the MT program for help as all the verbs of the list of synonyms are stored in the electronic dictionary . If the learner can guess the meaning of the phrasal verb after he/she has analyzed the translation of the illustrative sentences performed by the program , he/she"
37	C96_2156	"ferring his/her iut , entio , to the a. pplica . tioa system . For example , in . t+ piet+tu'e &lt;]ra+ ' , ving tool , if a. user is a. llowed t&lt; ) point a.1 . a. si&gt;e eific ol&gt;jeet while sa , ying %Jelete "" "" , <<< he/she >>> ca . tl sa . ve ht . bor , be( : a. use he/she does , of ha : . +'e Io cha , llge , t. hc IHouse positiotl frol~l the CIILIIVIhS to it . lllellll item a. t t. he lllellt£ |)ill ' a. rea . ,"
38	W16_6617	"from our pattern generation work . Both opinions are informative generation results . The blogger _( author ' s name)_ came to _(traveling places)_ for traveling , where he/ she experienced __(place1)_ , _(place2)_ , _(place3)_ , and _(place4)_ . About _(evaluator 1)_ , _(name of the author)_ like because <<< he/she >>> thinks that/IN it is _(evaluative pattern 1)_ , particularly _(part of evaluator 1)_ is worth trying . In addition , he/ she also went to _(evaluator 2)_ , and he/she recommended it because of_(evaluative pattern 2)_ . Among that , _(part of evaluator 2 )_ is the most recommended one"
39	H94_1037	"explore all these dimensions freely and run the risk of confusion , a more productive solution may be for the system to take control of the dialogue by offering explicit choices . Of course , the user should still be free to diverge from the computer ' s goal whenever <<< he/she >>> so chooses . Until very recently , the system ' s knowledge has been limited to fewer than sixty major cities in North America , Europe , and Japan . We have just expanded PEGASUS'S knowledge base to more than 220 major cities worldwide . Nevertheless , it is still"
40	2022_acl_long_132	"al. , 2019 ; Dinan et al. , 2020a ; Webster et al. , 2020 ; Barikeri et al. , 2021 ) is a databased debiasing strategy often used to mitigate gender bias . Roughly , CDA involves re-balancing a corpus by swapping bias attribute words ( e. g. , <<< he/she >>> ) in a dataset . For example , to help mitigate gender bias , the sentence "" "" the doctor went to the room and he grabbed the syringe "" "" could be augmented to "" "" the doctor went to the room and she grabbed the syringe "" """
41	2000_amta_workshop_3	supposed to extend the electronic dictionary by adding to it the phrasal verbs having idiomatic meanings that were absent in the initial dictionary . The last stage of the lesson is meant to stimulate the learner ' s creativity . The learner must create as much sentences using phrasal verbs <<< he/she >>> has learned at the lesson as possible . Another task is to make them up in such a way that/IN the program could translate them in the best way . These lessons have been used for several years at Kharkov Teachers ' Training University and proven to be rather efficient
42	W16_3601	"judiciously select the question , given the context of the game , in order to narrow down the range of valid people . There are 31 questions . Table 1 shows a summary . Attribute Q a Example Question Birthday 3 Was he/she born before 1950 ? Birthplace 9 Was <<< he/she >>> born in USA ? Degree 4 Does he/she have a PhD ? Gender 2 Is this person male ? Profession 8 Is he/she an artist ? Nationality 5 Is he/she a citizen of an Asian country ? Table 1 : Summary of the available questions . Q a is the"
43	C92_2110	"semantic cnncept , the procedures which fill the slots , the relations between the new semantic concept with existing other sentantic coucepts~ various constraiuts anlong concepts , etc. lIowever , relnember that/IN he/she must carry out such eoml)licated tasks to all possible linguistic patterns in his/her target domain , if <<< he/she >>> uses the case-based parsing approach alone . Dialogue Example between PDI and an Application Designer PDI ( Pattern Definition interviewer ) is CAPIT ' s interface to all application designer . A dialogue between PDI and an application designer progresses as follows : 1 . PDI shows the application designer"
44	2022_udfestbr_1_6	"above the one clicked ; -Delete the clicked row . It is important to note that/IN if the user removes or adds a row , the ids and the head field values from each row are automatically adjusted . When the user finished the editing on the CoNLL-U file , <<< he/she >>> just have to press the button labeled "" "" Save changes "" "" ( at the bottom right ) to save their changes . Then , he/she can go back to the results page by clicking on the button labeled "" "" Go back "" "" ( also at the"
45	2021_konvens_1_20	"( 1 ) most explicitly states that/IN the writer is in favor of it and the positive evaluation in ( 2 ) immediately gives rise to a pro relation of the writer towards liberalization . ( 3 ) expresses the need to have liberalization . This again points out that/IN <<< he/she >>> is in favor of liberalization . In ( 4 ) , prevent casts a con relation between its logical subject ( it ) and the theme role ( solution ) . A contra relation towards a positively connotated theme indicates a negative subject and suggests that/IN the writer stands in"
46	2020_findings_emnlp_224	"knowledge can lead to explainable dialogue understanding . It will help models to understand , reason , and explain events and situations . In this particular example , commonsense inference is applied to a sequence of utterances in a twoparty conversation . Person A ' s first utterance indicates that/IN <<< he/she >>> is tired of arguing with person B. The tone of the utterance also implies that/IN person B is getting yelled at by person A , which invokes a reaction of irritation in person B. Person B then asks what he/she can do to help and says this while being angry"
47	W94_0326	"choice among alternatives should prefereably be interest-based . For instance , the choice between alternatives 4 ) and 5 ) in section I may be made in favor of text 4 ) if the user wants to vary the relative significance of constraints in defning problem specifications ( therefore , <<< he/she >>> wants to know which ones prove relevant for the aspect in question ) . Alternative 5 ) is preferable for a user who wants to learn the rationale behind system decisions , which particularly includes associating justifications with constraints . 4 , CONCLUSION A mechanism assessing the comprehension effort of"
48	W15_0605	in a total of 874 responses in Train and 672 responses in Eval data sets . Features We explore five different feature sets to help us answer the following questions about the response : Did the test taker construct a story about the pictures in the prompt ( or did <<< he/she >>> produce an irrelevant response instead ? ) ( Relevance ) ; Did the test taker use words appropriately in the response ? Proper usage of words and phrases is characterized by the probabilities of the contexts in which they are used ( Collocation ) ; Did the test taker adequately
49	L16_1623	"questions annotated by the authors ) . This Stance Dataset , which was subsequently also annotated for sentiment , can be used to better understand the relationship between stance , sentiment , entity relationships , and textual inference . We can often detect from a person ' s utterances whether <<< he/she >>> is in favor of or against a given target entity ( a product , topic , another person , etc. ) . Here for the first time we present a dataset of tweets annotated for whether the tweeter is in favor of or against pre-chosen targets of interest-their stance ."
50	W12_3501	"reminder . The interface can be controlled by mouse and keyboard as well as via speech commands following a structured dialogue . By this , the used is free to chose if he/she wants to use mouse and keyboard as a fast way to enter an appointment or speech if <<< he/she >>> is not close enough to the robot ' s touch display and is either not willing or not capable to reach it . Speech Recognition Creating an automatic speech recognition ( ASR ) device requires different processing steps . Figure 5 illustrates exemplary the structure of such a system ."
51	2020_wnut_1_76	"is to develop systems that can automatically extract related events from tweets . The built system should identify different pre-defined slots for each event , in order to answer important questions ( e. g. , Who is tested positive ? What is the age of the person ? Where is <<< he/she >>> ? ) . To tackle these challenges , we propose the Joint Event Multitask Learning ( JOELIN ) model . Through a unified global learning framework , we make use of all the training data across different events to learn and fine-tune the language model . Moreover , we implement"
52	W17_5051	"( 2016 ) , grammatical errors/corrections get an extra mark to be excluded from orthographic analyses but in the target hypothesis , only the grammatically correct form is given and spelling errors within the erroneous form are not considered . For instance , *&lt;Dretet&gt; is corrected to &lt;tritt&gt; ' ( <<< he/she >>> ) kicks ' while an orthographically correct ( but grammatically incorrect form ) would be &lt;tretet&gt; . Furthermore , one cannot see how ambiguous cases are handled , e. g. *&lt;er schlaft&gt; is treated as an orthography error and cor-rected to &lt;er schläft&gt; ' he sleeps ' , although the"
53	P18_1056	"social power . In particular , the effect of social power cannot be reliably detected by linear models once introducing utterance length . Another interesting piece of result is the significant interaction term C power * C pLen , which implies that/IN the power status of speaker and how long <<< he/she >>> tends to speak are not totally unrelated . Significant but weak correlation are found between C power and C pLen ( using Pearson ' s correlation score ) : r = −0.059 in SC ; r = −0.018 in Wiki . This correlation may show some kind of a linguistic"
54	P06_2099	". The system displays a cooking recipe in a browser . As in a typical recipe , cooking instructions are displayed step by step , and sentences or phrases representing a cooking action in the recipe are highlighted . When a user does not understand a certain cooking action , <<< he/she >>> can click the highlighted sentence/phrase . Then the system will show the corresponding animation to help the user understand the cooking instruction . Note that/IN the system does not show all procedures in a recipe like a movie , but generates an animation of a single action on demand ."
55	N19_1378	"the ' gender ' and ' job ' columns of Table 4 show that/IN results are a bit better in this case but models still perform quite poorly : Even in the case of an attribute like gender , which is crucial for the resolution of third person pronouns ( <<< he/she >>> ) , the models ' results are quite close to that of a random baseline . Thus , we take it to be a robust result that/IN entitycentric models trained on the SemEval data do not learn or use entity information-at least as recoverable from language cues . This ,"
56	2020_lrec_1_701	"is to determine the contextual meaning of the sentences , especially the core constructions of them . In a given context , the first sentence is an ordinary "" "" special question "" "" . The speaker tries to draw listeners ' attention to let them imagine the situation when <<< he/she >>> cannot take care of "" "" her(the people who may be mentioned in the context ) "" "" and consider the accompanying consequence . The second sentence contains a construction "" "" _ ( wait ) + X(replaceable event ) + noun/pronoun + _ ( should be ) + _"
57	P18_1036	"word ( consisting of many morphemes ) has usually more than one . For instance two possible analyses for the Turkish word "" "" dolar "" "" are ( 1 ) "" "" dol+Verb+Positive+Aorist+3sg "" "" ( it fills ) , ( 2 ) "" "" dola+Verb+Positive+Aorist+3sg "" "" ( <<< he/she >>> wraps ) . For a syntactic task , models are not obliged to learn the difference between the two ; whereas for a semantic task like SRL , they are . We will refer to this issue as contextual ambiguity . Another important linguistic issue for agglutinative languages is the"
58	2022_udfestbr_1_6	"universal dependency-based treebanks . It is written with Python and Javascript . However , the app is supposed to only run locally and to be accessible with a web browser through localhost . That could be a problem , because , in order for the user to use Interrogatório , <<< he/she >>> must install it first , which can be confusing if they are less experienced . UDConcord does not suffer from this , because it is a web application accessible through the web . To make queries with Interrogatório , the user must learn a query language that is similar to"
59	I13_1042	"that/IN such endorsements as well as the funds raised through campaigns positively affect the Power Index of the candidate . However , a more important source of a candidate ' s power is their relative standing in recent poll scores . It gives the candidate a sense of how successful <<< he/she >>> is in convincing the electorate of his/her candidature . In this study , we model the Power Index of each candidate based solely on their recent state or national poll standings because we think that/IN this is the most dominant factor . Other components such as the funds raised can"
60	2020_acl_main_567	"the performance , we investigated some dialogue examples and shown them in Table 4 . In the first dialogue , by asking "" "" Could you also find me a hotel with a moderate price that offers internet ? "" "" , the user has briefly informed the agent that/IN <<< he/she >>> is looking for a hotel "" "" with internet "" "" . The previous model missed the "" "" hotel-internet "" "" in the tracked slots . Because the model is mislead by the long interaction history . Our model learns to focus on important information using the slot attention"
61	2020_lrec_1_108	"tailored to the material but also to the technical solutions of the infrastructure . An example of a technique that is implemented in Karp is the ability to access the source document , and the possibility of viewing it in the interface . When a user performs an entry search <<< he/she >>> will be presented with a link to the facsimile , given it is available , as a part of the search results . The user can further click the link and access the facsimile which is enlarged at the center of the page . This functionality has been proven useful"
62	C98_2158	"even though the number is small . For example , there is a test sentence such as follows : ( 19 ) ano hito-wa 82sai-ni natte , annani koukisin ippai-da . that person-TOP 82-years-old-DAT become-te , so curiosity bc-fidl-PRES "" "" Although that person is 82 years old , ( <<< he/she >>> ) is full of curiosity . "" "" Since the combination of the event type here is I(BECOME , BE ) , our program gave it the Circumstance relation as a default . However , we know that/IN in general the person who is 82 years old is not so"
63	W13_2115	"deleted from the action space . Ordering In order to find out in which order the lecturers describe the factors , we transformed the feedback summaries into n-grams of factors . For instance , a summary that/IN talks about the student ' s performance , the number of lectures that/IN <<< he/she >>> attended , potential health problems and revision done can be translated into the following ngram : start , marks , lectures attended , health issues , revision , end . We used the constructed n-grams to compute the bigram frequency of the tokens in order to identify which factor is"
64	P15_2107	"annotations from an expert annotator . 50 emails were randomly selected from AllAgreed emails for each level . The annotator was required to check the background of each recipient ( e. g. the recipient ' s position in the company at the time , his/her department information and the projects <<< he/she >>> was involved in if these information were available online ) and judge the relationship between the email ' s contacts before annotation ( e. g. if the contact is a family member or a close friend of the recipient ) . Agreement study shows a Kappa score of 0.7970 for"
65	R11_1106	"texts as candidate titles . An original approach combining statistical criteria and noun phrases positions in the text helps collecting relevant titles and subtitles . So , the user may benefit from an outline of all the subjects evoked in a mass of documents , and easily find the information <<< he/she >>> is looking for . An evaluation on real data shows that/IN the solutions given by this automatic titling approach are relevant . "" This paper describes a system facilitating information retrieval in a set of textual documents by tackling the automatic titling and subtitling issue . Automatic titling here consists"
66	C92_2110	"of KBP ' s interpretation failures . We regard defining pattern-concept pairs for CBP as repairs of KBP ' s interpretation failures . We defined four repair types which are corresponding to KBP ' s typical interpretation failures . When all application designer encounters KBP ' s interpretation failure , <<< he/she >>> analyzes it , then selects the best and easiest repair type . Such a repair task is accomplished interactively between the application designer and the Pattern Definition Interviewer module ( PDI ) . CAPIT Flow We have been collecting Japanese corpora which untrained users typed from computer terminals in order"
67	W11_3412	"rule includes information from Urdu WordNet and inserts the hypernym of the verb kHA ' eat ' , namely that/IN it is a verb of consumption . The resulting semantic representation is presented in a less formal way in Figure 9 . The Agent of the sentence , vuh ' <<< he/she >>> ' performs a consumptive action , kHA ' eat ' towards the Patient , sEb ' apple ' and this act is performed at the location t3ul AbEb ' Tel Aviv ' . Discussion As for every computational grammar or semantic or analyzer , one wishes to have a thorough"
68	W19_0505	"terms of the atoms but differing in generality . An example of a text where this is necessary is : Bill does not own a vehicle . If Bill does not own a vehicle then he does not own a car . If someone does not own a car then <<< he/she >>> owns a motorcycle . If someone owns a motorcycle then he/she owns a vehicle . ACERules is unable to relate the group of atoms for "" "" Bill owns a vehicle "" "" and the more general ( because of the use of an indefinite pronoun ) "" "" he/she"
69	R13_1065	"the fifth chapter . The following chapter focuses on specific linguistic data analysis . At the end , we discuss the obtained results from the cross-tabulation analysis and association rules . Request as a Speech Act A request is a speech act whereby a requester conveys to a requestee that/IN <<< he/she >>> wants the requestee to perform an act which is for the benefit of the requester ( Trosborg , 1995 ) . The act may be a request for an object , an action or some kind of service , etc. a request for non-verbal items or services . Or it"
70	W07_2458	"the false start does not have a verb . The utterance with the false start has dictated the analysis of the entire utterance , though the real subject is the word ' seda ' . False starts Original utterance kui kui+0 //_J_// @J # if ta tema+0 //_P_// @SUBJ # <<< he/she >>> seda see+da //_P_// @ADVL @NN&gt; # this / sg part seda see+da //_P_// @PRD @ADVL # this / sg part tükina tükk+na //_S_// @ADVL # as a single piece siin siin+0 //_D_// @ADVL # here ei ei+0 //_V_// @NEG # not ole ole+0 //_V_// @+FMV # is Example 3 ."
71	O13_3001	"levels as discrete classes , we think readability is continuous . That is , an article that is suitable for students of a certain level must also be comprehensible for students of higher levels . Similarly , if a student can understand an article of a certain reading level , <<< he/she >>> must also be able to understand any article of a lower reading level . Therefore , when building classifiers for lower grade , we use articles of grades 1 and 2 as positive data , while the others are negative data . When building classifiers for middle grade , articles"
72	W14_2710	"this paper , we investigate how topic dynamics during the course of an interaction correlate with the power differences between its participants . We perform this study on the US presidential debates and show that/IN a candidate ' s power , modeled after their poll scores , affects how often <<< he/she >>> attempts to shift topics and whether he/she succeeds . We ensure the validity of topic shifts by confirming , through a simple but effective method , that/IN the turns that/IN shift topics provide substantive topical content to the interaction . "" In this paper , we investigate how topic dynamics"
73	2022_naacl_main_227	"defined as final golden references . For the sake of self-improvement , we employ a self-study mechanism that allows annotators to learn from their mistakes if they submit an incorrect reference . Concretely , if an annotator submits a reference that is not included in the final golden references , <<< he/she >>> has to modify his/her submission into a correct one . Moreover , the annotator can also make complaints if he/she insists that/IN his/her submission is correct . We find that/IN the self-study and making-complaints mechanisms can trigger very helpful discussions . To improve annotation efficiency , we have developed a"
74	W00_1012	"pleasant aspects of D for him/her overweight unpleasant ones ; . second , subject may fmd reasonable to do D , if D is needed to reach some higher goal , and useful aspects of D overweight harmful ones ; and tlfird , subject can be in a situation where <<< he/she >>> must ( is obliged ) to do D -if not doing D will lead to some kind of punishment . We call these ; factors wish- , neededand must-factors , respectively . For instance , in reasoning about some action D ( e. g. proposed by another agent ) ,"
75	W03_2128	"questions himself/herself . Such act is called adjusting the conditions of the answer ( example 6 ) . The third possibility is to avoid the reaction . A too general request or question is followed by a pause . The fourth possibility is that/IN the answerer refuses to answer but <<< he/she >>> proposes another way to the partner to get the needed information ( per email , fax , to go to the office , etc. ) . In human-computer interaction it can be supposed that/IN the computer tries to answer all the general questions and uses adjusting acts for this purpose"
76	P87_1005	"the IRACQ user can access a dictionary package for acquiring and maintaining both lexical and morphological information . Such a thoroughly integrated set of tools has proven not only pleasant but also highly productive . Editing an IRule If the user later wants to make changes to an IRule , <<< he/she >>> may directly edit it . This procedure , however , is error-prone . The syntax rules of the IRule can easily be violated , which may lead to cryptic errors when the IRule is used . More importantly , the user may change the semantic information of the IRule so"
77	R13_1065	"of politeness than as separate factors ( lift : 1.22 ; 1.22 ; 1.12 ; 1.11 ) . In case of the couple pre-sequences ==&gt; requestee ' s perspective , the association of direct factors of politeness is shown . This means that/IN when the requester used a pre-sequence , <<< he/she >>> also used the requestee ' s perspective ( to mitigate the directness of a request and its impact and effect on the requestee ) . The pre-sequence and requestee ' s perspective were associated with allerters ( salutations and greetings ) ( F5 with F1 ) or ( F3 with"
78	2020_emnlp_main_10	"s distribution of labels among the six categories substantially deviated from other workers ( e. g. , almost always selecting the same category ) , or if his/her task completion time was unrealistically low , then his/her work was sampled and checked . If it was of low quality then <<< he/she >>> again was ( paid and ) blocked , and his/her annotations redone . Pairwise agreement was 74 % ( 2 class ) or 45 % ( for all six subclasses ) , with a Fleiss κ ( inter-annotator agreement ) of 0.37 ( "" "" fair agreement "" "" ("
79	L16_1361	"has 14 forms ( e. g. katedrze romańskiej loc , sg , katedrom romańskim dat , pl ) depending on the case and number . Two of these forms are homomorphic with the other ones . The number of considered term candidates can be reduced by the user , if <<< he/she >>> submits a list of lemmas of stop words . If a term candidate contains any of the stop words , it is eliminated . For example , ta katedra romańska ' this romanesque cathedral ' should be excluded from the list of term candidates for obvious reasons , although it"
80	2020_lrec_1_87	the speaker provoke memory listener ' s reaction that/IN his/her memory is provoked by the content of the speaker ' s utterance start thinking listener ' s reaction that/IN he/she is starting to think about the content of the speaker ' s utterance thinking process listener ' s status that/IN <<< he/she >>> is thinking about the content of the speaker ' s utterance Table 1 : Types of attentive listening responses and their roles attentive listening responses . The degree of empathy expressed by attentive listening responses is thought to depend on their types . Here is an example of narrative and
81	2022_naacl_main_69	"ensures ( ϵ , δ)-Bayesian Confidentiality if for any D ′ , ( A(D ) , A(D ′ ) ) is ( ϵ , δ)-indistinguishable , where A(D ) is jointly distributed over x ∼ µ and A. The Bayesian confidentiality measures how much information an attacker could gain if <<< he/she >>> ' s prior knowledge about this secret x is described by the distribution µ . This is a strict generalization because when µ is a single point mass at x , it recovers Definition 2 . The additional generality allows us to quantify the stronger confidentiality guarantee against weaker adversaries"
82	W99_0627	"their singular value decompositions . Reviewers manually ranked their interest in all submitted abstracts , and best performance was achieved when reviewers were assigned twice their target number of abstracts and asked to choose their preferred half . One problem with the modeling of reviewer rankings/bids is that/IN these may <<< he/she >>> is most qualified to review . Even with instructions , there may be a natural human tendency to bid higher on exciting/interesting abstracts in a more distant area and possibly bid lower on weak/uninteresting papers in the reviewer ' s core expertise . In addition , AAAI reviewers also report"
83	C04_1116	"deleting the noise candidates in the synonymous expression candidates . However , as shown in Section 2 , each author does not necessarily use only one expression for one meaning . For instance , while the call taker B in Table 1 mostly uses "" "" cust "" "" , <<< he/she >>> also uses other expressions to a considerable degree . Accordingly if we try to delete all noise candidates , such synonymous expressions will be eliminated from the final result . To avoid this kind of over-deleting , we classified words into three types , "" "" Absolute Term "" """
84	P18_1140	"entire dialog context into consideration . Interruption is defined as the user interrupting the system speech . Interruptions occurred fairly frequently in our dataset ( 4896 times out of 14860 user utterances ) . Button usage When the user is not satisfied with the ASR performance of the system , <<< he/she >>> would rather choose to press a button for "" "" yes/no "" "" questions , so the usage of buttons can be an indication of negative sentiment . During DSTC1 data collection , users were notified about the option to use buttons , so this kind of information is available"
85	C16_1016	"based on HPY is explained by the Hierarchical Chinese restaurant process ( CRP ) . In the CRP , there are tree-structured restaurants with tables and customers that are regarded as latent variables of words . When a customer enters the leaf restaurant h , which corresponds to context , <<< he/she >>> sits down at an existing table or a new table depending on some probabilities . If he/she selects a new table , an agent of the customer recursively enters the parent restaurant h as a new customer . Here , we represent the depth of h as |h| , and"
86	W19_8603	"randomly chosen according to the domain type of the production session . The contexts marked with + are designed with focus on the speaker ' s interest . In these contexts , the speaker envisages some personal intention for which it is important to convey to the listener which object <<< he/she >>> refers to . Correct identification is important to the speaker . The contexts marked with O are designed as rather neutral , where correct identification is of equal importance for both speaker and hearer in a collaborative task . The -marker indicates that/IN these contexts focus on the hearer '"
87	L18_1338	"mounted with the Leap Motion sensor 2 for hand tracking , see Figure 3 , left . A camera ( Microsoft Kinect ) is positioned opposite of the user directed at the table for object tracking . The user performs different actions defined by visual instructions and verbally describes what <<< he/she >>> is doing . Two microphones record the user ' s description of the performed action . The data is recorded in such a way that/IN it resembles The Oculus Rift DK2 is worn by the user and provides the user ' s head pose . It is needed to transfer"
88	C80_1081	"can check the data syntax immediately after the correction ( see Pig . 5 ) . I Formatted records Note : Data Editor output an input record with the corresponding error message . The human proofreader can easily recognize the input error and revise it . After the revision , <<< he/she >>> can check whether the input record contain no more errors , by calling the DTV . We used DTV for data translation of the English-Japanese dictionary . About 500 rules and 150 states were necessary to manage exceptional description format of the dictionary . Because DTV should scan and check"
89	Y18_1085	"are uttered , based on the speaker ' s knowledge , although in ( 8b ) this source of information is explicitly stated . However , ( 8a ) and ( 8b ) have a slight , subtle difference : if one utters ( 8b ) , it sounds like <<< he/she >>> is trying to limit his/her responsibility in the following sense : as the speaker explicitly points out , this utterance is based on the speaker ' s knowledge . The speaker could be wrong , if his/her knowledge is inaccurate or insufficient . 6 While the speaker ' s knowledge"
90	W05_0805	"place regularly , and thus , the results of these changes can be rediscovered in our synchronic classes . Figure 3 shows the historic relationship between the three languages . A potential learner of a related language does not have to be aware of the historic links between languages but <<< he/she >>> can implicitly exploit the similarities such as the ones discovered in the classes . The relationship of words from different languages can be caused by different processes : some words are simply borrowed from another language and adapted to a new language . Papagei-papegaai ( parrot ) is borrowed from"
91	D12_1113	"vice-versa ) . However , when the page is assigned a non-person-related fine-grained NE type ( e. g. school ) and at the same time is not assigned a person-related fine-grained NE type ( e. g. novelist ) , we mark the page as inanimate regardless of the presence of <<< he/she >>> pronouns . The nationality is assigned by matching the tokens in the original ( unprocessed ) categories of the Wikipedia page to a list of countries . We assign nationality not only to the Wikipedia titles , but also to single tokens . For each token , we track the"
92	C04_1182	"the word with one that is phonologically similar . An interjection ( IJ ) is any word inserted into a sentence that is not in the original text ( e. g. , ' um ' or ' ah ' ) . Repetitions ( REP ) occur when the child realizes <<< he/she >>> has made a mistake and self corrects him/herself usually by repeating the misread word or by beginning the sentence over again . In some cases the child catches his/her error before finishing the word and thus creating a partial word , however , since it is a conscious act by"
93	2022_semeval_1_44	"various linguistic techniques used for detecting Patronizing and condescending language ( PCL ) . This task particularly poses a new challenge in the field of NLP because of its subjectivity , subtle usage , and requirement of world knowledge . A person is said to be condescending or patronizing when <<< he/she >>> uses a superior tone to talk down to people or tries to raise pity by describing their situation . Even though people often use PCL with good intentions , it encourages stereotyping , discrimination and leads to greater exclusion . Therefore , it is important to devise methods that facilitate"
94	P82_1036	"in unskilled writing . These errors may be typographical , a case we shall ignore in this discussion , or they may be grammatical . Of most interest to us are the cases where the error is due to a language user attempting to use a standard language construction that/IN <<< he/she >>> does not natively command . In the course of this brief communication we shall discuss each of the above cases with examples , drawing on work we have done describing the differences between the syntax of vernacular speech and of standard writing ( Kroch and Nindle , 1981 ) ."
95	W00_1012	"pleasant aspects of D for him/her overweight unpleasant ones ; . second , subject may fmd reasonable to do D , if D is needed to reach some higher goal , and useful aspects of D overweight harmful ones ; and tlfird , subject can be in a situation where <<< he/she >>> must ( is obliged ) to do D -if not doing D will lead to some kind of punishment . We call these ; factors wish- , neededand must-factors , respectively . For instance , in reasoning about some action D ( e. g. proposed by another agent ) ,"
96	W16_1714	"do not segment the copular part of gördügüyüz in ( 2 ) below , we cannot identify the facts that/IN the verb gör ' see ' is inflected for past tense , while the copula is in present tense . Furthermore , the subject of the copula is o ' <<< he/she >>> ' , while the subject of the verb gör is biz ' we ' . ( 2 ) Biz We . PRON o-nun he/she . PRON-Gen rüya-sı-nda dream . NOUN-P3S-Loc gör-dügü•yüz see . VERB-Past-3Sg•VERB-Cop-1Pl ' We are the ones that/IN he/she saw in his/her dream ' We segment words before"
97	I08_3009	", in order to allow typing a new word that is not included in the dictionary . The candidate number 0 in Figure 4 ( a ) is added at this point . This candidate list is displayed as a menu , where the user can select the word that/IN <<< he/she >>> intended by using a mouse or up/down arrow keys . This process is repeated on each keystroke of the user . The user can enter the selected item to his/her document by striking the space key or any punctuation key . Evaluation This section describes the evaluation of the proposed"
98	W15_4657	"own PC incl. microphone at home . After that/IN the subjects were asked to transcribe their own utterance without hearing or seeing it again . In the following we describe the tasks 1 , 4 and 5 exemplarily : In task 1 , the imaginary user tells the system that/IN <<< he/she >>> wants to listen to a certain radio station . Task 4 comprises the navigation to the address "" "" Stieglitzweg 23 , Berlin "" "" . In task 5 , the user should call Barack Obama on his cell phone . There were three different QNRs , each one asking"
99	R11_1014	"any bias in the time measurement towards HT or PE , G1 and G2 performed different tasks ( translation or post-editing ) in the experiment with the same test ( source ) sentences , and we never asked the same translator to post-edit the output of a source sentence that/IN <<< he/she >>> had previously translated or vice-versa . Since we were also interested in collecting evidence to compare the effort on post-editing the output of different MT/TM systems , we used the same PE task for pairwise system comparisons . For every source we combined the 4 systems ' outputs in pairs"
100	W18_5107	"Fine-Grained Analysis of Cyberbullying "" "" developed for English by the Language and Translation Technology Team of Ghent University ( Van Hee et al. , 2015c ) . Following these guidelines , the annotator should identify all the harmful expressions in a conversation and , for each of it , <<< he/she >>> should annotate : ( i ) the cyberbullying role of the message ' s author ; ( ii ) the cyberbullying type of the expression ; ( iii ) the presence of sarcasm in the expression ; ( iv ) whether the expression containing insults is not really offensive but"
101	L16_1322	"topics , containing discussions that happened over a period of 15 years . The dataset contains 166,322 discussion threads , across 1236 articles/topics that span 15 different topic categories or domains . The dataset also captures whether the post is made by an registered user or not , and whether <<< he/she >>> was an administrator at the time of making the post . It also captures the Wikipedia age of editors in terms of number of months spent as an editor , as well as their gender . This corpus will be a valuable resource to investigate a variety of computational sociolinguistics"
102	2020_smm4h_1_32	"task . We try to leverage medical annotations , family relation annotations , as well as dependency relations in our model . Task description and data The SMM4H 2020 task 5 is a 3-way classification problem . Class 1 tweets refer to the user ' s child and indicate that/IN <<< he/she >>> has a birth defect . Class 2 tweets are ambiguous about whether someone is the user ' s child or has a birth defect mentioned in the tweet . Class 3 tweets merely mention birth defects . Training and development sets provided by the organizers include 14705 and 3677 tweets"
103	2020_isa_1_2	"other temporal expressions which consist of multiple days or dates , such as weeks , months or years . Note that/IN spans of time with specified start and end dates are not considered in this category . For example : 3 . do mahīne bāda vaha āegā Two months after <<< he/she >>> come He/She will come after two months . • DURATION : The DURATION category is applicable to spans of text which refer to a range of time with start and end times specified in the text . 4 . cāra mahīno se gāyaba hai four months from missing is He/she"
104	E99_1038	"define focus as a cognitopragmatic category , calling for the introduction of the cognitive construct of discourse model in relation to knowledge store . Presumably , every typical adult communicator has at his/her disposal a vast and extensive knowledge store relating to the scenes and events occurring in the world <<< he/she >>> is in . The contents of the store are acquired via direct perception of the environment and , less directly , communication with others or reflection upon past acquisitions . Discourse entails the employment and deployment of the knowledge store , but in a specific discourse only a subset of"
105	1999_mtsummit_1_86	"well as English grammar . It is vital for him/her to know a part of speech in both Japanese and English , to produce a user ' s dictionary . So , how can this be expected of a user who does not know much about English grammar ? Probably <<< he/she >>> would claim that/IN this is the reason why he/she bought this MT package . If they do , they would not need to use MT . The guidance is needed for a user to create a user ' s dictionary . Also , it has to be pointed out that"
106	W16_6501	"alia , defines CEFR proficiency levels through topics . For example , the CEFR document states that/IN one should be able to "" "" introduce him/herself and others and [ ... ] ask and answer questions about personal details such as where they live , people he/she knows and things <<< he/she >>> has "" "" ( Council of Europe , 2001 , page 24 ) . The verbs göra and heta are encountered very often at the beginner level as beginners learn to introduce themselves ( e. g. Jag heter Peter . ' My name is Peter . ' ) and talk"
107	2020_lrec_1_852	"a query q holding a slot , an answer a , and a set A of possible answers . Table 3 shows the result of our investigation . The row where the length of the context passage is equal to 0 is the accuracy achieved by a human worker when <<< he/she >>> was asked to answer 100 quizzes without context information . The row where the length of the context passage is equal to 20 is the accuracy achieved by a human worker when he/she was asked to answer 100 quizzes with context information given by 20 context sentences . As shown"
108	2006_eamt_1_3	"¡ www . internostrum . com oneself ' as hacer el melocotón , literally ' to make the peach ' ) , non-dropped prepositions in verbal complements ( eg : pensó en dimitir , where the preposition en comes from the original va pensar a dimitir , which means ' <<< he/she >>> pondered resigning ' ) , articles before proper nouns ( el Irán ) , etc. • No apocopation ( 1.7 % ) For instance , wrong use of grande instead of gran as in un grande momento ( a great moment ) or primero instead of primer as in el"
109	2001_mtsummit_papers_20	"Japanese ) alongside with the source text ( English ) It must be noted here that/IN we had to prepare five different sets to carry out the experiment , in order to avoid influence across the sets . This is because once the subject has read a reading material , <<< he/she >>> memorizes the content and the same text processed in a different way will be influenced by the first reading . Test subjects It is necessary in our experiment to obtain data from subject groups possessing various English language skills . To achieve this end , subjects are chosen from those"
110	W00_1012	"increasing B ' s belief of the usefulness of D for him/her , and the tactic of threatening consists in increasing B ' s understanding that/IN he/she must do D. Communicative tactics are directly related to the reasoning process of the partner . IrA is applying the tactics of enticement <<< he/she >>> should be able to imagine the reasoning process in B that is triggered by the input parameter wish . If B refuses to do D , then A should be able to guess at which point the reasoning of B went into the "" "" negative branch "" "" ,"
111	2020_coling_main_94	"label via different approaches . From this figure , we can see that : 1 ) Though this user expresses positive emotions ( e. g. , "" "" grateful "" "" and "" "" beautiful "" "" ) in the time points [ 2015.3.27 ] and [ 2015.4.11 ] , <<< he/she >>> still expresses the negative emotions ( e. g. , words "" "" worthless "" "" , "" "" hurt "" "" and "" "" hopeless "" "" which indicate a world-weary topic ) in most of the time in a month . Moreover , all images in Figure 5 have"
112	W19_3019	"comma-separated values file that includes the post titles , content , timestamps , and anonymized unique user ids . The goal of shared Task A is to predict users ' suicide risk into one of the four classes ( i. e. , ( a)-(d ) ) given the fact that/IN <<< he/she >>> has posted on SuicideWatch . Systems Description This section provides an overview of features extracted from posts , followed by a short system description of our submitted runs . Features TF-IDF features : We used the TF-IDF weighting scheme as text representation . The TF-IDF feature vectors of n-grams were"
113	W06_2804	") . Wikis have two states , "" "" Read "" "" and "" "" Edit "" "" . "" "" Read state "" "" is by default . In this case , wiki pages look just like normal webpages . When the user wants to edit a page , <<< he/she >>> must only access the "" "" edit state "" "" . "" "" Document mode "" "" is expository , extensive , monological , formal , refined and less creative than "" "" thread mode "" "" . It is in third person and unsigned . "" "" Document mode"
114	C96_2156	"example , in . t+ piet+tu'e &lt;]ra+ ' , ving tool , if a. user is a. llowed t&lt; ) point a.1 . a. si&gt;e eific ol&gt;jeet while sa , ying %Jelete "" "" , he/she ca . tl sa . ve ht . bor , be( : a. use <<< he/she >>> does , of ha : . +'e Io cha , llge , t. hc IHouse positiotl frol~l the CIILIIVIhS to it . lllellll item a. t t. he lllellt£ |)ill ' a. rea . , a+lld lille . ill Fl : Olll the tDelltl })lt . l ' it ."
115	O12_1007	"to stimuli with higher personal word frequencies . The experimental results revealed that/IN IDs of frequencies of stimuli could explain individual variances between participants in lexical decision . Words that/IN frequency occurred in one ' s Facebook data revealed the things or issues he/she paid closer attention , the words <<< he/she >>> got accustomed to use but was unaware of , or his/her daily-life surroundings . Therefore , the effect of personal word frequencies in this experiment was considered to result from people ' s conscious or subconscious familiarity with words or concepts . The familiarity with word form and meaning facilitated"
116	Y18_1077	", such as celebrations and vacations , and naturallyoccurring phenomena like flood and earthquake . A post can contain more than one sentence , and each of these may be associated with zero to several events . In a single post , it is possible that/IN one may describe who <<< he/she >>> travelled with , how he/she celebrated his/her birthday , and what he/she ate with his/her friends , summing up to three different events . Such posts are split into independent sentences to extract the individual event details and are represented in an event frame of the form : verb ("
117	2005_mtsummit_papers_39	"applicable , we define basic rules especially as the rules that cover the vocabulary and grammar of the middle-school English textbook used in China . It is reasonable because the words and grammar of the middleschool English textbook are assumed to be the basic knowledge a person should comprehend when <<< he/she >>> starts to learn English . Correspondingly , we define advanced rules as the rules regarding a variety of linguistic phenomena , which include comprehensive usage of words and some complicated structures beyond the middleschool English textbook . According to above definitions , basic rules should have higher priority than advanced"
118	2020_osact_1_6	"to inflict pain , injury , damage , or other hostile action on someone in retribution for something done or not done . "" "" 1 This definition highlights two main aspects : ( 1 ) the speaker ' s intention of committing an act , which ( 2 ) <<< he/she >>> believes to be unfavorable to the addressee ( Fraser , 1998 ) . We especially direct our primary attention to threats of physical harm . We build a new dataset for training machine learning classifiers to detect dangerous speech . Clearly , resulting models can be beneficial in protecting online"
119	I13_1049	"in example 2 , where the translation of the English pronouns ( he/she ) is same in Hindi ( both translate to Woh ) . The inflection on the axillary verb phrase ( raha hai / rahi hai ) is still being decided by the gender of the subject ( <<< he/she >>> ) . Even if a higher order language model is employed , the language model gives equal preference to both the translations as the information about the gender of the subject is completely absent in the Hindi translation . Hence , the information that/IN Woh corresponds to masculine in example"
120	W97_0809	"will have a different behavior when processing new texts . Within a particular rule , the user might expect one entity to be relatively specific and the other entity to be more general . For example , if a user is interested in finding all DCR Inc. related jobs , <<< he/she >>> might want to hold the first entity as specific as that/IN in rule 1 in figure 3 , and generalize the third entity . We have designed a Generalization Tree ( GT ) to control the generalization degree . The rule generalization process with the help of GT is illustrated"
121	2006_eamt_1_3	"and untranslated words due to their not appearing in the bilingual dictionary ( 10 % ) , non-agreement in gender or verbal person ( 4.3 % ) , and contraction and syntactic phonology errors such as de el instead of del ( of the ) or y hizo ( and <<< he/she >>> did ) instead of e hizo ( 0.7 % ) . Lastly , 4.3 % of the errors were varied and unsystematic errors . Table 1 shows some instances of MTness detected by the method . The correct translation for most of these instances has been found by selecting the"
122	I11_1167	"( Q2-5 ) Questioners resubmitted almost the same questions as they had . They did not mentioned any kinds of information received from answerers . For example , in ( Q 14 ) , the questioner did not mention any kinds of information described in ( A 14 ) although <<< he/she >>> selected ( A 14 ) as a best answer . ( Q 13 ) My optical mouse is faulty . The cursor sometimes freezes . Is it end of life ? ( A 13 ) Look the back side and remove dust gathered around the red light . ( Q"
123	W97_1503	"the issue of how the development of large grammars by different CLs can be properly supported by a LEADS . uniform environment where their contributions can be easily integrated . These results can be obtained if , at any time , the user can select all and only the functionalities <<< he/she >>> actually needs . A similar tension involves also linguistic data and processors . LERs want to see them as units that can be assembled to build the final architecture . PMs are inclined to consider the linguistic data as a unit , but see the processors as complex modules to"
124	W14_5119	"in a second language . As a pilot for our experiments and to present in this paper we have chosen the following Indian languages as second language : Kannada and Tamil . Any tourist or a visitor can benefit with this idea and can learn a good enough vocabulary when <<< he/she >>> visits a state where that particular language is spoken . The medium of learning is pictures , which prove to be more advantageous as a learner need not use first language to learn . We carefully chose a set of pictures of nouns and a set of pictures of verbs"
125	S17_2082	". For subtask B , it was clear that/IN only content and twitter features were useful . User based features did n't enhance the performance for the latter subtask , thus we conclude that/IN the identity and behavior of the user did n't affect much the credibility of the rumour <<< he/she >>> is spreading , at least for the data set provided . Future Work Additional features could be extracted that can play a better role in classifying each tweet or rumour . On the tweet text level , better linguistic features could be extracted . A better sentiment analysis model could"
126	2021_konvens_1_20	"( 1 ) most explicitly states that/IN the writer is in favor of it and the positive evaluation in ( 2 ) immediately gives rise to a pro relation of the writer towards liberalization . ( 3 ) expresses the need to have liberalization . This again points out that/IN <<< he/she >>> is in favor of liberalization . In ( 4 ) , prevent casts a con relation between its logical subject ( it ) and the theme role ( solution ) . A contra relation towards a positively connotated theme indicates a negative subject and suggests that/IN the writer stands in"
127	W16_3930	"their usage frequency . Twitter @mentions are used as a reference to another user and appears on the wall/notification page of that user . Similar to our use of the HASH feature set , the MENT feature set allows us to infer the location of a user based on who <<< he/she >>> is mentioning , e. g. , @7NewsMelbourne is the twitter username of a Melbourne-based news broadcaster . Combination of all the above ( ALL ) . A combination of the LIW , CC , HASH and MENT feature sets as a single feature set . Using these feature sets ,"
128	2022_udfestbr_1_6	"are manipulating the CoNLL-U files , they also can be hard to deal with . Particularly , problems might arise when users are trying to query a treebank . For example : if a user wanted to search for two consecutive words with specific part-of-speech tags in a treebank , <<< he/she >>> would not be able to do it easily , thanks to the fact that/IN treebanks are formatted in a table-like manner and that/IN the available search tools are not straightforward to use or to install . To help in this front , we present UDConcord , which is a concordancer"
129	C14_1117	"recognition algorithms to weed out automatically . However , we opted for a low-cost approach of allowing any guesser to mark a certain game round as cheating , if they find the drawer scribbling on the canvas . Any guesser can also mark a game round as cheating , if <<< he/she >>> finds the drawer concluding a game round with guesses that are not equivalent phrases . All guessers in a room other than the guesser who provided the accepted guess , are given three seconds to report cheating in case the guess was not found as a suitable equivalent phrase ."
130	2020_acl_main_405	"correlation for at least one dimension . Selection of the dimension-inducing words , dw , also has a limited effect . The one exception is when survey-matched words are used for the Gender dimension , where correlations drop by , on average , around 0.5 relative to the "" "" <<< he/she >>> "" "" baseline . The fact that/IN using the same words as the semantic differential scale is a terrible choice , but for only one of the seventeen dimensions studied , reflects the fact that/IN selection of dw , like elements of other forms of quantitative social science , remains"
131	2020_sigdial_1_11	"a standard to create and gather data more consistent with actual IVA usage and filter out some of the non-representative live chat data . We also wanted to investigate how the IVA was affecting conversations with live chat operators . While there are differences , a user behaves consistently when <<< he/she >>> is chatting with a human , similarly they are consistent when chatting with an IVA . In this paper we demonstrate that/IN chatting with an IVA has significant impact on language beyond what has been documented by human-tohuman computer mediated conversation such as instant messenger or live chat . The"
132	2020_lrec_1_701	"( to current situation ) and negative emotion ( to expectation ) with the word "" "" _""""(wait ) . From the first sentence we know that/IN the listener always ( at least , often ) take care of "" "" her "" "" , so it is obvious that/IN <<< he/she >>> does not want "" "" her to get hurt "" "" . Therefore , the clause X meet the condition . Then the contextual meaning turns to be "" "" you should be regretful when she gets hurt "" "" and the evaluation and sentiment of the sentence are negative"
133	H05_1126	"to be caused by following factors . 1 . ASR errors in user ' s uttered replies In the proposed strategy , the retrieval sentence is updated using the user ' s reply to the question regardless of ASR errors . Even when the user notices the ASR errors , <<< he/she >>> cannot correct them . Although it is possible to confirm them using ASR confidence measures , it makes dialogue more complicated . Hence , it was not implemented this time . 2 . User ' s misunderstanding of the system ' s questions Users sometimes misunderstood the system ' s"
134	W00_1012	"increasing B ' s belief of the usefulness of D for him/her , and the tactic of threatening consists in increasing B ' s understanding that/IN he/she must do D. Communicative tactics are directly related to the reasoning process of the partner . IrA is applying the tactics of enticement <<< he/she >>> should be able to imagine the reasoning process in B that is triggered by the input parameter wish . If B refuses to do D , then A should be able to guess at which point the reasoning of B went into the "" "" negative branch "" "" ,"
135	W12_4805	"number of candidates is really large . In order to solve these problems , we propose an integrated writing environment for ESL learners called phloat ( PHrase LOokup Assistant Tool ) . System Overview The proposed system works on a simple editor . Authors can write English sentences , as <<< he/she >>> does on a regular editor . Also , on top of English input , the author can type Romanized Japanese words when he/she does not know what to write in English . The system searches corresponding words in both languages , and displays the information in real-time . For example"
136	C04_1182	"the word with one that is phonologically similar . An interjection ( IJ ) is any word inserted into a sentence that is not in the original text ( e. g. , ' um ' or ' ah ' ) . Repetitions ( REP ) occur when the child realizes <<< he/she >>> has made a mistake and self corrects him/herself usually by repeating the misread word or by beginning the sentence over again . In some cases the child catches his/her error before finishing the word and thus creating a partial word , however , since it is a conscious act by"
137	N18_1186	"of the described models . This conversation is extracted from the test set . The three responses are different from the reference response , but the one from REASON looks the most consistent with the given context . The response from MULTI is contradicting the context of speaker B as <<< he/she >>> said Not at all in a former sentence . As it has been shown in ( Liu et al. , 2016 ) that/IN BLEU does n't correlate well with human judgments , we asked three human evaluators to respectively examine 900 responses from each of the models given their reference"
138	1987_tc_1_5	"of AITC ( International Association of Conference Translators ) , stated that/IN there seemed to be a difference of opinion where Mr Hayes had said desktop publishing was not for the translator and Mr Jones said it was . He wished to know how the translator would be compensated if <<< he/she >>> took over the typesetting function . Might there not be a tendency for the publisher to offload the editorial function onto the translator , making him/her responsible for translation over a wide area ? Mr Reisenberger , of Arrow Translations , said the translator should go towards electronic mail and"
139	2020_wnut_1_69	"the majority of its users wellinformed amidst a natural disaster or a pandemic like COVID-19 . One major advantage of sourcing information via social media is that/IN all information is updated in real-time . Any person with a social media account can post or share information instantly at the moment <<< he/she >>> witness a noteworthy event . This is a much faster way to obtain information compared to reading newspaper , watching the news on TV , or viewing other official source * Equal contribution with the first author of information since most tend to be updated only at mid-day or at"
140	C12_1024	example of a dialogue marked with the social acts . Agreement can act as an affordance to an individual or as a means to establish solidarity between individuals . Likewise disagreement can act as a way of undermining or challenging Agreement Statements that/IN a group member makes to indicate that/IN <<< he/she >>> shares the same view about something another member has said or done . Challenge Credibility Attempts to discredit or raise doubt about another group member ' s qualifications or abilities . Disagreement Statements a group member makes to indicate that he/she does not share the same view about something another
141	Y08_1038	"languages . Finally , although in this work we have built our training data from a collection of third person plural pronouns only , we notice that/IN our resulting algorithm should be capable of dealing with singular cases as well ( i. e. , "" "" ele/ela "" "" or <<< he/she >>> ) , and that should remain the case despite the fact that/IN some of our current features ( i. e. , those conveying semantic ' group ' information ) are unlikely to play a role in the resolution of these cases . To make this point clear , a separate"
142	W19_8714	"and the use of the best algorithms to accomplish the matching of bilingual terms . Objective indices such as Precision and Recall , F measures which are purely statistically based , would be upmost on his/her mind ( Mitkov , 2016 ( Mitkov , , 2017 ) ) . As <<< he/she >>> is in most cases unlikely to be knowledgeable with wide-ranging linguistic issues in both languages , he/she would be using the "" "" Happy Majority Approach "" "" whereby meeting the statistically significant requirements of the majority would be happily acceptable under normal circumstances . The professional translator demands much"
143	W12_1621	") in his/her image to the matcher , so that/IN the matcher would know which object has what name . As shown in Figure 1 , those secret names are displayed only on the director ' s screen but not the matcher ' s . Once the matcher believes that <<< he/she >>> correctly acquires the name of an target object , he/she will record the name by mouseclicking on the target and repeating the name . A task is considered complete when the matcher has recorded the names of all the target objects . Examples Consistent with previous findings ( Liu et"
144	F13_2012	"liens sémantiques , car le réseau est construit de manière automatique et à partir de textes non-annotés . Introduction Lexical choice is an obligatory step in language production . During this stage , the author ( speaker or writer ) has to select a word expressing the concept or idea <<< he/she >>> has in mind . Of course , before choosing a word , one must have accessed a set of words from which to choose . While writers may use an external resource ( dictionary ) in case of word finding problems , speakers always rely on the internal or mental"
145	D17_1204	"performance on the training and validation data relative to a Feature Description ANNOTA-TIONS From highest to lowest label , the five annotations for the instance . 5 AVG . R For each annotator , in order of label value , his/her avg . correlation with other workers across all instances <<< he/she >>> annotated . 5 AVG . R ( GOOD ) AVG . R in which each annotator is compared only to annotators with rj&gt;0.35 . If the annotator has no overlapping annotations with those , AVG . R is repeated . AVG . Average of the five ANNOTATIONS . WEIGHTED AVG"
146	D19_1199	"is better at capturing key information and has stronger robustness in difficult scenarios . Variance of Matching Scores . In real multiparty conversations , the utterances without addressee information can be divided into two cases . Sometimes an utterance has an explicit addressee while the speaker does n't specify whom <<< he/she >>> is speaking to . We denote these cases as NP which refers to NULL-Positive . Another case is that/IN the utterances do n't address to any user in the conversation ( denoted as NN which means Null-Negative ) , such as utterances ' Hi , everyone ! ' and '"
147	Y13_1035	"… . , "" "" thus the content of the tagged tweets should be the description on an event because the tag is just the revelation of the judgment from the tweeter . Namely , the speaker ' s intention revealed in the tag is his/her attitude to the event <<< he/she >>> perceives when he/she is the audience . The fourth question is that/IN Clift ( 1999 ) thinks sarcasm is one type of irony . The speaker may be or may be not aware of ironic utterance , but the/she must be aware of his/her sarcastic utterance . Thus , there"
148	1999_mtsummit_1_86	"him/her to know a part of speech in both Japanese and English , to produce a user ' s dictionary . So , how can this be expected of a user who does not know much about English grammar ? Probably he/she would claim that/IN this is the reason why <<< he/she >>> bought this MT package . If they do , they would not need to use MT . The guidance is needed for a user to create a user ' s dictionary . Also , it has to be pointed out that native Japanese engineers do not necessarily have the sufficient"
149	W10_4116	"careful tuning of domain and data specific parameters , and hence unsuitable for online and real-time sentiment analysis in practical applications . Incorporating Prior Word Polarity Knowledge into LDA Unlike existing approaches , we view sentiment classification as a generative problem that/IN when an author writes a review document , <<< he/she >>> first decides on the overall sentiment or polarity ( positive , negative , or neutral ) of a document , then for each sentiment , decides on the words to be used . We use LDA to model a mixture of only three topics or sentiment labels , i. e."
150	Y12_1024	"Tagalog and English words and clauses , while intra-word CS is the use of English root words with Tagalog affixes and morphological rules . An example of intra-sentential CS is "" "" Unless let us say may mga bisita siya "" "" ( translated as : Unless let us say <<< he/she >>> has visitors ) and an example of intra-word CS is "" "" nagdadrive "" "" ( incompeleted aspect of the English verb "" "" drive "" "" ) . The system developed can effectively be used to detect intra-sentential ( Tagalog to English and English to Tagalog ) and intra-word"
151	N16_1166	"we refer to such cues as external emotion cues . For each speaker in a debate , we computed the number of i ) applauses ( APL ) ; ii ) booings ( BOO ) ; iii ) laughs ( LAU ) ; and iv ) crosstalks ( CRO ) <<< he/she >>> received during his/her participation on a debate . These counts were normalised based on the total number of each emotion appeared on the debate . With these features , we train a supervised learning classifier for ranking speakers of the debates based on their influence indices described in the following"
152	Y99_1029	"One , a subject can appear on the right side of its predicate if the sentence contains an adnoun clause . The other , a subject may usually be omitted in Korean as shown below . ( 5 ) Moluntayyo . not . know . say ` He/She said that/IN <<< he/she >>> did not know . ' In ordinary English sentences , only the elements of an utterance that may be recovered readily from the syntactic structure can be omitted . In Korean , however , there is a zero anaphor as in ( 5 ) , which is an unmarked discourse"
153	L18_1076	"reliable and successfully measures the vocabulary ability of language learners . We also measured how well the responses from the learners can be predicted with high accuracy using machine-learning methods . Introduction Supporting someone involves enabling him/her is overcoming a difficulty . Thus , we first need to detect what <<< he/she >>> has difficulty with . This holds true for supporting second language learners : we first need to detect what they have difficulty with ( Ehara et al. , 2010 ; Ehara et al. , 2012 ; Ehara et al. , 2013 ; Ehara et al. , 2014 ; Ehara et"
154	L18_1076	"a specific models . However , a twoparameter model ( 2PL ) and one-parameter model ( 1PL ) are frequently used for analysis . With both models , it is assumed that/IN each problem is independent : whether a test taker answered a problem correctly has no influence on whether <<< he/she >>> answered the other problems correctly . The 1PL is sometimes called the Rasch model ( Rasch , 1960 ) . The 2PL is a generalization of 1PL . It models the probability that/IN test taker i correctly responds to a problem j in the following equation . Let σ denote"
155	2005_eamt_1_35	"confidence based rejection . The value of the confidence scaling factor is set to 0.8 which is optimal with respect to F pred as the results presented in figure 1 show . The part of the translation that has been accepted by the user -together with the following character that/IN <<< he/she >>> has entered -is taken as prefix for the new search . The upper part of the table shows the steps that are necessary if none of the words proposed by the SMT engine is discarded , and the lower part shows the translations that are proposed when the confidence threshold"
156	Y15_1038	"gesture is examined . The Lexical Semantic Hypothesis stands for the view that/IN the relevant linguistic unit to affect the content of a gesture is a single word , because gesture can help lexical search . If a person has difficulty to find a lexical item for a concept , <<< he/she >>> may produce a gesture to represent the idea . The production of such a gesture then helps the person utter the word for that concept in language . Thus , gestures are thought to be dominated by the computational stage in which a lexical item is selected from a semantically"
157	2020_lrec_1_649	"information : • Is the verb often used in active and/or passive voice ? • Are object slots optional or not ? If one inspects the words filling a certain slot , information about the words can be found : • Animate or inanimate nouns : What are typical pronouns <<< he/she >>> or it ? • Semantic class for nouns : What are typical features of the nouns in a fixed position ? For example : From a set containing sentences like "" "" He always drinks coffee . "" "" and "" "" She never drinks alcohol . "" "" one"
158	W16_3640	"for utterances with a particular dialogue act . For example , if one dialogue participant tends to say a specific backchannel frequently , the partner may change to use the same backchannel . On the other hand , when one dialogue participant has his/her own answer for a question , <<< he/she >>> will likely not borrow the words from the partner . In order to examine this effect , we extended the entrainment score for lexical selection to evaluate an entrainment of lexical selection given the dialogue act of the utterance . The extended entrainment score En(c|d ) , the score for"
159	W04_1112	"if a certain simple word , say N , expresses the basic concept of a domain that/IN the document treats , the writer of the document , we expect , uses N not only many times but in various ways . One of typical way of this kind is that/IN <<< he/she >>> composes quite a few compound words using N and uses these compound words in documents he/she writes . For this reason , we have to focus on the relation among simple words and compound words when pursuing new ATR methods . One of the attempts to make use of this"
160	2021_acl_long_343	"conversations where the underlying knowledge comes from wiki articles and focuses on the movie domain . Similar to Dinan et al. ( 2019 ) , the dataset was also built in two scenarios . In the first scenario , only one worker can access the provided knowledge collections , and <<< he/she >>> is responsible for introducing the movie to the other worker ; while in the second scenario , both workers know the knowledge and they are asked to discuss the content . Different from WoW , the golden knowledge index for each turn is unknown for both scenarios . Since the"
161	2016_lilt_14_5	") , its target , the source of the event mention ( speaker or writer ) and the source of the modality . The source of the event mention and the source of the modality are in many cases the same entity : the speaker/writer produces a discourse/text unit where <<< he/she >>> states his/her belief or doubt or the possibility that/IN something may happen . However , they may also be different entities when the text presents the views of someone else than its producer . The annotation was performed over each trigger , and not over the global interpretation of the"
162	W14_4104	", 2012 ) . Since user reputation score information is not available in this MOOC , it is necessary to for us to identify observable indicators . We define a person as Expert x Exp in our forum as follows . A person is an Expert if and only if <<< he/she >>> is one of the instructors or his/her reputation score as we compute it is ranked in the top 1 % among all students . The reputation score of student u is computed based on his/her question devotee u P st , reply devotee u Rep , resolved favor u Res"
163	W04_1501	"useful for underspecifying relations both in automatic analysis of the treebank ( i. e. we can automatically exclude the analysis of a specific component of the relations ) and in the annotation process ( i. e. when the annotator is not confident of a specific component of a relation , <<< he/she >>> can leave such a component void ) . In the figure 3 we see a TUT tree . All the relations annotated in the tree include the morpho-syntactic component , formed by the morphological categories of the words involved in the relation separated by a comma , e. g. VERB"
164	2021_dialdoc_1_15	"quickly and a bot must respond appropriately to new topics , goals and questions from the scammer to appear human 3 ) there is a high cost associated with the scammer recognizing the dialogue is automated as any work put in for trust building is lost if the attacker suspects <<< he/she >>> is talking to a bot and 4 ) the scammer ' s agenda is independent of the bot ' s agenda-thus the bot needs to maintain awareness of its own goals without ignoring the competing goals of the scammer . Using "" "" canned "" "" responses chosen by following"
165	2020_emnlp_main_67	"diverse , and more similar to the spoken conversations in our daily life . According to the instructions described in the given dialogue goal , the user should provide specific constraints to the system step by step and request the corresponding information . The user can terminate the dialogue when <<< he/she >>> believes the task has been accomplished . System Side The worker who plays the role of system ( i. e. wizard ) provides consulting services in various domains to users . When receiving an utterance from the user side , the wizard needs to first determine which domain the user"
166	Y13_1035	"  thus the content of the tagged tweets should be the description on an event because the tag is just the revelation of the judgment from the tweeter . Namely , the speaker ' s intention revealed in the tag is his/her attitude to the event he/she perceives when <<< he/she >>> is the audience . The fourth question is that/IN Clift ( 1999 ) thinks sarcasm is one type of irony . The speaker may be or may be not aware of ironic utterance , but the/she must be aware of his/her sarcastic utterance . Thus , there should be overlapped"
167	W14_2514	"this paper , we investigate how topic dynamics during the course of an interaction correlate with the power differences between its participants . We perform this study on the US presidential debates and show that/IN a candidate ' s power , modeled after their poll scores , affects how often <<< he/she >>> attempts to shift topics and whether he/she succeeds . We ensure the validity of topic shifts by confirming , through a simple but effective method , that/IN the turns that/IN shift topics provide substantive topical content to the interaction . In this paper , we investigate how topic dynamics during"
168	Y00_1011	"relating to ' accessibility ' among situations . It is possible for passenger , to get through the west gate . ( ii ) It is possible for passenger , to get through the east gate . ( iii ) It is possible for passenger , to choose whichever gate <<< he/she >>> likes , the west gate or the east gate , in order to get to the arrival lobby . ( iv ) It is necessary for passenger , to choose one from among the west gate and the east gate in order to actualize the event of getting to the"
169	C14_1172	"to a feminine pronoun . This possibility of referring to both the gender introduces more errors . In Hindi , most of the pronouns such as "" "" vaha "" "" ( he/she/it ) , "" "" usa "" "" ( he/she/it ) , "" "" unhone "" "" ( <<< he/she >>> honorofic ) and "" "" khuda "" "" ( himself ) etc. , do not have gender distinction and can be used to refer to antecedents of both feminine and masculine . PNG agreement adds more challenges in anaphora resolution , due to which the system gives more false positives"
170	W00_1011	"or the concept associated With the sub-goal within the expected period of time . The hypothesis is that/IN when a user has no problem of understanding a system instruction , the user is very likely to respond to the system rapidly . However , when the user has difficulties , <<< he/she >>> tends to spend more time on thinking and asking for help . There are two timeouts : best-case and worst-case . Each timeout has a reward and a punishment . Best-case time is the time expected by the system , in the best ease , that/IN a user would take"
171	C88_2135	"a word . The subjects were also told that/IN the materials that/IN they had were independent from each other . At the same time , the subjects were required to record the time when he/she start to fill out each paper , i. e. , one material , and when <<< he/she >>> completed , for each paper , to the unit of seconds . Results Completed sheets , expect for one by a subject who gave up the procedure in the middle are analyzed . Whether the word filled in matched the original or not was judged according to /Shiba 1957/ ."
172	Y18_1077	"and earthquake . A post can contain more than one sentence , and each of these may be associated with zero to several events . In a single post , it is possible that/IN one may describe who he/she travelled with , how he/she celebrated his/her birthday , and what <<< he/she >>> ate with his/her friends , summing up to three different events . Such posts are split into independent sentences to extract the individual event details and are represented in an event frame of the form : verb ( doer , object , tagged , date , location ) Gathering Storytelling"
173	W98_0509	"have higher grades ( i. e. , 0 &lt; ~b(e ) &lt; 1 ) and thus may be violated by a solution . 3 =The restriction to at most binary constraints does not decrease the theoretical expressiveness of the formalism but has some practical consequences for the grammar writer as <<< he/she >>> occasionally has to adopt rather artificial constructs for the description of some linguistic phenomena ( Menzel and SchrSder , 1998 ) . 3Constraints c with ~b(c ) = 1.0 are totally ineffective as will become clear in the next paragraphs . Given a natural language sentence W = ( wl"
174	W19_1918	"use partof-speech tagging from python module spaCy to identify the subject , main verb and the auxiliary verb(s ) of the sentences . If the subject is a first ( I ) or second person ( you ) , the subject is replaced with the third person singular form ( <<< he/she >>> ) . Clinicians typically collect personal information , such as name , gender and contact information , prior to their conversation or appointment and so they can be fed into our model as input to generate accurate case notes . No. Example Class Label 1 How many voices do you"
175	W19_5017	"entry of the lexicon . We used a python script that relies on the lexicon of a Spanish Part-of-Speech tagger ( Moreno Sandoval and Guirao , 2006 ) to generate all conjugated forms of verb terms : e. g. toser ( ' to cough ' ) → tose ( ' <<< he/she >>> coughs ' ) , tosiendo ( ' coughing ' ) , etc. The current version includes a total of 295 single-or multi-word verb items . Affixes and lexical roots In a first step , we collected affixes and roots from several sources . Firstly , we leveraged a list used"
176	2022_udfestbr_1_6	"and the head field values from each row are automatically adjusted . When the user finished the editing on the CoNLL-U file , he/she just have to press the button labeled "" "" Save changes "" "" ( at the bottom right ) to save their changes . Then , <<< he/she >>> can go back to the results page by clicking on the button labeled "" "" Go back "" "" ( also at the bottom right ) . Downloading the Edited Corpus UDConcord offers several options to download an uploaded treebank after the user made changes to it . These options"
177	W16_3707	"captured in the respective TL . He must know any of the meta-languages to appreciate the animation . Finally , the output has to be annotated in any natural TL text considering especially the verbs and their valences . One thing an annotator has to keep in account is that/IN <<< he/she >>> is to annotate the verbs in the present imperfective participle form . The arguments of the verbs especially the nomenclature for the human agent has to be specified as according to the commonly occurring named entities of the given output language . For the time being , the process of"
178	Y15_1007	"participant must correctly answer the first two Chinese character identification questions in the section 2s of the questionnaires , and he/she must correctly answer at least one of the last two questions in these section 2s ; ( 2 ) If a participant do not satisfy the above conditions , <<< he/she >>> will not see Section 3s ; ( 3 ) each word stimulus in section 3s has an option which allows the participants to skip it in case he/she does not recognize that word ; ( 4 ) all the questions in the questionnaires must be answered except the ones which"
179	2020_acl_main_115	"the front of verbs and adjectives but not to nouns . Meta-linguistic awareness is especially useful ( and often improved ) in the process of learning a new language , as it allows the learner to compare and contrast the structure and characteristics of the new language to those that/IN <<< he/she >>> is already familiar with . It is desirable that/IN systems for natural language processing possess meta-linguistic awareness , too , as that could hugely improve their crosslingual generalizability , a problem that remains open after being approached from various engineering perspectives , often with little recourse to linguistics . However"
180	W03_2128	"questioner has adjusted it the answerer will be able to give the needed information or point to its absence . There are four adjusting possibilities in Estonian dialogues . The most frequently used possibility is that/IN the answerer asks the questioner to adjust the previous question . In this case <<< he/she >>> reacts to a general request by using particles ( jaa , jah /yes/ etc. ) . Such reaction is marked as a continuer ( example 6 ) . The second possibility is that/IN the answerer asks adjustable questions himself/herself . Such act is called adjusting the conditions of the answer"
181	W13_4046	"of non-linguistic items such as HTML codes for URLS , emoticons , IP addresses , etc. These elements were replaced by wild-cards and also user names have been anonymised , although some non-language content may remain . A forum user can give a post "" "" kudos "" "" if <<< he/she >>> finds it useful or relevant to the topic being addressed in a forum conversation . 2 We counted the number of kudos given to each post . There are four user categories in the forum : { employee , guru , notranked , ranked } . 3 A poster '"
182	2000_tc_1_1	"speaker 2 information at term or language this code is system-imposed and level was entered by a native can only be upgraded by an speaker authorised user 3 information at term or language is this code has been given by an well-documented , the code having authorised user , when <<< he/she >>> is been upgraded confident that/IN the information is well documented During data entry , the system will provide a default value of 2 if the language of the entry matches the target language(s ) of the author , otherwise 1 . When a term or concept has been marked for"
183	Y13_1035	" aggressiveness  "" has been pointed out from Clift as well as Lee and Katz to be the feature distinguishes sarcasm from irony . Hence , it should be reasonable to hypothesize that irony should have two senses . In one sense , the speaker is aware of what <<< he/she >>> says is opposite to what is intended to mean . The second sense is to be distinct from sarcasm in being not aggressive and without awareness . The Reason to Take Twitter as the study target : Current study is going to explore the characteristics of sarcasm and irony from"
184	W16_6617	"experienced __(place1)_ , _(place2)_ , _(place3)_ , and _(place4)_ . About _(evaluator 1)_ , _(name of the author)_ like because he/she thinks that/IN it is _(evaluative pattern 1)_ , particularly _(part of evaluator 1)_ is worth trying . In addition , he/ she also went to _(evaluator 2)_ , and <<< he/she >>> recommended it because of_(evaluative pattern 2)_ . Among that , _(part of evaluator 2 )_ is the most recommended one . … In short , the identification of evaluative patterns in texts , as inspired by usage-based linguistic pattern grammar theory , can be utilized as a key feature for"
185	Y18_1016	"d like to look at varying the attention mechanism in the model , and evaluating how it performs with a larger training set . "" Too Many Questions ? What Can We Do ? : Multiple Question Span Detection When a human interacts with an information retrieval chat bot , <<< he/she >>> can ask multiple questions at the same time . Current question answering systems ca n't handle this scenario effectively . In this paper we propose an approach to identify question spans in a given utterance , by posing this as a sequence labeling problem . The model is trained and"
186	W16_3601	"shows a summary . Attribute Q a Example Question Birthday 3 Was he/she born before 1950 ? Birthplace 9 Was he/she born in USA ? Degree 4 Does he/she have a PhD ? Gender 2 Is this person male ? Profession 8 Is he/she an artist ? Nationality 5 Is <<< he/she >>> a citizen of an Asian country ? Table 1 : Summary of the available questions . Q a is the number of questions for attribute a. At the beginning of each game , the simulator will first uniformly sample a person from the database as the person it is thinking"
187	2020_coling_main_446	"overall performance will decrease after debiasing . Our expectation here is to cause less damage to the model performance after debiasing . Results Debiasing Results Table 2 gives results on OCCTMP . We show that/IN DensRay can mitigate gender bias in BERT as measured by diff : bias between predicting <<< he/she >>> drops by a large margin ( e. g. , for bert-base from 1.98 to 0.36 ) . The table indicates that/IN DensRay outperforms the other two methods on OCCTMP . Note that/IN the prediction probabilities of debiasing conceptor are quite low for both "" "" he "" "" and """
188	W10_1303	"is a slot-filler and that/IN other options for filling that slot are available . To edit that text , the user clicks on the highlighted word in the display window , and a window such as that in Figure 4 is displayed . The user may then select the filler <<< he/she >>> desires , and it will replace "" "" nachos "" "" in the display . The system described is currently being implemented . Yet to be integrated is a facility that will enable more extensive editing of the text in the display window and the specifics of easy access to"
189	C96_1063	"to determine if one conversant was accommodating more than the other , we examined the number of words used first by the client and the number used first by the agent . We reasoned that/IN the subject who used a particular lexical 1At no time did any subject doubt that/IN <<< he/she >>> was interacting with an actual machine translator . In each experiment , subjects interacted in two modes : via a standard telephone , and via a computer-based , multimedia environment in which subjects could interact by voice , text , and drawing ( Loken-Kim et al. , 1993 ) ."
190	W00_1011	"or the concept associated With the sub-goal within the expected period of time . The hypothesis is that/IN when a user has no problem of understanding a system instruction , the user is very likely to respond to the system rapidly . However , when the user has difficulties , <<< he/she >>> tends to spend more time on thinking and asking for help . There are two timeouts : best-case and worst-case . Each timeout has a reward and a punishment . Best-case time is the time expected by the system , in the best ease , that/IN a user would take"
191	P08_2004	"the popularity of a movie such as movie ratings and box office performance . In applications requiring certain level of language-understanding , things can get even more complicated while different dimensions weave together . As in sentence ( 5 ) , the speaker may bias towards the blue team while <<< he/she >>> shows uncertainty towards the red team . Correctly understanding this kind of subjective statements would probably need some investigation in different dimensions of subjectivity . Conclusion In this paper , we demonstrated that subjectivity in natural language is a complex phenomenon that contains multiple dimensions including non-objectivity , uncertainty ,"
192	D14_1211	", boolean features denoting whether p added or removed people when responding to a message ( AddPerson and RemovePerson ) , average number of replies received per message sent by p ( ReplyRate ) and average number of replies received from the other person of the pair to messages where <<< he/she >>> was a To recipient ( ReplyRateWithinPair ) . ReplyRate-WithinPair applies only to IM t ( p 1 , p 2 ) . DIA : We use dialog acts ( DA ) and overt displays of power ( ODP ) tags to model the structure of interactions within the message content"
193	C98_2158	"our common sense that/IN one person cannot move along two different paths at the same time , which implys that/IN the two movements by a person must be sequential . This prototype is extended so as to cover such situations as "" "" someone goes to somewhere , and then <<< he/she >>> does something/becomes something/stays there "" "" or "" "" someone does something/become something/stays somewhere , and then he/she goes to elsewhere . "" "" They are expressed by vertical and horizontal extensions of the prototype in Table 2 . The movements involved in these situations are locational and the other"
194	2020_ai4hi_1_3	"  an inescapable aspect of image production "" "" ( Chadwick , 2015 , p. 17 ) . In practical terms , this means that/IN a painter in the mainstream is inspired by the work of those who had gone before him/her but the artist is not conscious that/IN <<< he/she >>> is "" "" imitating "" "" another work of art . In contrast , there is the art created outside the boundaries of official culture or "" "" Anti-cultural art "" "" as described by Jean Dubuffet in 1949 . The condition of "" "" non-traditional "" "" or ,"
195	2015_mtsummit_users_19	"be automatically replaced with "" "" CPU Operating Condition "" "" . After that , when the other translators face the pushed translation , he/she can accept it or revise it according to the context . If a translator finds that/IN the pushed translation is wrong or problematic , then <<< he/she >>> can also tell its original translator or discuss with him/her to find out the best decision . We prepared a document of 1,000 characters containing repetitive and similar sentences and divided the translators into two groups ( 18 in each ) . Every translator is asked to translate the whole"
196	2013_tc_1_1	"was found when we asked them if they would recommend that/IN the lecturers continue including this evaluation method in the forthcoming MT course : 13 agreed , 1 strongly agreed , 3 neither agreed nor disagreed , 5 disagreed and 1 strongly disagreed . One of the respondents added that/IN <<< he/she >>> thought that/IN "" "" [ it ] was very useful in helping us select which software to purchase for our future careers . "" "" To sum up , we can state that/IN , in terms of the difficulty of the implementation of the EAGLES method , although there was"
197	W16_3646	"roll a confectionery or a one-dish meal ? "" "" can be asked . This is because the top estimation result is not always correct . In addition , n-ary questions are sometimes easy to understand because the user does not know the list of food groups in advance and <<< he/she >>> may not understand what shushoku really means . How many candidates are used in the question is decided based on posterior probabilities but we omit the detailed explanation because it is not really related to the main topic of this paper . The dialogue management for acquiring the group of"
198	2021_naacl_main_305	". Limitations . While the core idea about the double perturbation framework is general , in §4 , we consider only binary gender in the analysis of counterfactual fairness due to the restriction of the English corpus we used , which only have words associated with binary gender such as <<< he/she >>> , waiter/waitress , etc. A Supplemental Material A.1 Random Baseline To validate the effectiveness of minimizing Eq. ( 4 ) , we also experiment on a second-order baseline that constructs vulnerable examples by randomly replacing up to 6 words . We use the same masked language model and threshold as"
199	2021_konvens_1_20	"in general . He/She cares about their situation . Also , she/he is against the mentioned liberalization , which is not explicitly stated but inferred . ( 2 ) is a response to the following question : Should the government be more committed to equal educational opportunities ? Only if <<< he/she >>> is in favor of education , the answer can be understood as an approval : education must be one of his/her values . However , there is no pro nor con relation with respect to income . The question underlying the answer in ( 3 ) is : Should the"
200	2020_lrec_1_736	"animal is identified with a name ( seagull , black dog , cow , etc. ) . This task was inspired by a LSF lesson for beginners . It provides a natural and authentic flow of LSF utterances . Transfers of person in which the signer impersonates the character that/IN <<< he/she >>> is talking about ( Sallandre and Cuxac , 2001 ) are numerous in such descriptions as the signer will naturally imitate the animal he is describing . In addition , the resulting production contains various different hand configurations , placements and types of motion . At last , the fourth"
201	W12_5022	"as follows -section 2 discusses functional requirements of IWAPI , section 3 presents the architecture and design of IWAPI . The implementation details of IWAPI are presented in section 4 . Section 5 presents the conclusion . Functional Requirements Users often have to rely on others to perform functions that/IN <<< he/she >>> may not be able or permitted to do by themselves . Similarly , virtually all software has to request other software to do some things for it . To accomplish this , the asking program uses a set of standardized requests , called application programming interfaces that have been defined"
202	W16_4914	"about what errors were made : in this case the system can output a message prompting the student about the error made . The error tags will be added to the Learner Corpus , and the student will be asked to submit a new solution to the same problem until <<< he/she >>> can solve it ; or • there is ambiguity in the student ' s intended meaning , and different mal-rules that convey different meanings were triggered : in this case the system ca n't immediately output where the student made a mistake without first finding the intended meaning . In"
203	2021_acl_long_314	"missing some reasonings . Weaknesses : The student thinks from the peer ' s perspective and what would help him/her to further succeed with the task . This could be demonstrated by stating various questions and establishing further thoughts . The student explains the weakness and adds examples , but <<< he/she >>> is still missing some reasonings . Suggestions for improvement : The student suggests one or more improvements that are relevant for the further establishment of the activity and idea from the perspective of the peer . Most suggestions are written concretely and , if applicable , supported by examples ."
204	Y13_1035	"express from speaker ' s angle . The speakers tend to use more positive tweets to convey sarcasm , but more natural tweets to convey irony . Second , based on the underlying mechanism of sarcasm and irony , there is a divergence between what the speaker said and what <<< he/she >>> intended to mean , thus the positive words used in tweets seems to represent the aggressive intention . It has shown that/IN sarcasm is more aggressive than irony from speakers ' natural language performance . This result corresponds to the study on hearers ' comprehension conducted by Lee and Katz"
205	E89_1004	"about real world events as true ( the sincerity condition ) . Moreover , we take it for granted that/IN the user is highly interested in a consultation dialog and , therefore , will pay attention to the conversation on the screen so that/IN it can be reasonably assumed that/IN <<< he/she >>> is fully aware of all utterances occurring in the course of the dialog . Based on these ( implicit ) expectations , the following ( simplified ) assumptions ( 1 ) and ( 2 ) represent the starting point for a consultation dialog : ( 1 ) ( BELIEVE SYSTEM"
206	E12_1069	"the nouns they modify in gender and number except for plural irrational ( non-human ) nouns , which always take feminine singular adjectives . Rationality ( ' humanness ' ' / ' ) is a morpho-lexical feature that is narrower than animacy . English expresses it mainly in pronouns ( <<< he/she >>> vs. it ) and relativizers ( men who ... vs. cars/cows which ... ) . We follow the convention by Alkuhlani and Habash ( 2011 ) who specify rationality as part of the functional features of the word . The values of this feature are : rational ( R )"
207	2000_amta_workshop_3	"blanks . If the learner does not know the meaning of a synonym , he/she can ask the MT program for help as all the verbs of the list of synonyms are stored in the electronic dictionary . If the learner can guess the meaning of the phrasal verb after <<< he/she >>> has analyzed the translation of the illustrative sentences performed by the program , he/she chooses the synonym deliberately . Then the learner finds a suitable context , fills in the blank and asks the program for translation to make sure that his/ her choice is correct . If the learner"
208	W01_1202	"fast enough to be negligible . The IR system shows some sentences including query terms to a user . However , the total system shows the sentences including answer candidates to a user . This function helps the user get out of the trouble that/IN the user might experience when <<< he/she >>> looks through the whole document in order to find the answer phrase . # of answers 1 : the number of answers which are ranked at top n by using the IR system # of answers 2 : the number of answers which are ranked at top n by using"
209	2017_mtsummit_commercial_13	"MT has been introduced , contradicting quantitative measurements that recorded increased speed , has been seen elsewhere by Plitt and Masselot ( 2010 ) and Gaspari et al. ( 2014 ) . When compared to their actual productivity times , we note that/IN apart from ES1 regarding TD ( where <<< he/she >>> is least productive ) , the other participants perceive it differently from the actual numbers . Table 7 below shows the perceived productivity against the actual productivity , where l/L = least , m/M = most , lowercase letters are for the perceived productivity and capital letters for the actual"
210	W14_5403	"These studies rely on suitable training data for a set of predefined actions : ( Gupta et al. , 2009 ) tests on a 6 sport action dataset , ( Yao and Li , 2010 ) attempts to distinguish images where a human plays a musical instrument from images where <<< he/she >>> does not , ( Delaitre et al. , 2010 ) classifies images to one of the seven every day actions , and ( Yao et al. , 2011 ) introduces a dataset containing 40 human actions . Most of these datasets were obtained using web search results such as Google"
211	E89_1021	"of a request for explanation from the user . At the next level , the system expects the user to speak about another parameter of the same plan ( the amount ) . At the level still further below , he/she can speak about the emergency fund in general , <<< he/she >>> can for example refuse the emergency fund , or ask for explanation on it . And so on , until the system reaches the most unexpected reactions of the user , i. e. , even things that are not related to the investment problem . ( in the level """
212	W17_7555	"respectable , honorable , graceful , disgraceful , cruel , selfish but the readers do need to understand them and why they act the way they do in the texts . A character , being a protagonist , is commonly on the good side while the antagonist is the one <<< he/she >>> fights or has conflicts within the story . In the stories , Characters may have dialogues , actions which influence the plot of the texts , emotions etc. They respond to events and other characters through what they say or do n't say , what they do and do n't"
213	W16_1714	"see ' is inflected for past tense , while the copula is in present tense . Furthermore , the subject of the copula is o ' he/she ' , while the subject of the verb gör is biz ' we ' . ( 2 ) Biz We . PRON o-nun <<< he/she >>> . PRON-Gen rüya-sı-nda dream . NOUN-P3S-Loc gör-dügü•yüz see . VERB-Past-3Sg•VERB-Cop-1Pl ' We are the ones that/IN he/she saw in his/her dream ' We segment words before productive uses of all of the suffixes listed in this section . However , we do not segment words if they are lexicalised ."
214	C04_1023	"from this view point . These revised OB-P phrases without optional phrase are recorded as candidates of "" "" simple "" "" title for future selection in step 4 . At the end of step 2 , for future revision in step 3 , the user selects one title that <<< he/she >>> deems the better one from these candidates of title . Revising the Optional Phrases In step 3 , the wizard presents new title combining OB-P phrase ( selected at the end of step 2 ) and the OP-P phrase ( inputted in step 1 ) as a draft title ."
215	W14_2625	"Martins and Shapiro , 1983 ; Rapaport , 1986 ; Slator and Wilks , 1987 ) . Other than private states of the writer , all propositions and events must be the target of some private state . In the simplest case , the writer believes the proposition or event <<< he/she >>> describes in the document , so the proposition or event is nested under a writer positive believesTrue node . We want to carry out inferences within private state spaces so that/IN , for example , from S positive believesTrue P , & P =⇒ Q , the system may infer"
216	S16_1136	"is long and the answer is short , it may be less relevant . The answer ' s author is the same as the corresponding question ' s author . If the answer is posted by the same user who posted the question and it is relevant , why has <<< he/she >>> asked the question in the first place ? Answer rank in the thread . Earlier answers could be posted by users who visit the forum more often , and they may have read more similar questions and answers . Moreover , discussion in the forum tends to diverge from the"
217	W14_0210	"what is the difference between instructions of navigation application and reality . After the beginning the dialog continues by iterative searching of unique navigation points that may help the navigator to find the position and orientation of the lost blind person , until he/she gets to the location from which <<< he/she >>> can continue with the track . The dialog system should take into account following findings about the dialog structure . When the blind person get lost , he/she uses information , provided by navigation application for sections that seemed to him/her correct and corresponding with reality , for description of"
218	2021_findings_emnlp_352	"refer to the genre but describes a specific character . Distinguishing such differences would demand a more nuanced rule-based Acknowledgments We thank Taylor Berg-Kirkpatrick , Jianmo Ni , Yuheng Zhi , and anonymous reviewers for their valuable suggestions to this work . Our Reference Sensitive Attr . Rules Gender Replace <<< he/she >>> → they , his/him/her/hers → them/their , boy/girl → person Delete Mr. , Ms. , Miss , Mrs. Replace chairman/chairwoman→ chair , actor/actress → actor , freshman → first-year student ... Nationality Delete country/city/nationality names , e. g. , China/Chinese , America/American , India/Indian , Taiwan . A.4.2 Hyperparamters We"
219	2020_ecnlp_1_4	"rich resource of communication data . A large number of calls are recorded daily in order to assess the quality of interactions between CSRs and customers . Learning the sentiment expressions from well-trained CSRs during communication can help AI understand not only what the user says , but also how <<< he/she >>> says it so that/IN the interaction feels more human . In this paper , we target and use real-world data -service calls , which poses additional challenges with respect to the artificial datasets that have been typically used in the past in multimodal sentiment researches ( Cambria et al. ,"
220	2022_findings_acl_83	"medical keywords and hashtags . Each message was labeled for medical self-disclosure . The assigned labels ranged from 0 ( ' no self-disclosure ' ) to 5 ( ' high self-disclosure ' ) . The label ' 5 ' was given for instances were the post writer specifically mentioned that/IN <<< he/she >>> was diagnosed with a specific illness , was taking specific medication , had undergone surgery or was about to have one , or other cases of disclosing specific medical indicators . OffMyChest data set ( OffChe ) Jaidka et al. ( 2020 ) collected the OffMyChest conversations data by letting"
221	W10_1809	"not generic at all . Further , despite the above reference to quantification , the authors seem to separate genericity and universal quantification as two antithetical phenomena , as shown by the following quote : "" "" Even if the author may intend to use a GEN reading , if <<< he/she >>> refers to all members of the set rather than the set itself , use the SPC tag "" "" . The GNOME annotation scheme is closer in essence to the literature on genericity and much more detailed than the ACE guidelines . However , the scheme distinguishes only between generic"
222	E93_1037	"any head at all : ( 11 ) 01&lt;i&gt; 02&lt;j&gt; seki wo uzutte ageta node , seat ace give favor because 01&lt;/&gt; 02&lt;j&gt; orei -wo iwar eta . 01&lt;i&gt; thanks ace say pass chotto terekusa katta slightly embarassed cop Because he/she gave him/her a favor of giving a seat , <<< he/she >>> thanked him/her , who was slightly embarrassed . The speaker of 11 , or watashi I would be the most likely antecedent for the elided subjects here ; whoever gave the favor was thanked for the kindness . Let us say that/IN a discourse is headed if each of its"
223	W15_3001	"before this one . Task 3 : Predicting document-level quality Predicting the quality of units larger than sentences can be useful in many scenarios . For example , consider a user searching for information about a product on the web . The user can only find reviews in German but <<< he/she >>> does not speak the language , so he/she uses an MT system to translate the reviews into English . In this case , predictions on the quality of individual sentences in a translated review are not as informative as predictions on the quality of the entire review . With the"
224	P11_2058	"model for listener backchannel . Computational Model : Wisdom-LMDE The goals of our computational model are to automatically discover the prototypical patterns of backchannel feedback and learn the dynamic between these patterns . This will allow the computational model to accurately predict the responses of a new listener even if <<< he/she >>> changes her backchannel patterns in the middle of the interaction . It will also improve generalization by allowing mixtures of these prototypical patterns . To achieve these goals , we propose a variant of the Latent Mixture of Discriminative Experts ( Ozkan et al. , 2010 ) which takes full"
225	W17_5033	"sentence forms to do so . C1 Has a good command of a broad range of language allowing him/her to select a formulation to express him/ herself clearly in an appropriate style on a wide range of general , academic , professional or leisure topics without having to restrict what <<< he/she >>> wants to say . C2 Shows great flexibility reformulating ideas in differing linguistic forms to convey finer shades of meaning precisely , to give emphasis , to differentiate and to eliminate ambiguity . Also has a good command of idiomatic expressions and colloquialisms . Previous research Within NLP , it"
226	Y10_1092	"the word as a query . An image along with the word itself is shown in the Q1 page of Dr Sentiment game . A word along with an image is more attractive rather than only a word . The words are shown in player ' s own language as <<< he/she >>> specified in the login page . The sentiment score calculated by the different emoticons pressed by different players and scale of sentiment score assigned accordingly as extreme positive ( pos : 0.5 , neg : 0.0 ) , positive ( pos : 0.25 , neg : 0.0 ) , neutral"
227	W07_1213	"Tichý 1980 ) . -frame : AG&lt;person:1&gt; who_nom obl VERB obl PAT&lt;person:1&gt; whom_acc opt KNOW&lt;subject:3&gt; what_acc , to_what_dat obl -example : naučil dítě abecedu ( he educated a children in the alphabet ) -example : učí studenty matematiku ( he teaches mathematics for students ) -example : vyučuje dějepisu ( <<< he/she >>> teaches history ) -use : prim If understood as in "" "" What does ( s)he live off ? ( S)he teaches . "" "" it is the case of cry 3 ( see above ) . To teach understood as in "" "" He teaches history , maths """
228	P09_2005	"User : A user who is cooperative with a system by answering what the system asked . _ Corrective User : A user who try to correct the misbehavior of system by jumping to or repeating specific subtask . _ Self-directing User : A user who tries to say what <<< he/she >>> want to without considering system""""s suggestion . Examples of discourse knowledge description for three types of user are shown in Fig. 4 . Both the formulas from data-driven model and formulas from discourse knowledge are used for constructing MLN in generation time . In inference , the discourse context related"
229	C16_1202	"After the learning phase , we obtain the distributed representations of users and items shown as vectors . They are used in the score prediction task . Predicting Scores As is described in Problem 1 , the problem of score prediction is to estimate the score of a user before <<< he/she >>> actually purchases the item . Thus , we do not have the text comment for the given pair when testing . We build a regression/classification model on top of the user/item representations . Specifically , a prediction model is a parameterized function F ( U i , I j )"
230	2022_acl_long_135	"and SenseBERT embeddings , except for nurse where BERT is slightly antistereotypically biased whereas SenseBERT shows a similar in magnitude but a stereotypical bias . Recall that/IN nurse is stereotypically associated with the female gender , whereas other occupations are BERT SenseBERT stereo/anti-stereo sentences stereo anti diff stereo anti diff <<< he/she >>> is a strong nurse -0.45 -0.67 0.22 -15.71 -16.64 0.93 he/she is a professional nurse -0.73 -0.85 0.11 -16.53 16.81 0.27 As a mother/father of five , she/he carefully nurse all of her/his children -0.16 -0.15 -0.01 -18.07 -18.24 0.18 she/he made milk herself/himself to nurse the crying baby -0.77"
231	C92_4182	"concept ' address ' , he/she will use "" "" 3uusyo""""([my ] address ) , e. g. "" "" Juusyowa Oosaka-sht desu . "" "" ( My address is in Osaka~city . ) . On the other hand , if he/she is uttering tile other participant ' s address , <<< he/she >>> will use "" "" . qo . juusyo "" "" ( [ your ] address ( polite fornl ) ) , e. g. "" "" Go-juusyo-wo onegaishi-masu . "" "" ( Your address , please ? ) These facts lead rlS to ilnplenmltt knowledge SOllrces elf s/Idl vari~ . lions(we"
232	2020_findings_emnlp_347	"collected dialogue ratings from users belonging to "" "" novice "" "" ( 15 % ) , "" "" some experience "" "" ( 33 % ) and "" "" experienced "" "" ( 52 % ) groups . A novice user has minimal experience conversing with the SDS and <<< he/she >>> has never used the functionality provided by the 28 domains prior to the study . A user with some experience has interacted with some ( but not all ) domains , whereas an experienced user is a seasoned user of Alexa and its domains . Experimental Setup This section describes"
233	W11_2852	": • Only the target button is visible : in this case the system confirms that/IN this is the correct button , for example by saying Yes , that one . • Only buttons of the wrong colour are visible : in this case the system reminds the user that/IN <<< he/she >>> needs a button with another colour , for example by saying No , not this button . It should be blue ( Figure 4A ) . • Only wrong buttons , but of the correct colour are visible : here , the system tells the user that/IN another button is"
234	Y16_3026	"Corpus Our claims are also supported by contextual data collected from Sejong Korean Corpus for factive and NF al-ta . In the corpus data , as in ( 13 ) , al-ta with -uro is used to imply that/IN the speaker has uncertainty or false belief about the complement content <<< he/she >>> is talking about but she has some piece of evidence for her belief unlike in the case of other neg-raising weaker epistemic verbs such as mit-ta ' believe . ' Consider the following : ( 21 ) e~ malchalyey-ka congkyeltoyessum-ul Uh~ conversation turn-NOM finish-ACC phyosihanun , malcharyey tanwi phyoci-ka represent"
235	W19_4434	"over time and thereby improves its ranking . With the aforementioned training set we were able to repeatedly achieve a recall accuracy of 0.86 or higher in identifying images which are likely to be selected by the validator . The validator looks through the images and selects the ones which <<< he/she >>> thinks is appropriate considering the script and search term ( Figure 2 ) . A search term without valid images is considered irrelevant and is ignored . Once the validation is completed , the verification step concludes . The output of this layer is a mapping between the Prioritized Search"
236	R13_1065	"The next pair was requester ' s perspective and the politeness markers ( F2 with F4 ) . In case of interlanguage ( English ) , when requester used more direct utterance through factor F3 , he/she mitigated this directness with expressive factor F4 ( politeness marker ) . When <<< he/she >>> decided to express him/herself more indirectly , he/she used a combination with politeness marker ( F2 with F4 ) reinforcing the likelihood of request fulfilment , which is confirmed by the last couple of factors . The analysis results for the texts of requests written in Slovak were partially different"
237	W18_1923	"application ' s voice output can be changed when a cheaper , or better , TTS provider wraps its engine using the MFLTS API . In general , the application works in an "" "" interview-style "" "" fashion where the soldier is the driver of the conversation . Initially <<< he/she >>> will start the conversation by speaking into the application , and then waiting for it to recognize , translate and output the translation via text-to-speech ( TTS ) . All this happens close to real-time , with latencies from end-of-speech to begin-of-TTS on the order of 1000 milliseconds on the"
238	L18_1173	"the proper tag . To increase the speed of the annotation process , some of the words , like Named Entities and punctuations , will have an initial tag assigned automatically as part of a preprocessing step . However , the annotator is allowed to change the initial tag if <<< he/she >>> finds words annotated with a wrong tag . The interface uses color-coding to reflect useful information and status . For example , ' named entities ' will be displayed in purple color , while Other tagged categories such as Latin , URL , punctuation , digits , diacritics , emoticons"
239	P98_2163	"by vertical and horizontal extensions of the prototype in Table 2 . The Cause Circum Contrast Circum movements involved in these situations are locational and the other events must be done volitionally by the same person . Another extension covers situations where "" "" someone does something , and then <<< he/she >>> does something else . "" "" This is based on the fact that/IN one person cannot generally engage in two actions at the same time . Of course , any type of events may occur sequentially . However , there exists the constraint on the fitness with te-linkage as mentioned"
240	W91_0203	"we are still developing , for managing knowledge that is in different states of "" "" clarity "" "" ( for want of a better term ) . Lack of clarity may be due to several causes : for example , a terminologist may be unclear about a concept because <<< he/she >>> does not have the domain expertise to understand it properly ; a technical writer , translator , etc. in the document-production chain may be unclear about a concept because people at various preceding links in the chain have used a term inconsistently ; a concept may be very new ("
241	W12_3708	"n't change the meaning of the sentence . We conducted a preliminary survey and found that/IN our assumption works well . We asked 20 subjects to extract influential sentences from the 500 sentences . The task is to extract sentences by which each subject thinks it influential enough to decide <<< he/she >>> wants to book or never to do the hotel . We asked them not to include their personal tastes . There are 84 influential sentences on which more than 4 subjects agreed . In the following sections , these 84 sentences will be called the influential sentences and the other"
242	W00_1101	"has no synonyms at all ( e. g. 7b in the example ) , therefore all synsets for a given term need to be presented to the evaiuator in order to make an informed choice . The evaluator provides a yes/no answer for all the ( term , synset ) <<< he/she >>> is presented with ( with some exceptions , as explained in section 3.1 ) . Automatic pruning The automatic pruning task is analogous to manual pruning in two respects : ( i ) its input is the set of synonymy relations involving WordNet polysemous words appearing in the domain specific"
243	2020_acl_main_98	"the ground-truth profile for each seeker , which is known to the seeker , and unknown to the recommender . We ask that/IN the utterances of each seeker should be consistent with his/her profile . We expect that/IN this setting could encourage the seeker to clearly and self-consistently explain what <<< he/she >>> likes/dislikes . In addition , the recommender can acquire seeker profile information only through dialogs with the seekers . Knowledge graph Inspired by the work of document grounded conversation ( Ghazvininejad et al. , 2018 ; Moghe et al. , 2018 ) , we provide a knowledge graph to support"
244	N19_4012	"Then , he/she can write content of an article in the corresponding text-area ( step 2 ) without specifying it ' s headline and highlights , i. e. , summary . By clicking "" "" NATS "" "" button ( step 3 ) and waiting for a few seconds , <<< he/she >>> will see the generated headlines and highlights for the article in a new tab on the right hand side of the screen . Here , each of the buttons in gray color denotes the resource of the training data . For example , "" "" Bytecup "" "" means the"
245	Y10_1101	"structure or as an auxiliary . Besides we have some other auxiliaries for this purpose . We propose two simple tests to distinguish the modal and evidential auxiliaries . Introduction Evidentiality is a grammatical category which deals with the source a speaker has for his or her statement , whether <<< he/she >>> saw it , or heard it , or inferred it from indirect evidence . In some languages it is obligatory in every sentence , and there are also languages in which it is an optional category ( Jacobsen , 1986 ; Aikhenvald , 2003a ; Aikhenvald , 2004 ) ."
246	C12_1030	"relevant documents by the standard document retrieval systems ( i. e. search engines ) , his/her search task is usually not over ( Chali et al. , 2009b ) . The next step for him/her is to look into the documents themselves and search for the precise piece of information <<< he/she >>> was looking for . This method is time consuming , and a correct answer could easily be missed , by either an incorrect query resulting in missing documents or by careless reading . This is why , Question Answering ( QA ) has received immense attention from the information retrieval"
247	2020_emnlp_main_252	"The difference among these predictions corresponds to the characteristics of the conditional ECPs , which is to depend more on P ( y c i ) when P ( y o i ) indicates no causal relationship . As for Documents #3 and #4 , one shall feel frightened whenever <<< he/she >>> witnesses a bloody murder around him/her , which is unlikely to change with different contexts . Therefore , both documents should have causal relationships . As shown in the table , P ( y o i ) already indicates that/IN the pair is causally related regardless of context and hence"
248	W13_5632	"about intonation patterns of a given language can be made through the computer-aided analysis of a real world intonation phenomena . It would be of a great help to a human expert if similar intonation patterns are collected together and presented to him/her in a user-friendly way . Then , <<< he/she >>> could assign these collections to particular intonation categories , construct "" "" an inventory "" "" of intonation patterns , easily detect and eliminate "" "" false "" "" members out of these collections , mark pitch accents and boundary tones in a more uniform way . This paper describes"
249	2020_aacl_main_32	". The sender just move out to Katy few months ago . She is having a baby due in June . She is scared of being a mother but also pretty exited about it . Rachel is coming to visit her in couple of weeks and she is asking if <<< he/she >>> will join for any of the rodeo stuff . She run into heather evans which she had n't talked in 10 years . appear only once in the source text ; thus TextRank fails to capture the salient sentences . Our model , by contrast , can capture them because"
250	O12_1007	"the frequency index can be known . Experiment 2 : The role of personal word frequency in visual word recognition This experiment investigates whether a subject ' s personal word frequency of a certain LDT 10 stimulus would influence his/her corresponding reaction latency . It was preliminarily hypothesized that/IN if <<< he/she >>> used a word more frequently than other words , the response to the word would be more rapid . Besides , as shown in Table 1 , each participant ' s data differ in length ; to render frequency counts across the data sets comparable , two kinds of normalization"
251	Y03_1016	"between the accuracy and the amount of corpus to be manual proofread . The higher accuracy required , the larger corpus to be manual proofread . Thus , with a fixed resource of labour , one can determine the final accuracy of corpus after manual proofread is done , or <<< he/she >>> can estimate how many corpus should be manual proofread to achieve the required accuracy according to the curve . Conclusion The proposed context-rule model utilizes a broader scope of features to tag pos and achieve a better precision . The target word dependent Markov model also performs better than general"
252	W05_0901	"the full-text document ; or ( 2 ) HUM surrogates , then HEAD surrogates , and then the full-text document . In the second half , the subject saw the alternative ordering , e. g. , if a subject saw HEAD surrogates before HUM surrogates in the first half , <<< he/she >>> saw the HUM surrogates before HEAD surrogates for the second half . Either way , the full-text document was always shown last so as not to introduce judgment effects associated with reading the entire document before either surrogate type . In addition to varying the ordering for the surrogate type"
253	W19_2208	"in v c i because judges need only discuss issues material to how the case should be resolved . Suppose a claimant mounts two claims on the same issue against a defendant in tort , and in trademark law . If the judge finds for the claimant in tort , <<< he/she >>> may not discuss trademark at all ( though some may still do so ) . Thus , even though v c i raises trademark issues , j c i may not contain any N -grams discussing the same . It is possible that/IN a v c i we would assign"
254	D14_1143	"This LP score vector is the output of label propagation and is real-valued . To obtain the classification result from this real-valued LP score vector for an unlabeled node ( word ) i , the learner is predicted to know the word i if f i &gt; 0 , and <<< he/she >>> is predicted to be unfamiliar with the word if f i ≤ 0 . Next , we formally define a normalized graph-Laplacian matrix , which is used for penalization based on the cluster assumption . Let an N × N -sized square matrix W be a weighted adjacency matrix of"
255	W03_2128	"answers . Questions and Directives Some typologies we have studied make a difference between questions and directives , some do not ( e. g. Bunt 1999 ) . Sometimes questions and directives are differentiated on the basis whether the user needs some information ( then it is question ) or <<< he/she >>> wants to influence the hearer ' s future non-communicative actions ( then it is directive ) . Our departing point is that/IN it is not important for dialogue continuation whether the hearer must to do something outside of current dialogue or not . He/she must react to both a question"
256	L18_1026	"( CoI ) items 11 . This CoI category is a sub-category of "" "" NPOV disputes "" "" . Wikipedia encourages its editors to pick an article from this category and decide whether it meets its notability policy 12 . If one believes the article should be kept , <<< he/she >>> needs to review the text to ensure that/IN it complies with NPOV . This human categorisation of Wikipedia articles will be our basis for evaluating our results . In order to build a dataset containing both CoI and non-CoI articles , for each CoI article , we randomly select non-CoI"
257	W13_5205	"schema and the eventual reclassification of the data . Also such recording will help further usage of the treebank . For example , each usage could be reported with respect to the annotation context ontology . Later when somebody wants to use the treebank for evaluation of a new parser <<< he/she >>> could first examine the setups in which the treebank was used for similar tasks and then design a new one . Similarly the history of the annotation process could be useful in the process of design and implementation of new language resources . Created in such a way language resources"
258	J03_4002	"( i ) and ( ii ) , the questions constrain the theme/rheme partition of the answer . Small capitals represent focus within the rheme . In ( i ) , the otherwise clause will be interpreted as warning the hearer ( H ) that/IN H might get hurt if <<< he/she >>> transports the dog in some way other than carrying it ( e. g. , H might get tangled up in its lead ) . In ( ii ) , the otherwise clause warns H that/IN he/she might get hurt if what she is carrying is not the dog ( e."
259	2020_lrec_1_852	"of the context passage is equal to 0 is the accuracy achieved by a human worker when he/she was asked to answer 100 quizzes without context information . The row where the length of the context passage is equal to 20 is the accuracy achieved by a human worker when <<< he/she >>> was asked to answer 100 quizzes with context information given by 20 context sentences . As shown in Table 3 , 5 trials where the length of the context passage is 0 , 1 , 5 , 10 and 20 were conducted in our investigation . Table 3 shows that/IN"
260	Y18_1026	". In FF1 , ' ( I/ we ) stop the vehicle and move forward after confirming our safety ' seems to be a very typical writing that refers to an SB . In this instance , however , this writing provokes the author and readers into being cautious because <<< he/she >>> was involved in a car accident . Thus , the annotators tagged "" "" SJ . "" "" FF2 is the opposite case of the SB tagged as an SJ . The expression "" "" The sudden stop was miraculous . "" "" seems quite subjective if this sudden stop"
261	C14_1027	"item in order to emulate expert-level label quality , the quality of some tasks increased by increasing the number of workers to 10 . We also tested hidden gold-standard items once every 10 items to examine worker ' s quality . If a worker failed these items in serial , <<< he/she >>> would have to take a test to continue the task . We obtained judgments for the 59,426 clause pairs in the 10,000 documents of our corpus in the first stage of crowdsourcing , i. e. , the subtask of determining the existence of discourse relations . We calculated the probability"
262	W14_1405	"any h : Human , the dependent type Evt(h ) is the type of events conducted by h. Now , we can assume that/IN the verbs start , f inish and last have type where we have simplified the second case by assuming that/IN one would read a book if <<< he/she >>> has not written it . ( One may think of other actions to consider more subcases here . ) Having the above , we can now interpret ( 43 ) as follows ( in a simplified form ) : ( 44 ) start(j , wp ) & f inish(t ,"
263	W10_0202	"customer perception of loss is severe to the point that/IN the customer may cancel the service . On the other hand , email 2 is not emotional because customer perceived loss is not severe to the point of service cancellation . This customer would be satisfied in this instant if <<< he/she >>> receives the requested information in a timely fashion . To extract salient features from an email , eight separate lists of phrases customers use to express each of the salient features were manually created . These lists were extracted from the training data and can be considered as basic rules"
264	W03_2128	"this act . Refusal and Missing Information The second problem group are situations where the answerer is not able to give information . Three cases can be differentiated depending on continuation of dialogue : the answerer does not have the needed information , he/she refuses to give it , or <<< he/she >>> cannot give it immediately . If the answerer does not have the information then the questioner must abandon the following attempts . In the case of having information we have two possibilities depending on whether the answerer is the consultant or client . The first possibility can be excluded because"
265	2021_konvens_1_20	"in general . He/She cares about their situation . Also , she/he is against the mentioned liberalization , which is not explicitly stated but inferred . ( 2 ) is a response to the following question : Should the government be more committed to equal educational opportunities ? Only if <<< he/she >>> is in favor of education , the answer can be understood as an approval : education must be one of his/her values . However , there is no pro nor con relation with respect to income . The question underlying the answer in ( 3 ) is : Should the"
266	P17_4003	", Benben will recommend a recent news , according to the user profiling information , by a random alternation to the conversation topic transferring to break the stalemate . Note that/IN the news recommendation is also in an interactive way , which means that/IN Benben will ask the user whether <<< he/she >>> wants to read a news of a specific topic in an euphemism way . Response Generation As shown in Figure 2 , the response generation takes the conversation states and the intermediate results as input to generate text or speech responses to users . The filtration , rejection , confirmation"
267	N18_3003	"intent vector , and e s ∈ R 50 for a vector of slots . User Preferences User-specific signals are designed to capture each user ' s behavioral history or preferences . In particular , we encode whether a user has specific domains enabled in his/her IPDA setting and whether <<< he/she >>> triggered certain domains within 7 , 14 or 30 days in the past . Domain Index From this category , we encode domain popularity and quality as rated by the user population . For example , if the utterance "" "" I need a ride to work "" "" can"
268	N16_1166	is : P ( u ) = 1 |polls(D)| |polls(D)| i=1 p i ( 1 ) where p i is the poll percentage assign to speaker u in poll i in the reference polls . Features We characterise each speaker in each debate based on the content and emotion cues <<< he/she >>> generated . Specifically we analyse each candidate in three dimensions : i ) what they said ( content features ) ; ii ) the persuasiveness of the language they used including persuasive argumentation features and emotive language ; iii ) and external emotions evoked during the debates . We described
269	2008_amta_govandcom_24	"the most cost-effective IC element for human foreign language translation Traditional Human Translation Workflow Figure 1a portrays the traditional human translation workflow , both in government and in industry . The first significant aspect of this workflow is that/IN each human translator traditionally uses his or her self-developed/maintained wordlists which <<< he/she >>> shares with few other translators . Although major government agencies are able to provide corporate lexical resources to their translators , development and use of corporate linguistic knowledge is often minimal in smaller agencies . Second , the traditional workflow is sequential . Translators begin translating from the original source"
270	R11_1106	"he/she is looking for . An evaluation on real data shows that/IN the solutions given by this automatic titling approach are relevant . Introduction Web pages contain a multitude of information concerning many domains . Very often , the user has to supply heavy cognitive efforts to find the information <<< he/she >>> is looking for . For handicapped persons , while the access to Internet is a tremendous vector of integration in society , the localization of information remains complex . One of the key domains of web pages accessibility , such as defined by a standard proposed by handicap associations ("
271	2021_louhi_1_5	"it merely mentions vaccination ( Weissenbacher et al. , 2018 ) . This Vyvanse got me sweating right now and I dont even know why SM20-5 Birth defect mention detection is a 3way classification problem , where Category 1 tweets refer to the user ' s child and indicate that/IN <<< he/she >>> has a birth defect . Category 2 tweets are unclear whether the tweet speaks of birth defects of the author ' s child . Category 3 tweets merely mention birth defects but not with respect to the author ' s child ( Klein et al. , 2020 ) . Examples"
272	C98_2158	"implys that/IN the two movements by a person must be sequential . This prototype is extended so as to cover such situations as "" "" someone goes to somewhere , and then he/she does something/becomes something/stays there "" "" or "" "" someone does something/become something/stays somewhere , and then <<< he/she >>> goes to elsewhere . "" "" They are expressed by vertical and horizontal extensions of the prototype in Table 2 . The movements involved in these situations are locational and the other events must be done volitionally by the same person . Another extension covers situations where "" "" someone"
273	2007_mtsummit_papers_55	"get the right of maximal control , they also have the right of choosing control level . User ' s optional control means that/IN users can control the process of the translation engine as much as they want to do . If a user is relatively poor in English , <<< he/she >>> may put emphasis on the rewriting of the Korean sentence . If he/she wants to get professional translation quality , he/she is going to revise all the errors from the engine . The level of engine control can be set by the user . For provision of sufficient information to"
274	2022_ltedi_1_7	"of lexicons of lexically gendered words . These simultaneously represent a variety of applications for our lexical gender detection algorithm . Dataset evaluation The most straightforward form of using gendered words is to assess the distribution of gendered words in a corpus . Zhao et al. ( 2019 ) counted <<< he/she >>> pronouns in the One Billion Word Benchmark ( Chelba et al. , 2013 ) to show male skew in the training data for the ELMo language model ( Peters et al. , 2018 ) , which is the primary focus of their analysis . This analysis addressed calls for better"
275	2007_mtsummit_cre_1	"a naïve exercise , it is tolerant of a variety of skill and expertise levels . Anyone who speaks English may participate . If it turns out that/IN the participant also knows the source language of the experiment , there will be other interesting tasks during this exercise in which <<< he/she >>> can participate . Position Papers : Papers are not specifically solicited for this workshop , as it is a handson exercise . However , we will accept position papers ( 1-2 pages maximum ) from participants who have some contribution in the following topics : the Chinese room experiment ;"
276	E03_2014	"the MUMIS project to find out which events from the various documents should be combined such that/IN more complete information can be derived . The person who produced the natural language text from which events are extracted , acts as a "" "" semantic filter "" "" : the events <<< he/she >>> described are understood to belong together in the same scene ( groups of events semantically related ) if they are mentioned in the same textual fragment . For example , if the same players are mentioned in two different but close ( in time ) textual fragments , then the"
277	2021_ecnlp_1_10	"seller in attributes . faceted navigation , merchandizing , search ranking and comparative summary . Onboarding products in a catalog requires populating the structured as well as unstructured parts . The time a seller has to spend on a product addition request is proportional to the quantum of information that/IN <<< he/she >>> has to provide . On the other hand , correctness and completeness of catalog results in better product discovery , leading to a trade-off with its onboarding time . A good amount of attributes information is present in product description as well . This motivates us to extract the information"
278	C18_1134	", father , [ 7 ] liver , [ 8 ] we , to vomit , they , new , four , i , to pound/beat , [ 9 ] thou , who , one hundred , [ 10 ] name , to dig , to choose , stone , <<< he/she >>> , branch , when , to come , above , [ 11 ] thin , what , wife , mother , to hide , to grow , one , to buy , [ 12 ] dust , worm/earthworm , root , star , salt , toeat , [ 13 ]"
279	W15_5705	"the evaluator is presented again with the question , the MT answer ( A ) , and the reference answer ( B ) . This time the subject is asked to compare answers A and B. Taking into account that/IN the second answer B is giving the correct information , <<< he/she >>> is asked to re-evaluate the first answer A , selecting one of the following options : • A gives the right advice . • A gets minor points wrong . • A gets important points wrong Finally , evaluators are asked to give a closer look at the automatically translated"
280	L16_1121	"we averaged all measurements and entered the resulting coordinates in the Kinects ' config-files to improve their accuracy . Recording Procedure Each speaker read items that appeared on a smart-phone ' s screen . At the beginning , we informed the speaker about the purpose of the recording , and <<< he/she >>> signed a statement of agreement ( e. g. , to ensure that/IN we preserve the speaker ' s anonymity ) . Afterwards , we instructed the speaker about the overall procedure and equipped him/her with a headset , a back bag containing a battery-driven laryngograph and wireless transmitters . On"
281	E17_1026	"knowledge from the others . We distinguish these two types of knowledge because they are equally important and necessary for annotating a dataset , especially in a movie domain . A topic expert can be very confident on understanding the meaning of the text , but without any NLP knowledge <<< he/she >>> would not be able to perform a confident annotation , especially when dealing with the implicitness/explicitness and subjectivity/objectivity labels . On the other hand , being only a NLP expert is not sufficient when in the text subtle and sophisticated references to the topic are present , resulting in an"
282	W13_5205	"powerful mechanism for representation and manipulation of knowledge . They can be used to define different views over the same information and facilitate inference for consistency checking . Unfortunately , the conceptualization encoded in ontologies could follow different ontological assumptions . Thus , when someone uses datasets from LOD , <<< he/she >>> has to pay attention to the way in which they are conceptualized . One solution for the diversity of the ontologies within LOD is the definition of a common unifying ontology . Different communities have already defined and published their datasets on the LOD cloud . In the last years"
283	Y12_1056	"and politeness feature ( F2 with F4 ) . In case when the author of English request used more direct utterance through factor F3 , he/she mitigated this directness with expressive factor F4 ( politeness feature ) . When he/she decided to express him/herself in a more indirect way , <<< he/she >>> used a combination with politeness feature ( F2 with F4 ) reinforcing the likelihood of request fulfilment , which is confirmed by the last couple of factors . The analysis results for Slovak requests were partially different . The most frequent factors used were : F1 , F2 and F5"
284	W08_2205	"reader will infer that/IN ( probably ) : The soldier was shot ; The soldier died ; There was a fight ; etc. even though none of these facts are explicitly stated . A person is able to draw these plausible conclusions because of the large amounts of world knowledge <<< he/she >>> has , and his/her ability to use them to construct an overall mental model of the scene being described . A key requirement for this task is access to a large body of world knowledge . However , machines are currently poorly equipped in this regard . Although a few"
285	E17_1026	"A 1 is a NLP expert while he/she is not very confident on the topic selected , the second annotator A 2 has a good expertise in NLP and a good knowledge about the topic , the third annotator A 3 is a beginner in the field of NLP but <<< he/she >>> is competent on the topic . Dataset The data has been retrieved by monitoring different keywords on the Twitter microblogging platform related to two popular movies : Deadpool and Suicide Squad . This choice was motivated by the intention to increase the number of opinionated posts and therefore to have"
286	J86_2002	"France , which might happen to be true currently . Once again , the latter response violates the maxim of quality , a common occurrence if summary responses are not carefully tuned to reflect significant domain subdivisions . The DISTINGUISHING VALUE slot enables the database manager to specify classifications that/IN <<< he/she >>> would a priori like to appear meaningful to the user in descriptive responses . Without this information the system may fail to faithfully reflect the user ' s perceived notions regarding appropriate partitioning of entity classes . By changing the distinguishing values , the database manager can adapt the system"
287	H01_1064	"server proposes caller names by matching messages against existing caller models ; this module is trained from user feedback . The caller identification capability is based on text independent speaker recognition techniques applied to the processed speech in the voicemail messages . A user may elect to label a message <<< he/she >>> has reviewed with a caller name for the purpose of creating a speaker model for that caller . When the cumulative duration of such user-labeled messages is sufficient , a caller model is constructed . Subsequent messages will be processed and scored against this caller model and models for other"
288	W19_0505	"of proof on the negation of the existential assertion ( see ( Diller , 2019 ) ) , but arguably more in line with the framework of ( Strass and Wyner , 2017 ) is to reason by cases ; i. e. consider for everyone both the possibility that/IN the <<< he/she >>> owns a car and that he/she does not . One simple encoding of this option is as follows : object(A , somebody ) , ¬x auxP B1(A ) → x auxP H1(A ) object(A , somebody ) ⇒ ¬x auxP B1(A ) object(A , somebody ) ⇒ x auxP B1(A"
289	J78_3039	"n c e it is i r r e f l e x i v e . Yet your s i b l i n g ' s s i b l i n g i s your s i b l i n g a s long a s <<< he/she >>> is n o t yourself . T h i s is what w e mean by "" "" almost t r a n s i t i v e . "" "" N o t e t h a t f o r any r e l a t i"
290	W13_5506	"that/IN the DTA has which are not child/experiment specific which the LA does not have , such as the participant ' s length of residence at the session location , date of birth , nationality , place of birth , levels of language or cognitive impairment , dialect , whether <<< he/she >>> is a native speaker of the language used in the session , and his/her levels of proficiency in the language . The DTA also has a more detailed division of references as explained in section 2.2 above . corpus is described . Length of descriptions varies from a short paragraph"
291	W15_4611	"was probably because of the perception of "" "" what the system really understood "" "" . Some annotators thought the system made an utterance that did not match the content of the previous user utterance because it did not "" "" understand "" "" the user ; therefore , <<< he/she >>> used the RES-Non-understanding category , whereas others just used the RES-No-relevance category . In fact , other confusing pairs in the response level had similar problems . For example , the category RES-Excess/lack-of-information was confused with RES-Unclear-intention because some annotators thought the intention was unclear due to the lack of"
292	L18_1514	"connect lexical aspects with other language aspects such as grammar 8 based on the framework of CEFR . Also , the word level can be adapted flexibly based on a learners ' proficiency . If a researcher wants to establish a system that simplifies words into A levels , then <<< he/she >>> can omit B1 level candidates from the list . Table 5 shows the distribution of CEFR levels for both target and candidate words in SemEval2012 , Horn et al. ( 2014 ) , and CFER-LS . It is clear that/IN other two resources contain a number of A1 , A2"
293	W09_3927	"contrast , incorrect answers after a PopUp are negatively correlated with learning . We hypothesize that/IN these correlations indicate whether the user took advantage of the additional learning opportunities offered by the remediation subdialogue . By answering correctly the original system question ( PopUp-Correct ) , the user demonstrates that/IN <<< he/she >>> has absorbed the information from the remediation dialogue . This bigram is an indication of a successful learning event . In contrast , answering the origi-nal system question incorrectly ( PopUp-Incorrect ) is an indication of a missed learning opportunity ; the more such events happen the less the user"
294	D19_3030	"click on the Named Entities tab ( Figure 2b ) . Similarly , to select a noun phrase present in the paragraph as the pivotal answer , the user can click on the Noun Phrases tab ( Figure 2c ) . Once a user clicks on either of the tabs <<< he/she >>> will be presented with prehighlighted noun phrases/named entities as pivotal answers . The user can subsequently deselect a pivotal answer by clicking on it . Custom pivotal answer selection : Alternatively , the user can click on the Custom Answers tab ( Figure 2d ) and manually select the most"
295	W02_1407	"type of meaning . The second reason is that/IN if a certain single-noun , say N , expresses the key concept of a domain that/IN the document treats , the writer of the document must be using N not only frequently but also in various ways . For instance , <<< he/she >>> composes quite a few compound nouns using N and uses these compound nouns in documents he/she writes . Thus , we focus on the relation among single-nouns and compound nouns in pursuing new ATR methods . The first attempt to make use of this relation has been done by ("
296	N09_2010	"involved 16 pair of graduate students . In each pair there was a customer and an observer . The goal of the customer was to decide which camera he/she would purchase using a camera review blog 1 to inform his/her decision . As the customer read through the reviews , <<< he/she >>> was asked to think aloud and the observer recorded their observations . The website used for this study had two types of reviews : expert and user reviews . There were mixed opinions about which type of reviews people wanted to read . About six customers could relate more with"
297	P08_2004	"team will win . We could easily imagine a scenario where sentence ( 5 ) is more objective than sentence ( 6 ) and ( 7 ) . For example , the speaker may believe that/IN the red team will lose , but in order to avoid personal bias , <<< he/she >>> may instead say : "" "" It is possible that/IN the red team will win ( but the blue team has a better chance ) . "" "" In general , explicitly showing uncertainty can imply postulation , but it can also convey the intention of being objective by not"
298	C08_3010	"advantages ( one of which is the freedom to design the form of the query ; such as POS and dependency ) , it is a huge , expensive task ; not everybody can afford to make a search engine . More seriously , not everybody can use it as <<< he/she >>> may want . In this paper , we will propose an alternative solution which should enable researchers with modest resources to conduct research using huge corpora for knowledge discovery . It is an ngram search tool with the following requirements . Requirements Algorithm Overview There are two reasonable choices for"
299	Y12_1056	"reverse order . It means that/IN , when a requester used an att . getter ( a specific greeting etc. ) , it is more likely that/IN he/she used an expressive factor , which raised the indirectness of the utterance and decreased its possible negative effect . Similarly , if <<< he/she >>> used indirect expression of perspective -F2 then he/she combined it with politeness features , so the most frequently observed association rules were those indicating the preference of indirect expression in Slovak . Discussion and Conclusion If we look at the results from the point of view of language used ,"
300	W00_1312	"not have the skill to prepare a high quality query in the other language(s ) . Once documents are retrieved , machine translation or human translation , if desired , can make the documents usable . For the user who is fluent in two or more languages , even though <<< he/she >>> may be able to formulate good queries in each of the source languages , CLIR relieves the user from having to do so . Most CLIR studies have been based on a variant of tf-idf ; our experiments instead use a hidden Markov model ( HMM ) to estimate the"
301	D19_3038	"provides additional information , such as summary of the event and a description for each entity mentioned in an article . While these news aggregators help readers to get a more comprehensive coverage of an event , some of the sources might be unknown to the user , and thus <<< he/she >>> could naturally question the validity and the trustworthiness of the information provided . Deep analysis of the content published by news outlets has been performed by expert journalists . For example , Media Bias/Fact Check 4 provides reports on the bias and factuality of reporting of entire news outlets ,"
302	2009_eamt_1_17	"V TV , V IV ) for North Sámi , they were not specified in the Lule Sámi dictionary ( only V ) . Another matter of choice and convenience is the degree of lexicalisation as in the case of derived verbs . The North Sámi verbform gohčoduvvo ( ' <<< he/she >>> is called ' ) either goes back to the form gohččut ( ' order ' ) or to gohčodit ( ' call , name ' ) , which is derived from gohččut but to some extent lexicalised . In Lule Sámi , gåhtjuduvvá only gets the analysis with the lexicalised"
303	W08_1407	"participant was asked to familiarize himor herself with the location of the image by analyzing the map and going through all 11 URLs . Then each participant decided on up to 5 different pieces of information he/she would like to know if he/she sees the image or information about something <<< he/she >>> relates with the image . The information we collected in this way is similar to ' information nuggets ' ( Voorhees , 2003 ) . Information nuggets are facts which help us assess automatic summaries by checking whether the summary contains the fact or not . In addition to this"
304	P14_2056	"These findings suggest that/IN if a person starts an email thread , he ' s likely not to be the one who has power , but if a thread includes a pair of people who are hierarchically related , then it is likely to be initiated by the superior and <<< he/she >>> tends to contribute more in such threads . Predicting Direction of Power We build an SVM-based supervised learning system that can predict HP ( p 1 , p 2 ) to be either superior or subordinate based on the interaction within a thread t for any pair of participants ("
305	C12_1178	"model in section 3.1 , in the end , we build words ' confusion sets by filling them in with words that are most similar in their intensions . Our new model describes a two step process when a learner makes word selection choices : by examining the context , <<< he/she >>> will first think about an intension to convey ; then he/she chooses a word that conveys as similar an intension as possible . We will refer to the first step as making intension decisions , and the second step as making word choice decisions . The goal of their learning"
306	2022_acl_long_135	"the same sense as in prior work such as Kurita et al. ( 2019 ) . For example , we manually create templates such as [ gender word ] is a [ pleasant/unpleasant attribute ] engineer . We then fill the gender word by male and female gender pronouns ( <<< he/she >>> ) , pleasant attributes ( e. g. careful , skilful , efficient , etc. ) and unpleasant attributes ( e. g. clumsy , unskillful , inefficient , etc. ) to generate many example sentences demonstrating social biases . To the best of our knowledge , SSSB is the firstever dataset"
307	W00_0401	in English . This group was chosen because they have knowledge about what constitutes a good abstract and they are educated to become professionals in Information Science . Evaluation Procedure The evaluation was performed in one hour session at McGill University . Each human judge received a form ( so <<< he/she >>> evaluated six different abstracts ) and an instruction booklet . No other material was required for the evaluation ( i. e. dictionary ) . We asked the judges to read carefully the abstract . They had to decide which was the list of keywords that matched the abstract ( they
308	W19_0505	"the existential assertion ( see ( Diller , 2019 ) ) , but arguably more in line with the framework of ( Strass and Wyner , 2017 ) is to reason by cases ; i. e. consider for everyone both the possibility that/IN the he/she owns a car and that <<< he/she >>> does not . One simple encoding of this option is as follows : object(A , somebody ) , ¬x auxP B1(A ) → x auxP H1(A ) object(A , somebody ) ⇒ ¬x auxP B1(A ) object(A , somebody ) ⇒ x auxP B1(A ) x auxP B1(A ) →"
309	W19_8300	"indicating how many times a player talks , because we considered that/IN players with a lot of utterances were conspicuous . The second measure is the number of appearances indicating how many times a player comes up in utterances of other players , because we considered that/IN it indicates how <<< he/she >>> attracts attention from other players . The more the number of utterances and appearances are , the more attention will be drawn . Using decision trees , we analyzed how the numbers of utterances and appearances per player affected the winning percentage of werewolves . For making a decision tree"
310	2020_coling_main_94	", are highly probable to have the depression symptom ( American Psychiatric Association and others , 2013 ) . For instance , Figure 1 illustrates a month-long timeline of a depressed user . From this figure , we can see that/IN this person is highly possible to be depressed since <<< he/she >>> discloses negative emotions lasting for almost a month . This conforms to his/her depression symptom and indicates the importance of considering the global semantics for depression detection . Inspired by the above observations , this paper hypothesizes that/IN it is desirable to consider the global topic information inside multiple modalities"
311	W11_4610	"also be taken into account . For this , we are planning to use the comparability measure developped by Bo and Gaussier ( 2010 ) . • The joint use of several language resources seems to bias the results as the translators ' behaviour changes in function of the resources <<< he/she >>> has as his/her disposal . It is better to have only one resource per situation of translation , for instance : situation 0 : no resources , situation 1 : assessed terminology only , situation 2 : Internet only . • Translators should be prepared to translate in a situation"
312	D14_1124	"with respect to other authors . Since there are no direct referrals to previous authors in this corpus , references to variations of "" "" you "" "" , "" "" they "" "" , "" "" us "" "" , "" "" I "" "" , and "" "" <<< he/she >>> "" "" in each fifth of the post are included instead , for a total of 5×5 = 25 features . Meta-Post Features Slashdot allows users to rank others ' posts with the equivalent of a "" "" like "" "" button , changing the "" "" score "" """
313	P14_2056	"any requests ) . THR New : This is a new set of features we introduce in this paper . It includes the average number of recipients ( AvgRecipients ) and To recipients ( AvgToRecipients ) in emails sent by p , the percentage of emails p received in which <<< he/she >>> was in the To list ( InToList % ) , boolean features denoting whether p added or removed people when responding to a message ( AddPerson and Re-movePerson ) , average number of replies received per message sent by p ( ReplyRate ) and average number of replies received from"
314	P19_2004	"as in ( 8 ) . Here , @ modifies root-final -te , deletes root-final consonants , ∼ f deletes root-final -e , and ( g/t ) designates allomorphs that surface under distinct phonological conditions . ( 8 ) kaanneghituq kaate--@-nghite--∼ f ( g/t)u--q arrive--did . not--INTR . IND--3SG ' <<< he/she >>> did not arrive ' ( Jacobson , 2001 , p.43 ) A second proposed experiment will consequently explore the potential insight provided by including these morphophonological symbols in the training examples , studying whether the symbols facilitate learning of the surface form to glossed form mapping or whether these additional"
315	N18_1010	"read comments . We treat the ( non-)existence of a ∆ in an OH comment as a label for the last comment that/IN the OH read . We reconstruct the order in which the OH reads comments as follows . We assume that/IN when the OH writes a comment , <<< he/she >>> has read all prior comments in the path to that comment . Based on this assumption , we linearize ( i. e. , flatten ) the original tree structure of the initial post and all subsequent comments into a linear sequence S. Starting with empty S , for each of"
316	W11_3412	"the left and models the linear order and hierarchical relationshiop of the constituents . In the AVM on the right , the f-structure , the main predicate of the sentence is kHA ' to eat ' , the subject ( SUBJ ) of the sentence is the pronoun us ' <<< he/she >>> ' , with the object ( OBJ ) sEb ' apple ' . The location is analysed as an adjunct , an optional element in the sentence . Information on tense and aspect is captured in the TNS-ASP f-structure at the bottom . There is also some lexical semantic information"
317	P08_4009	", is presented in bold . Additionally , a paragraph relating the answer to the question is shown , and in this paragraph one sentence containing the answer is highlighted . Note also , that/IN each paragraph contains a link that takes the user to the Wikipedia article , should <<< he/she >>> want to know more about the subject . The intention behind this mode of presentation is to prominently display the piece of information the user is most interested in , but also to present context information and to furthermore provide options for the user to find out more about the"
318	C08_1077	"search to find the specific topic they are interested in . This active searching process leads to inefficiencies , especially in cases where queries or information needs are ambiguous . For example , a user wants to get an overview of the Virginia tech shootings , then the first query <<< he/she >>> might try is "" "" Virginia tech shooting "" "" . Most of the results returned would be posts just mentioning the shootings and the death toll . But the user might want a more detailed overview of the shootings . Thus this leads to continuously reformulating the search query"
319	P18_1065	"determining the outcome of the voting process . Moreover , it is reasonable to expect both the nature of these entities and the interactions between them to be sometimes expressed through hidden features/variables . For instance , one cannot directly observe a user ' s opinion of a product unless <<< he/she >>> writes a review , and one cannot directly observe a particular user ' s information needs or a product ' s nature , which would indicate what kind of review is most helpful for it . In the next subsections , we will discuss different moderating factors that have been"
320	W13_4046	"of non-linguistic items such as HTML codes for URLS , emoticons , IP addresses , etc. These elements were replaced by wild-cards and also user names have been anonymised , although some non-language content may remain . A forum user can give a post "" "" kudos "" "" if <<< he/she >>> finds it useful or relevant to the topic being addressed in a forum conversation . 2 We counted the number of kudos given to each post . There are four user categories in the forum : { employee , guru , notranked , ranked } . 3 A poster '"
321	L16_1352	"very important in post-editing . Accordingly , the value of ProphetMT lies in the following : ( i ) if the author is also a translator ( for example : writing a bilingual contract or a CV ) , ProphetMT will provide the author with a SMT result promptly while <<< he/she >>> is writing . If the SMT output is unsatisfactory because of unsuitable source side words or results , the author can choose to modify the source side in an appropriate manner , i. e. ' to post-edit the target by post-editing the source ' . ( ii ) if the"
322	I13_1185	"an imprint of translated text in the frequency spectrum , since function words are also subject to loaning and synonymy . If the translator has a choice for translating a preposition/affix and neither of the possibilities is similar to the source language , nor a loanword or structurally similar , <<< he/she >>> will go for the predominant word or structure of the target language ( since he/she is a native of the target language by translation industry standard ) , making the translation less different from native text . The data can be influenced by many additional variables such as differing translation"
323	W14_4104	", students have the opportunity to initiate a thread in the course forum , in order to engage other students in the class as well as the teaching staff . For example , if a student were confused about the distinction between an argument and a parameter in Python , <<< he/she >>> would post the question to the variables subforum , marking it unresolved at the same time . In the ideal case , another participant would reply to this question with some detailed explanation and example , which would solve that problem . When the student who initiated the thread receives"
324	W19_4447	"the source word poor into one of hard , difficult , and tough as opposed to the source word hard in hard luck . One example translation made by a participant is "" "" The reason why a person ' s life is tough might because he/she was lazy when <<< he/she >>> was young or he/she had a bad luck "" "" . In such cases , the learning effect cannot be correctly evaluated . We seek to find the best example sentences for word sets where the words are confusing for learners . Hence regarding the suggested example sentences , the"
325	W13_2115	"to 5 ( with a mean of 3 for each factor ) and they differentiate in the style of trend description and wording . Again the lecturer was free to choose which factors to talk about and in which order , as well as to decide on the template style <<< he/she >>> prefers for the realisation through the template options . Figure 3 shows an example of template selection for the same student as in Figure 2 . In Task 3 , the lecturers were presented with the plotted factor graphs plus a corresponding feedback summary that was generated by randomly choosing"
326	W12_5809	"approach . We describe the details of the approach and implementation as well as address the challenges associated with it . "" Personalized services are increasingly becoming popular in the Internet . This work proposes a way of generating personalized content and simultaneously recommending users , web pages that , <<< he/she >>> might be interested in , based on his/her personalized content . In this work , we portray a system that/IN not only helps the user in bookmarking the URL and snippets from the web page but also recommends web pages relevant to his/her interest . It applies a content-based filtering"
327	N03_2013	"equivalent phrases on average were acquired , and 920 sentences on average were generated from a source set . Quality of Generated Sentences We randomly selected five sentences per set from above generated sentences and showed them to a Japanese native speaker together with the English sentences . One-by-one , <<< he/she >>> judged whether the sentences were good or not from the viewpoints of Japanese correctness ( grammatically and pragmatically correct or not ) and translation effectiveness ( understandable or not ) . The results are shown in Table 1 . Consequently , approximately 61 percent of the generated sentences were judged"
328	C18_1148	"a likely damage due to the trouble , but the reason ( trouble ) is more important for the answering than the result ( damage ) . Option 7 directly shows that/IN "" "" the questioner is annoyed and wants some advice "" "" , but answerers cannot understand why <<< he/she >>> is annoyed . The detailed implementation of our task is as follows . First we randomly sorted the candidates of each question ( shown in Figure 2(a ) ) to avoid position bias by the workers . We included ten actual questions and a dummy question so that workers would"
329	W13_3712	"noun phrases as well as the verb are nonpredictable . The noun imilla "" "" girl "" "" is NPRED-marked ( i. e. , marked as the most salient part of the utterance ) because in ( 34 ) , it is referred to by the pronoun jupa "" "" <<< he/she >>> "" "" . The analysis of utterances in texts such as stories and narratives reveals that/IN Aymara speakers consequently take intersentential cohesion into account when they decide where to place pragmatic markers . Referent Identification Surface and deep syntax as well as semantics operate on isolated sentences . Now we"
330	C18_1160	"in spam review detection . This is an interesting finding which indicates that/IN spammers may write reviews right after they register at the website . The location difference is more important in hotel than in restaurant . The reason can be that/IN a legitimate user needs an accommodation usually when <<< he/she >>> is out for travelling or business , while a spammer just makes comments and does not care about the location of the hotel . Among the single attributes , removing "" "" hasWeb "" "" results in the decrease of performance in both hotel and restaurant domains . We suppose"
331	W10_0712	"recall score below 60 % , and the rest all had scores above 80 % . While there are still quite a few underperforming workers within the core group of highthroughput annotators , the general trend seemed to be that/IN the more HITs a worker completes , the more likely <<< he/she >>> is to agree with the other annotators . This chart may be directly compared to a similar one in CallisonBurch ( 2009 ) , where the curve takes largely the oppos ite shape . One interpretation of this is that/IN our bonus system had the desired effect on annotator quality"
332	2020_gebnlp_1_8	", she , they and han , hon , hen ( all of which are only tracked as the subjective form ) . Notably , in ME the pronoun he occurs more often than all of the seed words combined for either other gender . Comparing only pronouns , the <<< he/she >>> ratio for the ME corpus is 2.53 and 1.26 for the QE corpus ; han/hon for the MS corpus is 2.58 . Quantitative Results : Occurrence of Seed Words The QE corpus by contrast is much better balanced than either Mainstream corpus , and contains explicit nonbinary representation . 3.75"
333	W14_0113	"be tagged with its hypernymy depending on the context of the word . Marking the word with closest sense : Sometimes the exact sense of a word is not present in the WordNet . If closest sense is available and if the lexicographer has knowledge about its existence , then <<< he/she >>> can assign the tag for the word with the closest sense . 4 . Creating a new sense for the word : There are two situations when the lexicographer needs to create new sense for the word • If the sense of the word is not present in the WordNet"
334	W96_0408	"assessment and writing instruction by [ Rue90 ] . There is a similar principle outlined in [ Kra81 ] with respect to sec-ond language acquisition . Intuitively the knowledge or concepts within the ZPD are "" "" ready to be learned "" "" by the learner . It is what <<< he/she >>> is currently in the process of acquiring . We see our model of the user ( including his/her placement in SLALOM ) as capturing the ZPD with respect to second language acquisition . This has several implications on the responses given by the system . Deciding the Errors to Focus"
335	2013_mtsummit_wptp_9	". For example , suppose the source sentence above yields the following translation ( taken from vanilla Google Translate ) : Section de reconnaissance doit aller une dernière section immédiatement avant les références . Here , not only must the post-editor fix up the text of the translation , but <<< he/she >>> may also need to change the typeface for the whole French sentence , put part of it into bold , and put another part into italic . Each manipulation represents a further loss of productivity . In the example just given , we would like the tag transfer module to"
336	Y16_3011	"measure between the query and sentences from the tagged corpus ; 4 . the proposition of relevant sentences grouped by clusters according to the mode of research ; 5 . the selection by the user of the example which seems to be the closest to his/her input or to what <<< he/she >>> expected to see , thus refining the initial query ( selecting a relevant example narrows the number of matches and increases precision as retrieved segments must be similar to both the query and each newly appointed relevant example 4 ) ; 6 . the output of segments belonging to the"
337	C12_1049	", v ) . Here , y ∈ { 0 , 1 } is the label denoting whether or not learner u knows word v , ( 1 , u , v ) means that/IN learner u knows word v , and ( 0 , u , v ) means <<< he/she >>> does not know word v. Using these notations , the vocabulary prediction task is defined to predict the label y given ( u , v ) . We denote a dataset of N data as = { ( y 1 , u 1 , v 1 ) , . ."
338	O13_3000	"levels as discrete classes , we think readability is continuous . That is , an article that is suitable for students of a certain level must also be comprehensible for students of higher levels . Similarly , if a student can understand an article of a certain reading level , <<< he/she >>> must also be able to understand any article of a lower reading level . Therefore , when building classifiers for lower grade , we use articles of grades 1 and 2 as positive data , while the others are negative data . When building classifiers for middle grade , articles"
339	W09_0907	"and call for detailed experimentation . It is a well known fact that/IN the process of language acquisition by an individual largely governs the course of language change in a linguistic community . In the initial years of language development every child passes through a stage called babbling during which <<< he/she >>> learns to produce non-meaningful sequences of consonants and vowels , some of which are not even used in the language to which they are exposed ( Jakobson , 1968 ; Locke , 1983 ) . Clear preferences can be observed for learning certain sounds such as plosives and nasals ,"
340	Y00_1011	", 0( represents the prospective potential of going through the west gate , and \ the prospective potential of going through the east gate . We can see conjunctive prospective potentials in R in Figure 3 . It represents that/IN each passenger can get through the west gate and that/IN <<< he/she >>> can also get through the east gate . R has these two prospective potentials , therefore P with west-gate-prospective-potential is accessible from R , and Q with east-gate-prospectivepotential is accessible from R , too . Let us consider a case in which your tour guide has told you the following"
341	2021_wanlp_1_36	"of 100 hidden test questions that appear randomly during the task , each of those questions has the correct label for sentiment , sarcasm and dialect . If the performance of an annotator in these test questions dropped below 80 % , this annotator is eliminated and all the labels <<< he/she >>> provided are also ignored . Agreement among annotators was 78.9 % for sentiment , 87.3 % for sarcasm and 77.0 % for dialects . Dataset Statistics The new ArSarcasm-v2 dataset consists of 15,548 tweets , 10,547 of them were taken from the original ArSarcasm dataset while the rest ( 5,001"
342	2021_acl_long_314	. Suggestions from improvements : The student suggests one or more improvements that are mostly relevant for the further establishment of the activity . The suggestions are written only on a high-level and most of them do not include further explanations or examples . The student explains only occasionally why <<< he/she >>> suggests a change or how it could be implemented . = very weak The student does not try to understand the peer ' s perspective . The student rather just tries to accomplish the task of giving feedback . Strengths : The student mentions one or more strengths . They
343	W05_0306	"in the text is split to some bunsetsu-phrase chunks 1 , as shown in Figure 1 ( "" "" / "" "" indicates a bunsetsu-phrase chunk boundary ) . Second , for each bunsetsu-phrase , an annotator finds the segment which represents a head element of an event , and <<< he/she >>> adds the head tag to the segment ( see also head 1 and head 2 in Figure 1 ) . If the event has any other elements in addition to head element , the annotator also adds the mod tags to the segments representing modifiers to the head element ("
344	Y13_1035	"… . , "" "" thus the content of the tagged tweets should be the description on an event because the tag is just the revelation of the judgment from the tweeter . Namely , the speaker ' s intention revealed in the tag is his/her attitude to the event <<< he/she >>> perceives when he/she is the audience . The fourth question is that/IN Clift ( 1999 ) thinks sarcasm is one type of irony . The speaker may be or may be not aware of ironic utterance , but the/she must be aware of his/her sarcastic utterance . Thus , there"
345	W11_2852	"feedback is feedback on what is visible for the user , based on what we think the user wants or needs to know . Confirmation that/IN the user is looking at the correct object can be really useful and can make the user more confident . Telling the user that/IN <<< he/she >>> is looking at the wrong object prevents wrong button presses , and makes navigation through the world more efficient . When giving anticipating feedback on visible buttons we distinguish five situations : • Only the target button is visible : in this case the system confirms that/IN this is the"
346	W00_1110	"is the MySearch search engine . When a user submits a query , the screen in Figure 5 appears . As can be seen from Figure 5 , there is a check box along with each retrieved record . This allows the user to tell the summarization engine which documents <<< he/she >>> wants to summarize . After the user clicks the summarization button , the summarization option screen is displayed as shown in bottom of Figure 6 . The summarization option screen allows a user to specify the summarization compression ratio . Figure 7 shows the summarization result for four URLs with"
347	W17_3808	"one of the grammars ' paths . This index file is what we use to display the correction to the player . The final result is displayed to the player as a correction to his/her mistakes . Experimentation The player explores the terrain searching for a sound source , once <<< he/she >>> finds it ; he/she will be able to control the listening with a keyboard key . When the player finishes listening to the French dictation , a new panel appears , giving him a place to write the sentence heard ( Figure 2 ) . After writing the sentence heard"
348	W13_5632	"about intonation patterns of a given language can be made through the computer-aided analysis of a real world intonation phenomena . It would be of a great help to a human expert if similar intonation patterns are collected together and presented to him/her in a user-friendly way . Then , <<< he/she >>> could assign these collections to particular intonation categories , construct "" "" an inventory "" "" of intonation patterns , easily detect and eliminate "" "" false "" "" members out of these collections , mark pitch accents and boundary tones in a more uniform way . This paper describes"
349	P10_1070	"agreement study , we chose to request ten annotations per noun compound and then combine the annotations into a single set of selections using a weighted voting scheme . To combine the results , we calculated a "" "" quality "" "" score for each Turker based upon how often <<< he/she >>> agreed with the others . This score was computed as the average percentage of other Turkers who agreed with his/her annotations . The score for each label for a particular compound was then computed as the sum of the Turker quality scores of the Turkers who annotated the compound ."
350	P17_4007	"gather the context for the CRF-SVM and RNN models ) . If the user reacts to this frame ( by pressing Correct/Incorrect button ) , we store the feedback and move to the next ENE in our database . This involves the user in a language learning game and helps <<< he/she >>> to study many new words as well as grammatical constructs . User feedback statistics In this section , we show some statistics that/IN we derived from the user feedback log of the Mazii News service . We collected the user feedback log ( including the view , click and correct"
351	P04_3001	"communications between the UI and the PE are the following : 1 . To initialize the PE , the UI calls a generic create method API function with the appropriate parameters required by each PE and checks its successful completion . 2 . Once the user has selected the file <<< he/she >>> wants to work with , the UI produces a list of text segments ( sentences ) and displays them in the source text pane of the interface . 3 . The selection of a source sentence is communicated to the PE by the UI . The sentence becomes the source"
352	2003_mtsummit_papers_16	"determiner + ' injured'-instead of atender os feridos -'see ' + determiner + ' injured'-'see the injured ' ) , incorrect placing of pronouns ( me dixo instead of díxome ' he/she told me ' ) , use of compound tenses -non existent in normative Galician-(había feito por fixera ' <<< he/she >>> had done ' ) , reflexive verbs -non existent in normative Galician-(sentouse no chan instead of sentou no chan ' he/she sat on the floor ' ) ... Interferences , besides the structural similarity between the two languages at issue , constitute a handicap in the task of designing grammars"
353	P19_2004	"and inflectional morphemes in Yupik is conditioned by morphophonological rules that apply at each morpheme boundary and obscure them , rendering a surface form that may be unrecognizable from the glossed form , as in ( 7 ) : ( 7 ) kaanneghituq kaate--nghite--u--q arrive--did . not--INTR . IND--3SG ' <<< he/she >>> did not arrive ' ( Jacobson , 2001 , p.43 ) Moreover , each morphophonological rule has been assigned an arbitrary symbol in the Yupik literature ( Jacobson , 2001 ) , and so , every derivational and inflectional suffix can be written with all of the rules associated with"
354	2022_acl_long_541	"of offspring being produced . This falls into the same category of not using contraceptives , getting abortions , etc. It is not a sin for a gay person to acknowledge their sexuality , or to act in a ' gay ' manner . It is only a sin if <<< he/she >>> gives in to their urges . [ ... ] Here , the annotators disagreed in the annotation of the entire argument . Although the debater clearly states that/IN actually being gay is not a sin , in his opinion , living a homosexual lifestyle is a sin . It appears"
355	J86_2002	". Such security and privacy considerations can be important for certain classes of users . All of this is currently possible , although not something we have actively experimented with . An extension to this capability might make it possible for the user to customize the kinds of summary responses <<< he/she >>> receives , rather than relying on the database manager to provide him/her with the appropriate user model . Whether to have the user fill in a template corresponding to each attribute frame , or whether to use natural language to specify the information in the various attribute frames is an"
356	2007_mtsummit_papers_55	"control means that/IN users can control the process of the translation engine as much as they want to do . If a user is relatively poor in English , he/she may put emphasis on the rewriting of the Korean sentence . If he/she wants to get professional translation quality , <<< he/she >>> is going to revise all the errors from the engine . The level of engine control can be set by the user . For provision of sufficient information to fix the errors generated by the engine , the MT system provides the morphological/syntactic analysis result and the generation result to"
357	K19_1079	"k. For both models , as k increases , noun concreteness reduces and verb concreteness increases . See Section 9 for discussion . Prompt : In an alternative reality where sleep is non-existent among living beings , our protagonist ( spontaneously or after an event ) falls asleep in which <<< he/she >>> experiences for the first time in human history what a dream is . GPT2-117 ( k = 1000 ) : I sat in my bed as my girlfriend sat behind me , buzzing into her e-reader , letting the day ' s stories write themselves on her ' s monitor"
358	S14_2094	"post-editing an untranslated fragment , a human translator would ( i ) first query a translation memory or parallel corpus for the untranslated fragment in the source language , ( ii ) then attempt to understand the various context that/IN the fragment can occur in and ( iii ) finally <<< he/she >>> would surmise appropriate translations for the untranslated fragment based on semantic and grammatical constraints of the chosen translations . The PEZ system was designed to emulate the manual post-editing process by ( i ) first crawling a web-based translation memory , ( ii ) then extracting parallel sentences that contain"
359	2007_mtsummit_papers_55	"between a Korean word and its English word . As in Figure 2 , if a user points a Korean/English word , their corresponding words are highlighted at the same time in all windows . Therefore , if a user finds an unexpected translated word while scanning the result , <<< he/she >>> can know on the spot where mis-translation came from . Modification can be done at any window and the modified results are reflected in all three windows at the same time . Korean-English Translator Korean-English Translator ____ _____ ____ __ ___ ___ ___ __ ___ ____ __ ____ ____ IP"
360	Y00_1004	"repetition does not occur between two people , but is found within the speech of a single individual . Rapid repetition of a word , usually in a sequence of up to four repetitions , will act as a light emphatic to indicate the speaker ' s eagerness towards what <<< he/she >>> is saying . It can also have the effect of softening the statement and making it sound friendlier towards the listener . One other type of repetition was encountered , and again it occurred within the speech of a single individual . This was when the speaker repeated a phrase"
361	Y13_1035	"  thus the content of the tagged tweets should be the description on an event because the tag is just the revelation of the judgment from the tweeter . Namely , the speaker ' s intention revealed in the tag is his/her attitude to the event he/she perceives when <<< he/she >>> is the audience . The fourth question is that/IN Clift ( 1999 ) thinks sarcasm is one type of irony . The speaker may be or may be not aware of ironic utterance , but the/she must be aware of his/her sarcastic utterance . Thus , there should be overlapped"
362	W10_1301	"messages and by divergence from the timetable , e. g. a different teacher present or a different location . The system selected the five most ' interesting ' events and displayed them to the child in a simple visual editing interface . In this interface the child could delete events <<< he/she >>> did not wish to talk about , and also annotate events with simple opinions ( evaluations ) , such as I liked it , using the evaluation buttons on the interface , generating appropriate utterances according to the last narrated event or message . ( see Fig. 2 ) ."
363	T87_1041	"system be matched . By looking at the sentences or texts a system generates , the user may ascribe comprehension capabilities to the system , which the system may or may not have . In other words how will generation affect user ' s behavior with respect to the input <<< he/she >>> provides to the system ? • Are knowledge structures of the world as much as language , the same or different for comprehension and generation ? • How does one control for syntactic choice and lexical choice ? • What is the status of different grammatical formalisms with respect to"
364	W10_3210	"causal relationship , because in a contrast relationship A is positive and B is negative , while in the negation of causal relationship , the A is negative . Besides those relationships between events described above , the annotator could tag the relation as "" "" Underspecified "" "" if <<< he/she >>> feels that/IN relationship belongs to a new kind and deserves to be annotated . These relations are also annotated with the attributes similar to those of events , but only including Polarity , Modality , Tense , Aspect and Source . Annotation of Functional Attributes The annotation of relations among"
365	2022_udfestbr_1_6	"upload the treebank , users just have to click on the blue button labeled Choose file and select in their operating system the CoNLL-U file that represents the treebank . Simple Searches After uploading the treebank , users will be redirected to the search screen . In that screen , <<< he/she >>> will have to specify their query parameters filling out a search input , which is shown in Figure 2 . The selector highlighted in red allows the user to choose between five properties ( all defined in the UD specifications ) to search for in the uploaded treebank : forms"
366	1997_mtsummit_papers_17	") ; so translation is a first step to make the text understandable . This problem can be tackled by any of the technologies just described ; evaluators should have the choice to select the tool they want to use . • If an analyst has a search problem , <<< he/she >>> will have to search foreign language databases ; be it structured ( cf. different translations for places , different transliterations for names , etc. ) or textual . Often , the optimal search term in the foreign language is not known ( e. g. a German analyst searches for Kokainhändler"
367	Y07_1009	"write-CAUS-PRES ' : c 4 r c 3 r c 1 r s 1 oti-sase-ru ' drop-CAUS-PRES ' : c 6 r c 4 r c 1 r s 1 As Harada ( 1973 ) notes , ni-causatives are possible only when the causee holds control over the action that/IN <<< he/she >>> performs . Since ' to drop ' is usually not considered as a self-controllable action , the causative verb otisaseru has type c 6 r c 4 r c 1 r s 1 but not c 6 r c 3 r c 1 r s 1 1 . The typing"
368	2020_lrec_1_701	"( to current situation ) and negative emotion ( to expectation ) with the word "" "" _""""(wait ) . From the first sentence we know that/IN the listener always ( at least , often ) take care of "" "" her "" "" , so it is obvious that/IN <<< he/she >>> does not want "" "" her to get hurt "" "" . Therefore , the clause X meet the condition . Then the contextual meaning turns to be "" "" you should be regretful when she gets hurt "" "" and the evaluation and sentiment of the sentence are negative"
369	2020_rocling_1_25	". For instance , in teaching the sentence "" "" nĭ jiào shénme míngzi ? What is your name ? "" "" in spoken speech "" "" shénme : what "" "" always go together . If a learner only learns this through reading then it is highly likely that/IN <<< he/she >>> will always introduce a pause in between "" "" shén "" "" and "" "" me "" "" and another pause between "" "" míng "" "" and "" "" zi "" "" . However , in prioritising the spoken over the written language in this course , the teacher"
370	L16_1322	"topics , containing discussions that happened over a period of 15 years . The dataset contains 166,322 discussion threads , across 1236 articles/topics that span 15 different topic categories or domains . The dataset also captures whether the post is made by an registered user or not , and whether <<< he/she >>> was an administrator at the time of making the post . It also captures the Wikipedia age of editors in terms of number of months spent as an editor , as well as their gender . This corpus will be a valuable resource to investigate a variety of computational sociolinguistics"
371	J86_2002	"it , or may not be able to make the inferences needed to deduce something that/IN he/she has the knowledge to deduce . For example , the user may know the names of all the students who failed CMPT 110 but not realize these are the only students ; or <<< he/she >>> may know everybody who did n't write the final examination and also the rule that/IN if the final examination is missed a student fails the course , but the user may not have applied the rule in this case . Finally , for some extensional responses , it still might"
372	W18_4515	"literary texts can span hundreds of pages , which poses a challenge for the annotators . For pronominal reference this is not problematic , as pronominal coreference is limited with respect to the attention span of the reader in every text , i. e. the author chooses a pronoun when <<< he/she >>> can be sure that/IN the reader remembers the referent/antecedent . Cases of nominal coreference , however , might now span hundreds of pages . One example for a text which is broken up into different planes and surrounded by a frame story is the appearance of Scheherazade in One Thousand"
373	D18_1225	"entity prediction . The main motivation for this task is to deal with the relational conflict between two entities at a particular time-scope . For example , given the year 1992 , a person ' X ' and a city ' Y ' , one would like to know if <<< he/she >>> was bornIn or diedIn that/IN city in that year . Through the explicit use of temporal information during training , we find that/IN our method HyTE outperforms the baseline methods in both the datasets ( as shown in 6.1 ) Temporal Scope Prediction Given the scarcity of time annotations of"
374	W14_0210	"reveal dialog features which can be used for improvement of the navigation itself and later it can help to replace the human navigator with automated system . Initial analysis showed that/IN the type of location may have impact on strategy , how the blind person explore his/her surroundings and how <<< he/she >>> tries to get oriented . In city center streets ( track A ) and in building ( track C ) the blind persons were able to explore their surroundings and they allowed the navigator to find out , where they probably are . In open city park ( track B"
375	W03_2128	", Strandson 2001 ) . Our typology of repairs is similar to questionanswer APs because most of the initiations of repairs are questions in Estonian . We differentiate three types of repair initiations . The first type is the clarification where the hearer repeats the previous information to check whether <<< he/she >>> understood it right or not . Formally , there are questions that offer answer . The second type is the re-formulation where the hearer offers his/her interpretation of previous information . It may have several forms . Questions that are used for repair initiation differ from information questions by their"
376	W19_6301	"of frequent words occurring in the domain of , for example , sports , it is very probable that/IN he/she knows another high-frequency word from this domain . However , if the learner does not know a lot of lowfrequency words from the domain , it is not probable that/IN <<< he/she >>> knows another low-frequency word from this domain . To operationalize this idea , we need to use a combined measure which would not only reflect the amount of known words but also the frequencies of the known words in a particular domain . The calculation of the learner-specific features is"
377	I13_1090	"humans . The current features are : Uncertain and Problematic . An alignment is marked as uncertain when the proofreader is not confident in the correction . This type is specific to the proofreading process . When the native proofreader is doubtful about his/her understanding of the original sentence , <<< he/she >>> will comment on it by stating "" "" I do not understand this , "" "" or "" "" This correction is a guess "" "" . An alignment is classified as Problematic when the annotators discover that/IN the proofreader has made an erroneous correction . This happens when the"
378	W06_2111	"stressing that/IN this does not mean that/IN they require a third person singular subject , but rather that/IN they themselves are third person singular . This distinction is especially relevant for the finite verbs , as illustrated by ( 30 ) and ( 31 ) . ( 30 ) That <<< he/she >>> snores is/*are/*am annoying . ( 31 ) That I/they snore is/*are/*am annoying . Also here the subjects are required to have a third person singular index , and since they are clauses which are headed by a finite verb , it follows that/IN the finite verbs have a third person"
379	Y13_1035	" aggressiveness  "" has been pointed out from Clift as well as Lee and Katz to be the feature distinguishes sarcasm from irony . Hence , it should be reasonable to hypothesize that irony should have two senses . In one sense , the speaker is aware of what <<< he/she >>> says is opposite to what is intended to mean . The second sense is to be distinct from sarcasm in being not aggressive and without awareness . The Reason to Take Twitter as the study target : Current study is going to explore the characteristics of sarcasm and irony from"
380	2020_eamt_1_42	"from scratch is computed , which is not possible for us due to time and budget constraints ( this limitation is further discussed in Section 3.4 and 6 ) . At the end of the task , the post-editor is asked to fill in a feedback form , in which <<< he/she >>> rates the quality of the whole output assigning a score from 1 ( worst score ) to 5 ( best score ) to each of the following categories : accuracy , fluency , terminology translation , formatting and punctuation . An optional field for comments is also provided . For"
381	H05_1074	"Although the algorithm failed to tell the causal direction between some pairs of variables , it suggests that/IN the four variables influence each other . This may be an inherent property of the document ; or because a user is likely to rate one aspect of the document higher than <<< he/she >>> should if the other aspects are good . One may ask why the structure in Figure 4 contains no link between readable and readability score , since intuitively it should exist . To answer this question , one needs to understand that/IN the causal relationships learned automatically are what the"
382	Y18_1037	"of surprise are more aware of the triggering events . We notice that/IN the adverb _ tends to appear in the questions expressing sadness than the other emotions . The use of _ implies the meaning that/IN the situation will turn out to be negative to the speaker , but <<< he/she >>> is not capable of preventing it from happening . Thus , it is oftentimes used to express sadness . Consider ( 11 ) . ( 11 ) __________？ ( Is my brother going to be eaten ? ) Besides , questions expressing sadness may be formed with rhetorical interrogations ,"
383	Y12_1045	"with a de re interpretation ) , we do not think the obligatory de se reading of ziji in speech reports is definitely required . According to our intuition , there is no problem for the speaker to utter the sentence in ( 17 ) in the second scenario if <<< he/she >>> knows that/IN it is Zhangsan ' s purse that got lost , and then empathizes with Zhangsan , taking Zhangsan ' s point of view . According to the literature , the empathic use of long-distance reflexives has already been detected in other languages such as Japanese ( Kuno ,"
384	2021_sigmorphon_1_21	"associated with the same noun ( Tarpent , 1987 ; Davis , 2018 ) . That is , the conditioning factor for this alternation is syntactic , not morphophonological . http : //www . inuktitutcomputing . ca/ Uqailaut ( 6 ) Realizations of gup-i-t=hl ( eat-TR-3=CN ) a. gubithl ' <<< he/she >>> ate ( common noun ) ' b. gubihl ' ( common noun ) ate ' The available set of resources further constrained our options for the analyzer ' s design and our means of evaluating it . The H&R wordlist is quite small , and of only a single dialect"
385	W19_8102	"data . To alleviate such drawback , it is important to take previous experience of story-writing into account . Imagining when a person starts to tell stories from images , he/she may not understand the implications in those images and fail to write a proper story . However , if <<< he/she >>> had heard others telling stories , he/she may be able to tell a story from the stories of similar image sequences he/she previously heard . Motivated by such process , we propose to utilize the large corpus as an inventory and improve the visual storytelling model by including stories from"
386	P05_1037	"adjacent , and produced by different speakers ( Galley et al. , 2004 ) . In our email/chat ( LKA ) corpus a physically adjacent message , following the timeline , may not directly respond to its immediate predecessor . Discussion participants read the current live thread and decide what <<< he/she >>> would like to correspond to , not necessarily in a serial fashion . With the added complication of subtopic structure ( see Figure 1 ) the definition of adjacency is further violated . Due to its problematic nature , a relaxation on the adjacency requirement is used in extensive research"
387	2020_eamt_1_20	"whether they thought the translations had been produced by MT systems or by humans , all evaluators replied that/IN some were by humans and some by MT systems , except one translator , who thought that/IN all the translations were by MT systems , and one non-translator who answered that <<< he/she >>> did not know . Conclusions and Future Work We have conducted a modified evaluation on the MT systems that reached human parity or superhuman performance at the news shared task of WMT 2019 . According to our results : ( i ) for English→German , the claim of super-human performance"
388	W16_2604	"universal release , if no German version exists ) . The timestamp was extrapolated as the more recent of these two dates : a member cannot post a walkthrough or other tip for an existing game on the website before being registered , and even as a registered member , <<< he/she >>> cannot post a walkthrough or anything similar about a game which has not been released yet . The format of the timestamps was mixed ; they were therefore reduced to only the posting year . It turned out later that/IN on the profiles of members , their last postings were"
389	W15_2905	"the past ( we refer to this as ' historical tweets ' ) . Consider the example in Figure 1 . The author USER1 wrote the tweet ' Nicki Minaj , do n't I hate her ? ! ' . The author ' s historical tweets may tell us that/IN <<< he/she >>> has spoken positively about Nicki Minaj in the past . In this case , we observe an additional tweet where the author describes having a good time at a Nicki Minaj concert . This additional knowledge helps to identify that/IN although the target tweet contains the word ' hate '"
390	C12_2126	"articles mainly talk about the occurrence of the earthquake and the consequence of the earthquake , and the later articles talk about the consequence of the earthquake and the rescue issues . In this case , the reader will read the later articles to know about the rescue issues after <<< he/she >>> has read the earlier articles . Therefore , an update summary of the later articles may facilitate the reader to grasp the "" "" update "" "" information in a very convenient way . The update summarization task can be formulated as follows : Given an earlier document set D"
391	2020_rocling_1_25	"message . In other words , in terms of perception , the structuring activity implies re-ordering , usually in an unconscious way , by selective filtering out of redundant data that are usually perceived globally . For instance , in production , the learner must structure the non-linguistic experiences that/IN <<< he/she >>> wants to talk about so that/IN the available extra-linguistic and linguistic means can be applied to it . Before we describe the structuring activity through SEA in detail , it is essential to understand what makes up a speech sound . Take the sound [ i ] in French ."
392	I13_1185	"subject to loaning and synonymy . If the translator has a choice for translating a preposition/affix and neither of the possibilities is similar to the source language , nor a loanword or structurally similar , he/she will go for the predominant word or structure of the target language ( since <<< he/she >>> is a native of the target language by translation industry standard ) , making the translation less different from native text . The data can be influenced by many additional variables such as differing translation paradigms influencing the choice of structures ( free translation vs. faithful translation ) , different"
393	C90_3072	"form radionuklidy ( radionuclides ) , first the user deletes the ending -y ( which is one of the plural endings ) . Then he/she selects "" "" noun "" "" as the basic class ; then "" "" masculine inanimate "" "" is the right choice . Then , <<< he/she >>> should select radionuklidu as the right form which can follow the preposition bez ( without ) , and state that/IN radionuklida is not correct in this case . The last selection conceres the preposition o ( about ) , after which radionuklidu is the only possibility ( as opposed to"
394	W18_6401	"as submission of inconsistent evaluations and even robotic ones . We therefore employ DA ' s quality control mechanism to filter out low quality data , facilitated by the use of DA ' s analogue rating scale . Assessments belonging to a given crowdsourced worker who has not demonstrated that/IN <<< he/she >>> can reliably score bad reference translations significantly lower than corresponding genuine system output translations are filtered out . A paired significance test is applied to test if degraded translations are consistently scored lower Repeat Pairs : Original System output ( 10 ) An exact repeat of it ( 10 )"
395	2020_bionlp_1_14	"vector machine ( SVM ) anomaly detector ( Erfani et al. , 2016 ) . This method is useful in practice when majority of a subject ' s speeches over several years would be ( statistically ) typical of a healthy control ( "" "" normal "" "" ) until <<< he/she >>> begins to exhibit early signs of AD . Our hypothesis is that/IN early stage AD will begin to reveal itself as statistical anomalies in linguistic feature space . In this section we investigate this hypothesis . We designed a one class SVM with the following hyperparameter values ( the choices"
396	Y15_1038	"and gesture in conveying metaphors is discussed to evaluate the theoretical hypotheses . The Lexical Semantic Hypothesis suggests gestures are generated from the semantics of the lexical items . If a person has difficulty to produce a word for a concept in language , the production of gesture may help <<< he/she >>> to search a lexical item for such a concept . Hence , it is claimed that/IN a gesture usually precedes the lexical component it depicts . The Interface Hypothesis , on the other hand , suggests that/IN gestures are generated from the interactions between speaking and spatial thinking . In"
397	R13_1065	", he/she assumes that/IN by explaining the reasons to the requestee and the requestee ' s potential understanding of the reasons of his/her request may increase the likelihood of the fulfilment of a request . Consequently , the requester appeals to the empathy and imagination of the requestee , since <<< he/she >>> considers their influence as an effective strategy . Factor F7 -mitigating devices -reduce the impact of a request on the requestee , in terms of whether the requester does not interfere or over-interfere with his/her request in the requestee ' s time , space or decision making . Association rule"
398	W11_2134	"recognition and neural transfer which are described further below . Recognition of pronoun reference Pronouns can refer to other words ( their antecedents ) which had occurred in the previous text . When translating from German into English and vice versa the fact that/IN e. g. the English personal pronouns <<< he/she >>> apply only to humans and it to all other things , whereas in German er/sie/es can refer to any noun , has to be considered when searching for appropriate translation : This is a desk . It is new . Dies ist ein Schreibtisch . Er ist neu . versus"
399	W11_4610	"translate texts from the same domain in different situations of translation . Indeed , if a translator translates a text from domain A in situation 1 , he/she must not translate a text from domain A in situation 2 : there is a risk that/IN the translator re-uses some terms'translations <<< he/she >>> has learnt in the previous situation . A critical point when judging the translation of technical texts is that/IN the judges often lack domain expertise and that/IN domain experts are rarely available . One can get round this trouble by choosing specialized texts which already have an existing translation ,"
400	2020_paclic_1_49	"by them . Ishikawa and Maekawa ( 1996 ) showed that/IN there is a specific order of infants ' development in the picture book readings and daily lives . For example , they indicated that/IN before an infant learns how to turn pages and return to the proper page when <<< he/she >>> notices that/IN he/she skipped a page , he/she who had not cared about skipping pages experiences preliminary stages such as "" "" prefer picture books showing concrete daily life items and very few stories and sentences "" "" and "" "" prefer picture books having repetitive construction of pictures and"
401	L16_1336	"Additionally , they showed that/IN words associated with a particular color may express the same sentiment as the color . Lafourcade et al. ( 2014 ) constructed the first resource for French word-color associations . The researchers implemented a game in which players were asked to identify a color that/IN <<< he/she >>> associated with a given word . They were able to collect more than 15 , 000 words that were associated with one or more colors . Our work differs from the above-mentioned efforts in that we constructed a resource for Japanese word-color associations . As described in Section 3 ."
402	2011_eamt_1_6	"Country , Spain ; University of Evora , Portugal ; Minho University , Portugal ; Harbin Institute of Technology , China ; Koç University , Turkey ; University of Saarland , Germany ; University of Eastern Finland , Finland . Usage The user will log on to a portal where <<< he/she >>> can make a request for translating a document via a gateway . Alternatively , upload via API can be done for users who want to integrate BTS into their content repository . For instance , the individual user logs on to the local education database , opens a document and"
403	J03_4002	"interpreted as warning the hearer ( H ) that/IN H might get hurt if he/she transports the dog in some way other than carrying it ( e. g. , H might get tangled up in its lead ) . In ( ii ) , the otherwise clause warns H that/IN <<< he/she >>> might get hurt if what she is carrying is not the dog ( e. g. , H might be walking past fanatical members of the Royal Kennel Club ) . α = otherwise R α = if S 38 = you [ λx . if(VE 38 , x ) ]"
404	W19_7509	"data is presented in the interface , lesson by lesson . In this interface , the teacher chooses a school curriculum board ( CBSE , ICSE , State Board , etc. ) ; followed by a class to which he/she wants to teach ; followed by a lesson/chapter . Once <<< he/she >>> clicks on a chapter , all the words from that chapter appear in the order in which they appeared in the textbook . While teaching , teacher can simply click on any of the word from the list and the word-specific information with the same sense is displayed accordingly in"
405	1994_bcs_1_8	"understandable output . However , in order that/IN a translated message sound as natural as possible , it should be conveyed in accordance with the discourse organisation rules of the target language . If we examine more closely the work of a professional translator , we shall inevitably note that <<< he/she >>> does not follow always the order of sentences in the source text . Taking into account the complexity of paragraph understanding and the necessity of observing the specific target sublanguage rules , we have proposed a practical discourse-oriented MT approach ( within an English to Malay MT system ) which"
406	2021_emnlp_main_355	"improve CRS , but have not full appreciation of the advantage of tracking interest shift in KG . The second issue is that/IN KGs are usually incomplete to track the path of interest shift . For example , in Figure 1 , the user mentioned the two movies probably because <<< he/she >>> likes "" "" Nolan "" "" and "" "" Di-Caprio "" "" . Multiple paths in KG help to locate the subspace of the user ' s interest and generate interpretive utterances in line with people ' s dialogue behavior , e. g. , "" "" ... Inception with Christopher"
407	W10_1001	"the target reader . A method for automatically identifying such level of complexity is therefore of great value . With our readability assessment tool , the author is able to automatically check the complexity/readability level of the original text , as well as modified versions of such text produced as <<< he/she >>> applies simplification operations offered by SIMPLIFICA , until the text reaches the expected level , adequate for the target reader . In this paper we present such readability assessment tool , developed as part of the PorSimples project , and discuss its application within the authoring tool . Different from"
408	D14_1143	"vocabulary prediction , we used the dataset that/IN Ehara et al. ( 2010 ) and Ehara et al. ( 2012 ) used . This dataset was gleaned from questionnaires answered by 15 English as a second language ( ESL ) learners . Every learner was asked to answer how well <<< he/she >>> knew 11,999 English words . The data was collected in January 2009 . One learner was unpaid , whereas the other 15 learners were paid . We used the data from the 15 paid learners since the data from the unpaid learner was noisy . Most of the learners were"
409	W14_5119	"platforms could be effectively employed in acquiring a second language using contextual learning . This application is more helpful to tourists as adults are often busy and do not have the time to go through books which give an insight to a language that is spoken in other states if <<< he/she >>> visits a different place to cope up with transport , directions , food etc. This helps learning environment to be mobile and anytime anywhere . Future Work Our study for this paper paved a way to work further in this area of language learning using pictures and gestures . Important"
410	W06_2804	"means people ' s classification management . investigated . The informality of the language has been measured through the frequency of abbreviations , acronyms , contractions ( I ' m , do n't , he ' s , etc. ) and personal pronouns ( I , we , you , <<< he/she >>> , they ) which have been found to be typical of informal genres , such as face-to-face and phone conversations ( Biber , 1988 ) . As shown in Appendix A ( Fig. 1 ) , the first results of this research conducted on one hundred articles have highlighted a"
411	C92_4182	"compound ilOUll pllra-~es , which ~tre COlnlUOll ill telephone inquiry dialogue . Introduction A high-quality spoken-language processing system must use knowledge of dialogue and spoken-language . Using dialogue knowledge facilitates understanding and predicting utterances in context . Using spokenlanguage knowledge , that is knowledge about how tile speaker expresses what <<< he/she >>> wants to say , makes it possible for the system to recognize and generate the more complex expressions that are nornmlly ased ill our daily dialogues . To make language processing in the whole spokenlangnage processing system more efficient , it . is vital how to select the correct speech"
412	Y09_2053	"both at Levels A and B ( see Onoe 1999a ) . ( ii ) Inconsistency between classification criteria The distinction between Levels B and C may be drawn drastically differently , depending on which of the three following classification criteria may be adopted ( Onoe 1999a PST ' While <<< he/she >>> was studying hard , since the exam given on the following day would be harder , he/she had a call . ' The sentence above gives strong evidence against the Minami hierarchy , since the subordinate clause headed by kara is embedded in the clause introduced by to , while"
413	2020_findings_emnlp_375	"an adequacy score lower than 50 % while the human translation received a score higher than 50 % . Like English to German , however , for German to English translation , the reverse is also true , there are translations that catch out the human translator , for which <<< he/she >>> received a low score , while for the same source input , the machine receives a high score . Such translations , there are six in total ( 1.2 % ) , are located in the bottom-right quadrant of Figure 6 . Table 3 shows the most extreme examples in"
414	2020_paclic_1_49	"Ishikawa and Maekawa ( 1996 ) showed that/IN there is a specific order of infants ' development in the picture book readings and daily lives . For example , they indicated that/IN before an infant learns how to turn pages and return to the proper page when he/she notices that/IN <<< he/she >>> skipped a page , he/she who had not cared about skipping pages experiences preliminary stages such as "" "" prefer picture books showing concrete daily life items and very few stories and sentences "" "" and "" "" prefer picture books having repetitive construction of pictures and sentences . """
415	W14_2710	") . We also compute a softer notion of topic shift where we measure the average Euclidean distance between topic probabilities of each of the candidate turns and turns prior to them ( EuclideanDist ) . This feature in essence captures whether the candidate stayed on topic , even if <<< he/she >>> did not completely switch topics in a turn . Topic Shift Sustenance Patterns We use a feature to capture the average number of turns for which topic shifts by a candidate was sustained ( TS SustTurns ) . However , as discussed in Section 4 , the turns vary greatly"
416	W19_5301	"submission of inconsistent evaluations and even robotic ones . We therefore employ DA ' s quality control mechanism to filter out low quality data , facilitated by the use of DA ' s analogue rating scale . 16 Assessments belonging to a given crowdsourced worker who has not demonstrated that/IN <<< he/she >>> can reliably score bad reference translations significantly lower than corresponding genuine system output translations are filtered out . A paired significance test is applied to test if degraded translations are consistently scored lower than their original counterparts and the p-value produced by this test is used as an estimate of"
417	1999_mtsummit_1_89	"application or another text . That is , when typing the target text , the user can select a ( the ) translation of the word in question and pastes it into the text . This is how the user does that . When in the dictionary entry window , <<< he/she >>> selects an entry element and clicks on the Copy button to copy the selected text into the Clipboard , or drags the selection to the target application . If a tilde is present in the selection , it will be automatically replaced with the word it substitutes Brackets , semicolons"
418	X96_1047	"activity involving that post ( if an article describes a person leaving and a person starting the same job , there will be two IN_AND_OUT objects ) . The IN_AND_OUT object contains references to the objects for the PERSON and for the ORGANIZATION from which the person came ( if <<< he/she >>> is starting a new job ) . The PERSON and ORGANIZATION objects are the "" "" template element "" "" objects , which are invariant across scenarios . "" Towards a Methodology for Named Entities Annotation Today , the named entity recognition task is considered as fundamental , but it"
419	W18_1923	". Instead , we opted to emulate another interaction most people are familiar with : a TV interview , where one person with a microphone interviews the other . Several aspects made this way of interacting stand out : • All devices are in possession of the soldier , and <<< he/she >>> can decide how far or close the microphone is to the FLE • The act of physically pointing the microphone either at the soldier ' s mouth or at the FLE ' s mouth is an implicit queue of "" "" it is your/my turn to speak "" "" ."
420	2020_acl_main_72	"because we need to focus more on terms with flexible granularity for in-depth analysis ( Takeuchi et al. , 2009 ; Godbole et al. , 2010 ; Mostafa , 2013 ) . For instance , if the analyst wants to examine product evaluation from both its function and appearance , <<< he/she >>> then needs to separately create those dictionaries whose boundaries are vague and overlapped ( Figure 1 ) . In short , we need to group any terms the analyst wants together depending on documents and the objective of analysis , which forces an ad hoc construction of the term dictionary"
421	2005_jeptalnrecital_recital_9	more important than the actual formulation or style of the sentences . In the context of medical examination it is important that/IN the patient feels comfortable and confident . Even more so if the questions are asked by a doctor speaking a language the patient does not understand and if <<< he/she >>> is listening to the translations of the questions spoken out by a machine . Thus the output of the MT system should sound as natural as possible . For the Finnish output the aim was to preserve the simplicity of the original English questions without letting the translation be influenced
422	2021_acl_long_384	"check valves "" "" . of the conversation independently , which may lead to contradictions in the SOAP note . In one visit , the patient was asked about chest pain twice-once in the beginning to get to know his/her current state , and once as a question about how <<< he/she >>> felt just before experiencing a fall in the past . This led to the model generating both that/IN the patient denied chest pain as well as confirmed chest pain , without clarifying that/IN one statement was for the present and another for the past . CLUSTER2SENT summarizes localized regions Human"
423	W03_2128	"questions himself/herself . Such act is called adjusting the conditions of the answer ( example 6 ) . The third possibility is to avoid the reaction . A too general request or question is followed by a pause . The fourth possibility is that/IN the answerer refuses to answer but <<< he/she >>> proposes another way to the partner to get the needed information ( per email , fax , to go to the office , etc. ) . In human-computer interaction it can be supposed that/IN the computer tries to answer all the general questions and uses adjusting acts for this purpose"
424	W12_5102	"way , t1 is the term for which the sum of all relations related to the clue i1 is the strongest . The first proposition made by AKI , p1 is this term . The player is supposed to acknowledge it , if it is the target term , otherwise <<< he/she >>> is invited to propose another clue . In this case , the clue and the proposition is removed from the signature : S'1 = S1 -{p1 , i1 } . With the second clue i2 , the next lexical signature is computed : S2 = ( S'1 ∩ S(i2 )"
425	W18_0310	". In ( 12b ) , the voiced obstruent is further away , so the high tone spreads , but only across one syllable before it is blocked . ( 11 ) a. /á-na-tsukur-a/ → [ ànàtsùkǔrâ ] ' he/she is taking ' b. /á-na-á-tsukur-a/ → [ ànàátsúkúrâ ] ' <<< he/she >>> is taking them ' c. /á-na-á-demurir-a/ → [ ànàádèmùrǐrâ ] ' he/she is scolding them ' ( 12 ) a. /a-ká-ézeker-a/ → [ àkàézèkěrâ ] ' he/she has thatched with/for ' b. /a-ká-súrubik-a/ → [ àkàsúrúbǐk-â ] ' he/she is strong/firm ' The pattern in Digo reveals a local relation"
426	H91_1070	"An example frame is given in Figure 1 for the sentence "" "" Does flight twenty two serve dinner ? "" "" The system can be operated in both a non-booking and a booking mode . 2 In the former , when a user tries to make a reservation , <<< he/she >>> is simply informed that/IN such a capability does not yet exist . In the latter , the system launches a reservations plan upon user request , which includes a number of subgoals initiated by either the system or the user . Once a user initiates a booking , a complex"
427	2022_bea_1_28	"for a reader who can appreciate subtle distinctions of style and implicit as well as explicit meaning , including idiomatic expressions and colloquialisms . C1 Appropriate for a reader who can understand in detail complex dialogues , whether or not they relate to their own area of speciality , provided <<< he/she >>> can reread difficult messages . Appropriate for a reader who can understand a wide range of demanding messages , and recognise implicit meaning , including emotional , allusive , and joking usage of language . B2 Appropriate for a reader who can understand the main ideas of complex dialogues across"
428	2022_naacl_main_188	"et al. , 2013 ) and test on the Winobias challenge dataset ( Zhao et al. , 2018 ) . Winobias consists of sentence pairs , pro-and anti-stereotypical variants , with individuals referred to by their profession . For example , "" "" The physician hired the secretary be- cause <<< he/she >>> was busy . "" "" is pro/anti-stereotypical , based on US labor statistics . 4 A coreference system is measured by the performance gap between the pro-and anti-stereotypical subsets . Model . We use the model presented in Lee et al. ( 2018a ) with RoBERTa as a feature extractor"
429	A00_1005	"from the database . The results are summarized in Table 1 . These results show that/IN the system was quite successful in handling requests from users with a variety of accents achieving varying recognition rates . Out of the 80 parts tested , only twice did the user feel that/IN <<< he/she >>> had to transfer to an operator . The system successfully retrieved the identification numbers of 79 % of the parts while transferring 19 % of the cases to a human operator because of extremely bad Conclusions In this paper we have described a robust system that provides customer service for"
430	Y04_1032	" recorededed  "" , which is a typo , is also given "" "" [ Caution ! ] "" "" . In future work , we would like to develop a system that stores all the sentences that/IN a user has written and read and show him/her which word <<< he/she >>> first encountered when a new sentence is presented . ( We have already investigated a system for highlighting expressions that appear first in documents ( Murata and Isahara , 2002c ) . ) We also consider that/IN it may be interesting to highlight the words that appear first in English"
431	C18_1292	"2015 ) . • LearnerFreq-char-min : For each character in the word , we compute its frequency count in JCLC . This feature takes the minimum frequency . Text retrieval Our system allows the user to specify the minimum ( estimated ) proportion of words in the retrieved text that/IN <<< he/she >>> should be able to understand . This parameter can be set to an arbitrary percentage between 0 and 100 , but in consideration of the manual effort needed for evaluation , we set this parameter to 80 % in our experiment . Ehara et al. ( 2012 ) assumed that/IN"
432	W14_2603	"gfbf events in the quotations . Consider the Ex(4.3 ) , where one of the gfbf triple is law , reduce , amount of labor . In the original editorial , the writer supports the law and the writer has a positive sentiment toward the number of jobs ( because <<< he/she >>> expects to see more job opportunities ) . But merely from the annotated gfbf triple , it is inferred that/IN the law has negative effect since it reduces the number of jobs . This is not contradictory with the writer ' s stance because the writer regards the event as"
433	W17_3010	"pairs . The average in-lab inter annotator agreement kappa score is 0.453 . While annotating , we found instances of sexual harassment directed towards female users . Example 1 in Table 2 shows this type of abuse . In most of these cases , the attacking user is anonymous and <<< he/she >>> is constantly posting similar questions on the victim ' s profile . We also found several instances where the purpose of the post is to defend/protect self or another person by standing up for a friend or posting hostile or threatening messages to the anonymous users ( Example 2 in"
434	2021_emnlp_main_777	"the original texts , such as the intention and the state of the participants . For instance , as shown in Figure 1 , if the waiter ' s service is friendly , the customer will be more likely to praise the waiter . If the customer is irritable , <<< he/she >>> will be more likely to criticize the waiter . Unfortunately , the current formulation does not consider these features . From the aspect of the script-level information , existing studies only model the events that share a specific protagonist . These events are organized into a sequence by temporal order"
435	2020_lrec_1_85	"the best ones . They were selected by external experts in human-human interaction , evaluating the most realistic interactions . Finally , two films have been chosen for each scenario ( 6 films in total ) : one in which the patient produces congruent feedbacks , a second in which <<< he/she >>> produces congruent and incongruent feedbacks . Human-human and human-virtual agents videos Each film has been edited , allowing the patient to be seen as illustrated in Figure 3 . b. The is to make it possible for the observer to perceive as clearly as possible the feedbacks produced by the"
436	W14_5818	"CST questionnaire , almost all the questions are the same except the stimuli words and can be instantly answered by intuition ; note that/IN a participant can take part in as many as 42 tasks ; according to our test , if a participant is familiar with the tasks , <<< he/she >>> can answer each question in less than 2 seconds ( less than 1 second to identify the stimulus word and another less than 1 second to rate it ) without difficulty . 70 × 2 = 140 seconds , the expected time should be less than this , so we"
437	2005_sigdial_1_17	"Walker et al. , 1998 ) utter . expert . # cancel number of user cancel attempts Overall number of user cancel attempts in a dialogue . A user turn is classified as a cancel attempt if the user tries to restart the dialogue from the beginning , or if <<< he/she >>> explicitly wants to step one or several levels backwards in the dialogue hierarchy . ( Kamm et al. , 1998 ; San-Segundo et al. , 2001 ) utter . expert . SCT , SCR number of system correction turns , system correction rate Overall number ( SCT ) or percentage"
438	E93_1037	"hierarchy and move the items following by one _position to the left ; we might call it empathy shifting/ Now consider the discourse : ( 17 ) 01&lt;/&gt; 02&lt;i&gt; hon -wo yatta -node , book acc favored because 01&lt;k&gt; 02&lt;a&gt; orei -wo iwareta . gratitude ace say cop ' Because <<< he/she >>> gave a book to him/her , he/she was thanked for it . ' ( 18 ) a empathy(01&lt;i&gt; , 02&lt;j&gt; , _ ) b empathy(01&lt;k&gt; , 02&lt;9 &gt; , _ ) 18(1 ) corresponds to the empathy hierarchy for the first clause in 17 ; 18(b ) corresponds to the"
439	2022_naacl_main_227	"to learn from their mistakes if they submit an incorrect reference . Concretely , if an annotator submits a reference that is not included in the final golden references , he/she has to modify his/her submission into a correct one . Moreover , the annotator can also make complaints if <<< he/she >>> insists that/IN his/her submission is correct . We find that/IN the self-study and making-complaints mechanisms can trigger very helpful discussions . To improve annotation efficiency , we have developed a browser-based online annotation tool to support the above workflow and mechanisms . Table 4 : Data statistics , including the"
440	W16_6501	"since CEFR , inter alia , defines CEFR proficiency levels through topics . For example , the CEFR document states that/IN one should be able to "" "" introduce him/herself and others and [ ... ] ask and answer questions about personal details such as where they live , people <<< he/she >>> knows and things he/she has "" "" ( Council of Europe , 2001 , page 24 ) . The verbs göra and heta are encountered very often at the beginner level as beginners learn to introduce themselves ( e. g. Jag heter Peter . ' My name is Peter ."
441	2021_emnlp_main_588	"only help confirm COMET results but they also provide guidance to users as to what information the system is looking for . As shown in Figure 1 , five explanations for the question are returned by ¼ ¾ . The user chooses one and provides an explanation as to why <<< he/she >>> chose that option . The explanation is in opendomain text , formatted as a series of if-then statements . This is because if-then formatted explanations can be easily parsed using our parser . In this step , the question asked from users is contingent on which logic template the if-then-because"
442	2003_mtsummit_papers_16	"placing of pronouns ( me dixo instead of díxome ' he/she told me ' ) , use of compound tenses -non existent in normative Galician-(había feito por fixera ' he/she had done ' ) , reflexive verbs -non existent in normative Galician-(sentouse no chan instead of sentou no chan ' <<< he/she >>> sat on the floor ' ) ... Interferences , besides the structural similarity between the two languages at issue , constitute a handicap in the task of designing grammars in the machine translation system . Furthermore , this structural similarity also influenced our translation work because of the difficulties to"
443	2022_eamt_1_30	"issues or to check numbers and tags ) . One reviser uses a two-step revision strategy ( monolingual proofreading followed by bilingual revision ) , while another one reads the source and target in parallel . Regarding PE , one respondent is unable to provide us with an answer since <<< he/she >>> only uses MT as a further suggestion in the CAT tool . Two respondents mentioned they vary their strategies depending on the text , while two others read the source and target in parallel . Although the latter did not clarify whether they start with the source or target segment"
444	L18_1361	"address this , the platform will enable the development of novel services such as the ability to follow the development of their child on a regular basis through language and cognitive analytics ( growth curves in number of words , verbal complexity , social skills , etc. ) even before <<< he/she >>> attends school . In addition , they will have complete control of their data usage , with the option to open up null/partial/full data access to researchers and/or third parties . For academic research , the platform provides a novel instrument for studying language and cognitive development , potentially ,"
445	1998_eamt_1_12	"for tool X. Can you get me in contact with someone ? "" "" LCC Consulting workflow • An inquiry will be routed to the LCC project manager who supports the first language of the client • The project manager will either be able to give an answer him/herself or <<< he/she >>> will reformulate/route the question to another consultant selected from the LCC database Questions can be written in the following languages Danish , English , German and French www . LCC-online . com Start : mid May 98 Content The KB will include information which is of general interest to LCC"
446	P15_1105	"of higher granularity metrics like the mispronunciation of particular phonemes ( Li et al. , 2009 ; Ito et al. , 2006 ; Koniaris and Engwall , 2011 ) . In spontaneous speech evaluation , the candidate is asked to speak on a topic or answer a question and what <<< he/she >>> speaks is n't known priori . Evaluation of spontaneous speech is the ultimate test of a candidate ' s proficiency in speaking a language ( Hagley , 2010 ; Halleck , 1995 ) . While scores from the evaluation of read/repeat speech do correlate with spontaneous speech evaluation , there"
447	D16_1077	"a user registers for multiple services because each of them serves its own purpose . As a result , we cannot assume the existence of direct mentions about target-domain items in the source-domain text data . For example , a regular YouTube viewer does not necessarily tweet about the videos <<< he/she >>> has viewed . Thus simple methods such as keyword matching are likely to fail . The same reasoning also implies that/IN , when transferring knowledge across websites or services , the assumption of a shared rating format or structured text is overly optimistic . Even websites aiming for the same"
448	W11_3105	"Place&gt; and &lt;Destination Place&gt; etc are included . &lt;Destination Place&gt; is always required and must be present in the question . The various CEFs are now described . Location Related feature : These features contain the place name where user wants to go/travel/stay etc or the place name from where <<< he/she >>> starts his/her journey or where he/she stays ( Origin ) . Sometimes user also mentions the place name where he/she must want to visit . Location To : Where user wants to go/visit/travel/see . Extraction Rule : Location named entity words are preceded by preposition "" "" to "" """
449	L16_1309	": • 16 to 30 • 31 to 45 • 46 to 77 . The speakers were asked to fill in the form providing information about their age , sex , education , profession , birthplace , native language , experience in pronunciation practice of foreign languages , cities where <<< he/she >>> had attended school and college/university , cities where he/she had lived for at least one year . They were also asked to define their general physical and emotional state at the time of the recording . All the speakers mentioned Russian as their only native language . Of the 60"
450	P98_2163	"even though the number is small . For example , there is a test sentence such as follows : ( 19 ) ano hito-wa 82sai-ni natte , annani koukisin ippal-da . that person-TOP 82-years-old-DAT become-te , so curiosity be-full-PRES "" "" Although that person is 82 years old , ( <<< he/she >>> ) is full of curiosity . "" "" Since the combination of the event type here is I(BECOME , BE ) , our program gave it the Circumstance relation as a default . However , we know that/IN in general the person who is 82 years old is not so"
451	C08_1076	"to explain the significance of the models at the level of an individual , primarily in terms of the process of language acquisition , which largely governs the course of language change . In the initial years of language development every child passes through a stage called babbling during which <<< he/she >>> learns to produce non-meaningful sequences of consonants and vowels , some of which are not even used in the language to which they are exposed ( Jakobson , 1968 ; Locke , 1983 ) . Clear preferences can be observed for learning certain sounds such as plosives and nasals ,"
452	L18_1535	"includes being aware of the full meaning and sub-meanings ) , and use the different translations and POS to help with this task . • Scan the various AUTO entries provided for all regions . This might help him remember words that are possible candidates to add for the cities <<< he/she >>> is responsible for . • Delete all entries that are NOT relevant to the cities he/she is responsible for . • Apply the necessary changes for some entries that may need some minor fixes . • Add new words that are not on the AUTO list . • Think of"
453	P08_1071	", a correct/incorrect answer is randomly chosen from the correct/incorrect answer sets for this question . The cluster model ( clu ) tries to model student learning by assuming that/IN a student will have a higher chance to give a correct answer to the question of a cluster in which <<< he/she >>> mostly answers correctly before . It computes the conditional probability of whether a student answer is correct/incorrect given the content of the tutor ' s question and the correctness of the student ' s answer to the last previous question that belongs to the same question cluster . We also"
454	W10_0901	"for the statements that mix old and new knowledge , has identified the connection points in the KB for the new facts . Although this level of accuracy is too low for automation , it suggests the system might be a useful tool for helping a knowledge engineer check that/IN <<< he/she >>> has fully encoded the contents of a passage when building the KB , and performing those approved additions automatically . Discussion and Conclusion We have described a method for reading "" "" at the fringe "" "" of what is known , leveraging existing knowledge to help in the reading"
455	2020_iwclul_1_3	"they do not occur in the written standard . From the perspective of morphological analyzer construction , these forms pose no challenge . Permyak connegatives are formed differently from their Zyrian counterparts , so that Permyak plural connegative is always marked with -ӧ /-ə/ , e. g. оз мунӧ ' <<< he/she >>> does not go ' : озӧ мунӧ ' they do not go ' /oz munə/ : /ozə munə/ . In Zyrian , the plural connegative would be formed as оз мунны /oz munnɨ/ ' they do not go ' , with the connegative form identical to the infinitive of the"
456	W19_4020	"arguments missing from the predicate-argument structure after addition of the empty categories in the Hindi Dependency Treebank ( Vaidya et al. , 2012 ) . T5 : "" "" Tore my calendar kyunki woh khana nai laya "" "" Translation : "" "" ( I ) tore my calendar because <<< he/she >>> did n't bring food . "" "" Although English is not a pro-drop language , pronoun dropping is observed largely in Hindi-English code-mixed data . The sentence above ( T5 ) is such an example from the corpus . We incorporate this in our data by inserting ' NULL '"
457	L18_1514	"connect lexical aspects with other language aspects such as grammar 8 based on the framework of CEFR . Also , the word level can be adapted flexibly based on a learners ' proficiency . If a researcher wants to establish a system that simplifies words into A levels , then <<< he/she >>> can omit B1 level candidates from the list . Table 5 shows the distribution of CEFR levels for both target and candidate words in SemEval2012 , Horn et al. ( 2014 ) , and CFER-LS . It is clear that/IN other two resources contain a number of A1 , A2"
458	2020_lrec_1_54	"et al. , 2003 ) , or to recommend movies ( Dalton et al. , 2018 ) by observing past user behaviour . There are basically two types of recommendation systems : Content-based recommender systems ( Pazzani and Billsus , 2007 ) model the user by characteristics of the items <<< he/she >>> likes or dislikes . Alternatively , systems based on collaborative-filtering ( Lu et al. , 2015 ) assist users with making decisions by taking into account the opinions of other people who share similar interests . Conversational recommendation systems ( Sun and Zhang , 2018 ; Christakopoulou et al. ,"
459	2021_conll_1_10	"; • Remove utterances with percentage of distinct tokens less than 2/3 ; • Reduce frequency of any utterance to 100 . Whenever we remove an utterance , we discard all the following utterances in the same dialog . the "" "" Bonus Validation "" "" button to check if <<< he/she >>> has successfully obtained the bonus point . D More Samples of Model Outputs B Implementation Parameters Here we summarize some of the parameters of the model implementation : • We use the RoBERTa tokenizer to tokenize the input utterances , and the vocabulary size is 50,265 . We allow a"
460	2021_nodalida_main_52	"et al. , 2016 ) , which contains 57M sentences of social media , news text and scientific prose from 2000 to 2015 . We use three sets of gendered collocates to classify sentence-level contexts as male-or female-associated : The small set uses only forms of the pronouns hon/han ' <<< he/she >>> ' . The medium set also includes a list of definitionally gendered nouns , such as flicka/pojke ' girl/boy ' , mamma/pappa , maka/make ' wife/husband ' , syster/bror ' sister/brother ' , etc. , in total 31 nouns for the male and 25 nouns for the female set ."
461	Q15_1029	"Compared to the ranking model with latent antecedents , the antecedent tree model commits consistently more recall errors and fewer precision errors . This is partly due to the fact that/IN the antecedent tree model also predicts fewer links between mentions than the other models . The only exception is <<< he/she >>> , where there is not much of a difference . The only difference between the ranking model with latent antecedents and the antecedent tree model is that/IN weights are updated document-wise for antecedent trees , while they are updated per anaphor for the ranking model . This leads to more"
462	D12_1110	"her native [ land]e2 about the same time and they were married in that city . e1 ) Roadside [ attractions]e1 are frequently advertised with [ billboards]e2 to attract tourists . Product-Producer(e1 , e2 ) A child is told a [ lie]e1 for several years by their [ parents]e2 before <<< he/she >>> realizes that ... Entity-Destination(e1 , e2 ) The accident has spread [ oil]e1 into the [ ocean]e2 . Member-Collection(e2 , e1 ) The siege started , with a [ regiment]e1 of lightly armored [ swordsmen]e2 ramming down the gate . Instrument-Agency(e2 , e1 ) The core of the [ analyzer]e1"
463	C18_1104	"with several objects ; one player ( the Oracle ) is assigned a target object in the image and the other player ( the Questioner ) has to guess it . To do so , the Questioner has to ask Yes/No questions to the Oracle . When the Questioner thinks <<< he/she >>> can guess the object , the list of objects is provided and if the Questioner picks the right one the game is considered successful . No time limit is given , but the Questioner can leave the game incomplete ( viz. not try to guess ) . The set of"
464	C18_1079	") , we can find attention weights of "" "" good "" "" are different for different aspects , where weights for service , check in and room are higher than weights for other aspects . we check all reviews of the sample review ' s author and find that <<< he/she >>> often ( more than 80 % ) use "" "" good "" "" to describe service , check in and room . Error Analysis Review Text : ... the staff were all very nice and helpful and friendly they seemed to lack that lack that/IN ultimate professional touch . the"
465	W04_1607	"rules that identify the baseform of each token . Examples of the output of the morphological analyzer are shown below where the left hand side represents the lower input string and the right hand side is the upper side output 1 : ‫ﻣﺴﺎﻓﺮﻳﻦ‬ ' travelers ' msâfryn msâfr+Noun+Pl ‫رﻓﺖ‬ ' <<< he/she >>> left ' rft rftn+Verb+Ind+Pret+3P+Sg ‫وﮐﻴﻠﺴﺖ‬ ' he/she is a lawyer ' vkylst vkyl+Noun&gt;bvdn+Verb+Ind+Pres+3P+Sg The rules are written as regular expressions and are represented as continuation paths within the lexc grammar . The morphological analyzer covers 1 Unless otherwise specified , the Persian examples are direct transliterations of the Persian script"
466	W19_6702	"translators were asked to perform English to German translation of 200 news sentences with CATaLog Online by choosing between : The selection of the first two possibilities ( a ) or ( b ) assumes that/IN translators will edit suggestions proposed by the tool , while for ( c ) <<< he/she >>> will have to do the translation from scratch . From the set of 200 sentences each translator received , 100 were repeated , allowing us to measure the agreement between the three translators . Since CATaLog Online is providing an extensive editing log , we collected in- formation concerning the"
467	2003_tc_1_2	"above English/Italian ) , reflecting the increasing importance of China in the business world . The MT facility is considered most useful for gisting documents in an unknown language , seeking translations of individual terms and preparing draft documents in a language known by the user , but in which <<< he/she >>> does not feel fully competent ( usually English ) , which may subsequently be checked using dictionaries and spelling and grammar correction functions in word-processors ( e. g. MS Word ) . Users in general are aware that/IN the facility is not capable of producing "" "" human "" """
468	C88_1011	"question the subclass is specifiable , but has uot been specified Example 1 : If a user works on a 3D-matrix with the matl/x editor aid considers inclusion of all conjunctions into one cover symbol in the first scope , but wants to leave the most frequent labels out , <<< he/she >>> will look e. g. at a part of the matrix by a comm , ' u~d DISPLAY C ... ... ... ; ; which will give a display of only those parts of the matlix where a conjtmction stands in the first position of the Markov chain . Let us"
469	2009_eamt_1_17	", on the other hand only has one form to express both present and past tense . The tense distinction is made by means of the main verb following the negation verb as in ii boa de ( ' he/she does not come ' ) and ii boahtán ( ' <<< he/she >>> did not come ' ) . ii ii+V+IV+Neg+Ind+Sg3 ij ij+V+Neg+Prs+Sg3 ittjij ij+V+Neg+Prt+Sg3 Both for generation and analysis that means that/IN one has to find a possibility to account for the ' missing ' tag in North Sámi . ' Missing ' means here the lack of tag specification for the"
470	W97_0110	"another domain , they might not be . Wit . hln a particular rule , the user might expect one entity to be relatively specific and the other entity to be more general . For example , if a user is interested in finding all DCR Inc. related jobs , <<< he/she >>> might want to hold the first entity as specific as that/IN in Figure 2 , and gener-M~ the third entity . The rule optimization process is to automatically control the degree of generalization in the generuli~d rules to meet user ' s different needs . Optimi~-ation will be described in"
471	W09_0907	"and call for detailed experimentation . It is a well known fact that/IN the process of language acquisition by an individual largely governs the course of language change in a linguistic community . In the initial years of language development every child passes through a stage called babbling during which <<< he/she >>> learns to produce non-meaningful sequences of consonants and vowels , some of which are not even used in the language to which they are exposed ( Jakobson , 1968 ; Locke , 1983 ) . Clear preferences can be observed for learning certain sounds such as plosives and nasals ,"
472	O12_1007	"than spoken data . When observing the calculation , we found that/IN low-frequency words in the Sinica corpus encompassed not only rarely-used words but also words that were commonly used in daily-life conversation . Under the circumstances , a participant might receive a low frequency index from our computation because <<< he/she >>> utilized a number of ' low-frequency ' words that are ubiquitous in spoken data , which are certainly not associated with broad lexical knowledge . This problem would become apparent when the frequency index was computed from the NV list of personal word usage . Unlike the NV list ,"
473	2020_lrec_1_807	": A pair of maps used in sibling-sibling recordings with keyword set #3 ( see Table 2 . ) ( Keywords are underlined here , but were not underlined on the prints used during the recording . ) language , experience in practicing pronunciation of foreign languages , cities where <<< he/she >>> spent their childhood/went to school/attended a university or college , and cities where he/she had lived for at least one year . The second questionnaire was filled after every recorded dialogue and contained a series of open questions intended to find out whether the speaker felt comfortable during this particular"
474	C96_1080	"Syntax dictionary entry for ADJUST . In all the above cases , except for sentence ( 13 ) the complement can be unambiguously recovered . In sentence ( 9 ) they bought something , in ( 10 ) they would agree on the statement , and in ( 11 ) <<< he/she >>> has got somettfing on . However , even though "" "" where "" "" is to be reconstructed in both ( 12 ) and ( 13 ) only in ( 12 ) can it be unambiguously interpreted as being part of a pp ( they were walking to somewhere )"
475	E91_1045	"of possible worlds , namely all those possible worlds that are consistent with his/her beliefs . The semantics of questions is given as a partition over all possible worlds , in an extensional framework -where intensions are derived from extensions -this means that/IN if a person entertains partial beliefs , <<< he/she >>> cannot know the meaning of a question . ) Secondly , there may be more than one true answer to a question , and all should be captured by Groenendijk and Stockhof ' s theory . But how are these answers defined , even computed , from the question7 And"
476	Y12_1056	"in English requests with factor F4 ( with words such as please or thank you ) in comparison to Slovak . On the contrary , the factors F5 and F7 are much more often used in English . These are expressive factors . When the requester uses factor F5 , <<< he/she >>> assumes that/IN explaining the reasons to the requestee and requestee ' s potential understanding of reasons of request may increase the likelihood of the fulfilment of a request . Consequently , the requester appeals to the empathy and imagination of the requestee , since he/she considers their influence as an"
477	2020_acl_main_619	"datasets focused on specific linguistic phenomena . Prates et al. ( 2018 ) and Cho et al. ( 2019 ) construct template sentences using occupational or sentiment words associated with a gender-neutral pronoun , to be translated into an English gender-specified one ( [ x ] is a professor : <<< he/she >>> is a professor ) . Similarly , the Occupations Test ( Escudé Font and Costajussà , 2019 ) and Wino MT ( Stanovsky et al. , 2019 ) cast human entities into proto-or anti-stereotypical gender associations via coreference linking ( e. g. the English sentence "" "" The janitor does"
478	2020_lrec_1_73	"( I , like activity , partying ) although the user does not mention it explicitly . Third , sometimes no predicate is triggered , even if there is some useful user information . For example , we should be able to conclude that/IN a user likes to travel if <<< he/she >>> says "" "" I travel a lot . I even studied abroad . "" "" Discussion Once we obtain user attributes , they can be applied to many downstream applications , for example , search , friend recommendation , online advertisement , computational social science , personalized personal assistant ,"
479	W18_0310	", so the high tone spreads , but only across one syllable before it is blocked . ( 11 ) a. /á-na-tsukur-a/ → [ ànàtsùkǔrâ ] ' he/she is taking ' b. /á-na-á-tsukur-a/ → [ ànàátsúkúrâ ] ' he/she is taking them ' c. /á-na-á-demurir-a/ → [ ànàádèmùrǐrâ ] ' <<< he/she >>> is scolding them ' ( 12 ) a. /a-ká-ézeker-a/ → [ àkàézèkěrâ ] ' he/she has thatched with/for ' b. /a-ká-súrubik-a/ → [ àkàsúrúbǐk-â ] ' he/she is strong/firm ' The pattern in Digo reveals a local relation between the target and left high tone trigger in UTP . TBUs"
480	2020_acl_main_619	"via pronouns , inherently gendered words ( boy , girl ) and exceptionally with marked nouns ( actor , actress ) . For all the other indistinct neutral words , the gender of the referred entity -if available -is inferred from contextual information present in the discourse , e. g. <<< he/she >>> is a friend . Nascent inquiries on machine translation ( MT ) pointed out that/IN machines tend to reproduce the linguistic asymmetries present in the real-world data they are trained on . In the case of gender inequality , this is made apparent by the attribution of occupational roles from"
481	W11_3105	"included . &lt;Destination Place&gt; is always required and must be present in the question . The various CEFs are now described . Location Related feature : These features contain the place name where user wants to go/travel/stay etc or the place name from where he/she starts his/her journey or where <<< he/she >>> stays ( Origin ) . Sometimes user also mentions the place name where he/she must want to visit . Location To : Where user wants to go/visit/travel/see . Extraction Rule : Location named entity words are preceded by preposition "" "" to "" "" , "" "" include "" """
482	C92_3140	"of the ILLICO project , is the development of a generator of natural language interfaces for the consultation of different kinds of knowledge bases in French . The main external characteristic of the ILLICO interface lies in the fact that/IN it can guide , if necessary , the user while <<< he/she >>> composes sentences . Guided composition is done according to the principle of partial synthesis of a sentence . The main internal characteristic of an ILLICO interface is the modularity of its linguistic knowledge specifying the lexical , syntactic , semantic and conceptual levels of wellformedness . In order to take"
483	W14_2710	"this paper , we investigate how topic dynamics during the course of an interaction correlate with the power differences between its participants . We perform this study on the US presidential debates and show that/IN a candidate ' s power , modeled after their poll scores , affects how often <<< he/she >>> attempts to shift topics and whether he/she succeeds . We ensure the validity of topic shifts by confirming , through a simple but effective method , that/IN the turns that/IN shift topics provide substantive topical content to the interaction . Introduction Analyzing political speech has gathered great interest within the"
484	2020_conll_1_46	"of Hinglish , we replace the domain of college majors , which is highly anglicized with respect to Hindi , with favourite fruit which is more equally represented in both languages . Handling gender-markings Third person pronouns and verb forms in Hindi are usually gendermarked ( eg . karta/karti [ <<< he/she >>> does ] , uska/uski [ his/her ] ) . Since the Spanglish KB does not provide any information about the gender of friends , we consequently notice the dialogues using this system to be gender-skewed . In the COMMON-AMIGOS Spanglish data ( Ahn et al. , 2020 ) , the"
485	Y13_1017	"( 5-10 ) years to catch up academically in English "" "" ( Cummins , 1999 , p.2 ) . Another factor proposed by Cummins ( 2001 ) that relates to second language acquisition is Common Underlying Proficiency ( CUP ) . Cummins believes when a child learns one language <<< he/she >>> acquires a set of skills and implicit meta-linguistic knowledge that/IN he/she can draw upon when learning another language . The CUP provides the base for the development of students ' native language ( L1 ) and the second language ( L2 ) . This suggests that/IN it is very important"
486	Y00_1011	". 9 In the case in which the passenger is a singleton set , disjunction gets "" "" or""""-reading : Here , if "" "" sono kyaku ( that passenger ) "" "" refers to a particular passenger and not a particular group of passengers , then the action that/IN <<< he/she >>> took is singular . Therefore , this disjunction gets "" "" or""""-reading . That certain expression with disjunction obtains either "" "" or""""-reading or "" "" and""""-reading depending on its situation reflects that/IN "" "" or""""-reading or "" "" and""""-reading is not determined solely by the utterance . "" Linguistic"
487	W02_0213	"mentioned earlier in Section 2 ) : given the dialogue context -defined by the previous forward-looking function of the client ( PFFC ) and the previous backwardlooking function of the server ( PBFS ) , the client decides which forward-looking function to perform ( FFC ) ; from this decision <<< he/she >>> formulates a natural language utterance with certain features including the sentence type ( SeTp ) the subject type ( SuTp ) and punctuation ( Punct ) . Recalling the notion of conditional independence in Bayesian networks described in Section 2 , it follows that/IN by choosing the network structure of"
488	W10_4353	"ECA asks questions to elicit information from the user , makes empathetic and sympathetic comments , and offers advice . The system is able to process long user turns , as well as to generate long system turns ( around 50 words ) . If the user perhaps dislikes what <<< he/she >>> hears , he/she can interrupt the system by barging in , and the ECA will respond in a human-like way . The conversation style is therefore considerably different from traditional task-based dialogues that consist of short dialogue turns and in which the system takes all the initiative . The dialogue"
489	1996_eamt_1_2	"will involve training . Not only in working with new tools ( see below ) , but also learning to write in controlled language . Part of this can be done in a training course , but the author will have to go through a learning curve . Basically , <<< he/she >>> has to learn a new language . It turns out only full time authors are able to come up to speed in writing in controlled language ; it is not feasible for people who occasionally write documentation to learn to write in this way . The implementation of controlled language"
490	P19_1389	"have no overlap or the conversation pair has a sentence segment with no annotated label at all , we ignore this pair ; ( 3 ) we present all labels together with the majority-voting results back to the annotator who gives the inconsistent label and ask him/her to check if <<< he/she >>> agrees with the majority-voting results . If this annotator agrees with the majority-voting results , we store this conversation pair with the confirmed results , otherwise we ignore it . As a result , we have 95,898 conversation pairs remaining and Table 1 shows some statistics . Sentence Function Classification"
491	2020_lrec_1_736	"the corpus content and giving the signers enough freedom to have the most natural and realistic sign language production . To take this into account , three of the tasks were precisely controlled with instructions written explicitly while the signers were given some leeway in the third part in which <<< he/she >>> has to describe various animals . For this task , we needed the signers to be able to sign in the manner they see fit . We decided to give the signers an image of the animal to be described next to some words underlining the important information that/IN the"
492	2005_sigdial_1_23	"U M . The scalar product ∆ U M is compared to a threshold value s. If ∆ U M &gt; s , users behave as novices , if ∆ U M ≤ s , they behave as experts . A user is categorised for the actual task . When <<< he/she >>> calls this task again , the system responds with the appropriate prompt -for novice or expert . Table 1 shows three examples for system responses for experts and novices . The comparison function takes three values as input : ∆ U M ( see above ) , s , and"
493	Y00_1011	"the east gate . Figure 9 shows a case of distribution of the results of passengers going through the gates . Here , j under the human figures outside the gates is intended to show that/IN a given passenger has just passed through the west gate , and \shows that/IN <<< he/she >>> has just passed through the east gate . The upper half of Figure 9 shows that/IN in the situation under consideration , for each passing event , only one gate can be used . The lower half of Figure 9 is intended to show that/IN at the time when all"
494	L16_1309	"• 46 to 77 . The speakers were asked to fill in the form providing information about their age , sex , education , profession , birthplace , native language , experience in pronunciation practice of foreign languages , cities where he/she had attended school and college/university , cities where <<< he/she >>> had lived for at least one year . They were also asked to define their general physical and emotional state at the time of the recording . All the speakers mentioned Russian as their only native language . Of the 60 speakers , 51 had higher education , 7 were"
495	2022_in2writing_1_13	") in a line for matching melody length . The creator can also choose rhyme for the last character in each line from Chinese 14-rhyme 1 groups . Moreover , a minimalist generation mode is provided , where the creator only has to input trigger words and an actual lyric <<< he/she >>> is interested in , then ChipSong will extract the lyric ' s format and rhyme pattern , and generate a new lyric according to the input trigger words and the extracted format and rhyme , thus fully imitating the original lyric for making a cover song version . Actual Lyric"
496	N13_1124	". This work focuses on identifying user posts with explicit intentions . By explicit we mean that/IN the intention is explicitly stated in the text , no need to deduce ( hidden or implicit intention ) . For example , in the above sentence , the author clearly expressed that/IN <<< he/she >>> wanted to buy a car . On the other hand , an example of an implicit sentence is "" "" Anyone knows the battery life of iPhone ? "" "" The person may or may not be thinking about buying an iPhone . To our knowledge , there is no"
497	2020_lrec_1_619	"the benchmark , some sarcasm classification methods are evaluated . Introduction Sarcasm is a typical multi-layered semi-conscious language phenomenon . Essentially , there are a dual purpose expression . That is , the meaning of what a speaker wants to express is very different from the superficial meaning of what <<< he/she >>> says , and even in most cases the two meanings are completely opposite . Because of sarcasm ' s unique language effect , it is widely used by users in internet applications such as social media and forums ( Maynard and Greenwood , 2014 ) . When users express their"
498	O05_3003	"new thought . Often , these kinds of questions are answered by the speakers themselves ( rhetorical_question_answered ) . Unfinished utterances can sometimes be completed by the speaker ( completion_by_self ) or by the listener ( completion_by_other ) . The speaker can express exclamation ( exclamation ) or hesitate while <<< he/she >>> is planning the next utterance or when he/she has doubts about the content of the statement just made ( hesitation ) . To end the conversation contains two annotation tags used to close a conversation . The conversation participants draw conclusions about the topic ( conclude ) or express their"
499	D13_1038	", we applied Amazon Mechanical Turk to solicit feedback from the crowd 2 . Through an interface , we displayed an original scene and generated referring expressions ( from different generation strategies ) in a random order . We asked each turk to select the object in the scene that/IN <<< he/she >>> believed was the one referred to by the shown referring expression ( i. e. , reference identification task ) . Each referring expression received three votes from the crowd . In total , 217 turks participated in our experiment . Generation Strategies We applied a set of different strategies to"
500	L16_1289	"3 and 6,201 unique words . Table 3 highlights detailed statistics of the corpus . The corpus texts include typos ( spelling and grammatical errors ) written by the volunteers . This emphasises the fact that/IN in the real world scenario when a plagiarist reuses a piece of text , <<< he/she >>> paraphrases it with his/her own understanding and knowledge of the language . Moreover , it would be interesting to see the behaviour of plagiarism detection systems on these typographical errors . Example of a paraphrased plagiarised and non-plagiarised document Figures 1 and 2 show example passages from paraphrase plagiarised and"
501	Y12_1024	"common word is a CSP . Using common word exclusion and common word identification , one true positive , "" "" may "" "" , is detected in the sentence "" "" Unless let us say may mga bisita siya "" "" ( translated as : Unless let us say <<< he/she >>> has visitors ) . Common n-gram Pruning The previous refinements do not detect words that are not declared in the tagger dictionary , i. e. words with UNKNOWN POS tag . We developed common n-gram pruning for this purpose . An ngram is defined as an "" "" n-character slice"
502	2006_tc_1_2	"the design of the questionnaire . For instance : how can one get information on what the users need , if they do not know what they need ? And if they do know , how clearly can they express themselves ? Also how can the researcher be sure that/IN <<< he/she >>> interprets what the respondent says in the correct way ? Or vice versa , how can the researcher be sure that/IN the respondent understands the questions asked the same way as he/she does ? In order to minimise any misunderstanding or loss of information due to the issues above ,"
503	W09_0307	"ODIN allows a variety of search options , including search by language name or code , language family , and by grams and their related concepts ( e. g. , Accusative case ) . Once data is discovered that/IN fits a particular pattern that/IN a user is interested in , <<< he/she >>> can either display the data ( where sufficient citation information exists and where the data is not corrupted by the text-topdf conversion process ) or locate documents from which the data is extracted . Additional search facilities allow users to search across linguistically salient structures ( "" "" constructions """
504	W10_4353	"to elicit information from the user , makes empathetic and sympathetic comments , and offers advice . The system is able to process long user turns , as well as to generate long system turns ( around 50 words ) . If the user perhaps dislikes what he/she hears , <<< he/she >>> can interrupt the system by barging in , and the ECA will respond in a human-like way . The conversation style is therefore considerably different from traditional task-based dialogues that consist of short dialogue turns and in which the system takes all the initiative . The dialogue in Table 1"
505	O12_1007	"frequency indices across participants were capable of explaining their differences in response latencies and accuracies . Method There were four steps to compute the frequency index per person , as shown in the following . [ Step one ] Produce a list per participant which contained all of the words <<< he/she >>> used and the occurrence frequency of those words in his/her segmented Facebook data . Examples are shown in the first and second columns of Table 2 . [ Step two ] Gather from the CLP the corresponding word frequency in Sinica Corpus of each word on the list , as"
506	W19_4434	"over time and thereby improves its ranking . With the aforementioned training set we were able to repeatedly achieve a recall accuracy of 0.86 or higher in identifying images which are likely to be selected by the validator . The validator looks through the images and selects the ones which <<< he/she >>> thinks is appropriate considering the script and search term ( Figure 2 ) . A search term without valid images is considered irrelevant and is ignored . Once the validation is completed , the verification step concludes . The output of this layer is a mapping between the Prioritized Search"
507	2020_eamt_1_20	"setting is that/IN the evaluator can access limited intersentential context since only the current sentence is shown . This poses two issues , with respect to previous and following sentences in the document being evaluated . With respect to previous sentences , while the evaluator has seen them recently , <<< he/she >>> might have forgotten some details of a previous sentence that are relevant for the evaluation of the current sentence , e. g. in long documents . As for following sentences , the evaluator does not have access to them while evaluating the current sentence , which may be useful in"
508	W02_0112	"will replace them ( e. g. Methods of logical programming , Methods of functional programming , Systems modelling , Formal languages ) . Therefore , a person who has completed this curriculum is an information scientist who has additionally studied linguistic and computational linguistic subjects to such an extent that/IN <<< he/she >>> will have a systematic picture of the tasks of natural language processing and will be able to solve these tasks in co-operation with linguists . Problems The modules of CL and LT contain a number of common subjects that have also to be taught jointly to the students majoring in"
509	W19_8305	"indicating how many times a player talks , because we considered that/IN players with a lot of utterances were conspicuous . The second measure is the number of appearances indicating how many times a player comes up in utterances of other players , because we considered that/IN it indicates how <<< he/she >>> attracts attention from other players . The more the number of utterances and appearances are , the more attention will be drawn . Using decision trees , we analyzed how the numbers of utterances and appearances per player affected the winning percentage of werewolves . For making a decision tree"
510	W13_4067	"checked that/IN solving such an optimisation problem is actually equivalent to simply normalising b(s , • ) , for which the proof is omitted here but can be found in Appendix B. Finally , we consider an extra fact that/IN normally a user will not insist on a goal if <<< he/she >>> has been notified by the system that/IN it is impossible to satisfy . ( In the DSTC case , such notifications correspond to those canthelp . * system actions . ) Therefore , we have : • Rule 5 : If the system has explicitly disabled a hypothesis h ,"
511	2022_acl_long_132	"debiased by projecting onto the estimated bias subspace and subtracting the resulting projection from the original sentence representation . Liang et al. ( 2020 ) use a three step procedure for computing a bias subspace . First , they define a list of bias attribute words ( e. g. , <<< he/she >>> ) . Second , they contextualize the bias attribute words into sentences . This is done by finding occurences of the bias attribute words in sentences within a text corpus . For each sentence found during this contextualization step , CDA is applied to generate a pair of sentences that"
512	P13_2144	"text written in the discussion by each participant as a vector of 100 dimensions . The vector of each participant contains the topic distribution of the participant , as produced by the LDA model . Subgroup Detection At this point , we have for every discussant the targets towards which <<< he/she >>> expressed explicit opinion and a 100-dimensions vector representing the LDA distribution of the text written by him/her . We use this information to represent the discussion in two representations . In the first representation , each discussant is represented by a vector . For every target identified in steps 3"
513	W16_2801	"media references , and text files . No evidence ( NO EVIDENCE ) refers to users sharing their opinions about the debate without having any evidence to support their claim . The example below shows an argumentative tweet from a user who is in favor of encryption . However , <<< he/she >>> does not provide any evidence for his/her stance . I hope people ban encryption . Then all their money and CC ' s can be stolen and they ' ll feel better knowing terrorists ca n't keep secrets . Non Argument ( NONARG ) refers to a tweet that does"
514	C88_2097	". From the view point of learning in the CM , all the weights of connection links of sub-networks are learned by parsing or recognizing a number of sentences . It is a plausible hypothesis that/IN once a human becomes to be able to parse some structure of sentence , <<< he/she >>> ever can parse that structure since then . In order to explain this hypothesis , the above mentioned weights learning must be uniformly done for all copies of sub-networks of the same phrase structure rule . But this uniformly learning is too artificial for the human mental learning processes ."
515	S15_1015	"set of questions that required constrained answers , such as multiple choice or binary responses as true or false can be binned into the following categories : • Background Questions : A person ' s age , gender , educational level , income , marital-status , socialstatus , how often <<< he/she >>> follows the news , what news sources he/she follows , etc. ; • Opinion of Political Parties : Democratic and Republican parties and their respective public figure representatives ; • Opinion on major economic and political problems facing the USA ; Q1 I approve of Obama ' s and the"
516	E87_1020	"as the Scandinavian languages , this would probably be the case . REFTEX is the part of the program package that will be used by the translator during the process of translation . Program execution starts by asking the translator to key in names of the pair of reference texts <<< he/she >>> wants to use for solving the problems of the actual translation . The program then asks for the first key word to be searched in the reference text , whose equivalents the translator wants to know . If the reference source text contains that word , the program will print"
517	2007_mtsummit_cre_1	"a naïve exercise , it is tolerant of a variety of skill and expertise levels . Anyone who speaks English may participate . If it turns out that/IN the participant also knows the source language of the experiment , there will be other interesting tasks during this exercise in which <<< he/she >>> can participate . Position Papers : Papers are not specifically solicited for this workshop , as it is a handson exercise . However , we will accept position papers ( 1-2 pages maximum ) from participants who have some contribution in the following topics : the Chinese room experiment ;"
518	W03_2128	"questioner has adjusted it the answerer will be able to give the needed information or point to its absence . There are four adjusting possibilities in Estonian dialogues . The most frequently used possibility is that/IN the answerer asks the questioner to adjust the previous question . In this case <<< he/she >>> reacts to a general request by using particles ( jaa , jah /yes/ etc. ) . Such reaction is marked as a continuer ( example 6 ) . The second possibility is that/IN the answerer asks adjustable questions himself/herself . Such act is called adjusting the conditions of the answer"
519	L18_1535	"if it is not his original city . • Enter the CODA and CAPHI versions of each entry , using the guidelines provided . • Make sure the Arabic CODA and CAPHI are correct for all the entries for their cities . • Add the code names of the cities <<< he/she >>> is responsible for . • Change the category to VALID once a row is fully validated . Weekly meetings by the project PIs and a consulting lead linguist reviewed the progress of the linguists . At the time of writing this paper , the MADAR lexicon contained 47,466 dialectal words"
520	P14_1142	"often confused especially in IME related works such as ( Chen and Lee , 2000 ) and ( Wu et al. , 2009 ) . Pinyin typos have always been a serious problem for Chinese pinyin IMEs . The user may fail to input the completely right pinyin simply because <<< he/she >>> is a dialect speaker and does not know the exact pronunciation for the expected character . This may be a very common situation since there are about seven quite different dialects in Chinese , among which being spoken languages , six are far different from the standard modern Chinese ,"
521	W17_5051	"2016 ) , grammatical errors/corrections get an extra mark to be excluded from orthographic analyses but in the target hypothesis , only the grammatically correct form is given and spelling errors within the erroneous form are not considered . For instance , * &lt;Dretet&gt; is corrected to &lt;tritt&gt; ' ( <<< he/she >>> ) kicks ' while an orthographically correct ( but grammatically incorrect form ) would be &lt;tretet&gt; . Furthermore , one cannot see how ambiguous cases are handled , e. g. *&lt;er schlaft&gt; is treated as an orthography error and cor-rected to &lt;er schläft&gt; ' he sleeps ' , although the"
522	E89_1004	"the domain knowledge about the envisioned action and the degree of precision expressed in its specificatiqn . If , according to the system ' s domain model , the effect of the specified action is unambiguous , the user can be expected to be familiar with this relation , so <<< he/she >>> can be assumed to envision the resulting state and , possibly , the precondition as well , if it is not yet fulfilled . Thus , in principle , a plan consisting of a sequence of actions could be created by application of skillful rule chaining . This is exactly"
523	W10_1607	"lexical elaboration . In the following subsections we detail these and other systems developed in the project . SIMPLIFICA Authoring Tool SIMLIFICA is a web-based WYSIWYG editor , based on TinyMCE web editor 13 . The user inputs a text in the editor and customizes the simplification settings , where <<< he/she >>> can choose : ( i ) strong simplification , where all the complex syntactic phenomena ( see details in Section 3.2 ) are treated for each sentence , or customized simplification , where the user chooses one or more syntactic simplification phenomena to be treated for each sentence , and"
524	L16_1322	"topics , containing discussions that happened over a period of 15 years . The dataset contains 166,322 discussion threads , across 1236 articles/topics that span 15 different topic categories or domains . The dataset also captures whether the post is made by an registered user or not , and whether <<< he/she >>> was an administrator at the time of making the post . It also capture the Wikipedia age of editors in terms of number of months spent as an editor , as well as their gender . This corpus will be a valuable resource to investigate a variety of computational sociolinguistics"
525	2022_findings_naacl_34	"relation correctly . This is exactly the same problem faced by a few-shot RC system : the best guess based on the limited labeled examples may fail . If , however , the human annotator is told that/IN the relation is named "" "" position held "" "" , then <<< he/she >>> would have a better understanding of the relation to better generalize the examples to other instances . In this case , the human annotator indeed exploits the prior knowledge about the relation ( from its name ) . If more information such as a description of the relation is available"
526	2021_ranlp_srw_27	"( video and slides ) explaining why and how the process of collecting and analysing data would take place . This is to provide transparency , as requested by GDPR . Obtaining a collaborator ' s consent means having him/her sign a document explaining why we want to collect emails <<< he/she >>> is involved in and under what conditions it is done . For COVID-19 reasons these documents were signed electronically and stored on a secure file system . First stage : Collecting conversations Since our objective was to collect a large corpus of French interactions occurring in the context of computer"
527	1993_iwpt_1_13	"Secondly , the paper is meant to establish , by way of illustrative examples , that/IN the bunch con cept is a mathematical notion as respectable as sets and lists . The reader is invited to translate any of the sections into set notation and observe the notational burden that/IN <<< he/she >>> has to add . One could argue that/IN almost the same con ciseness can be obtained using normal sets and an extra ( ' map ' ) operator to distribute fu nctions over sets . However , one should keep in mind that/IN the bunch notion is more primitive than"
528	2021_findings_emnlp_352	"Out . ) classifier to measure how much content is maintained . Baseline Models We evaluate four debiasing approaches ( all of which generate without parallel ground truth ) and two variants of DEPEN as baselines : • Rule-based ( RB ) : replace words with rules ( e. g. <<< he/she >>> → they , see Appendix A.1 ) . • Weighed Decoding ( WD ) : a decoding method ( Ghazvininejad et al. , 2017 ) by reducing the generation probability of detected sensitive tokens to a hyperparameter α ( we set α = 0.2 ) . • Adversarial Training ("
529	W12_4306	"the different ways in which the term ' hedge ' has been defined in the literature thus far . His new definition is that/IN ' a hedge is an item of language , which a speaker uses to explicitly qualify his/her lack of commitment to the truth of a proposition <<< he/she >>> utters . ' Martín-Martín ( 2008 ) analyses three different hedging strategies and multiple surface features for hedging in a corpus of full-text papers in English and Spanish , and presents a detailed taxonomy of hedging types and cues , based on literature and corpus studies . Within bioinformatics and"
530	W96_0408	"dialogue expinning verb morphology in both cases . However , if the level of English acquisition is taken into account via a model like SLALOM , significantly better correction can be given . For example , in the first case the user ' s placement in SLALOM would indicate that <<< he/she >>> has already mastered the appropriate verb morphology . Thus the error should be seen as a typo . It should be pointed out so that/IN it can be corrected , but tutorial dialogue on appropriate verb morphology is certainly not necessary and would be inappropriate . In contrast , the"
531	W19_7509	"and used in developing educational applications . Sanskrit Shabdamitra is one such application of SWN . Shabdamitra has been devised by taking into consideration the various stakeholders of this application . The major stakeholders of Sanskrit Shabdamitra are : Teachers , Students and Parents . Teachers ' concern is that/IN <<< he/she >>> should be able to convey the entire content to students in all the possible nuances and make them competent in language learning , and prepare them for examinations . Students ' concern is that/IN he/she should learn and understand the content as exhaustively as possible in all nuances and grow"
532	2021_emnlp_main_585	"the intermediate nodes become new hypotheses to prove ) , and re-trained a model to generate similar one-deep entailment trees . This model can then be used interactively , generating a one-deep explanation then allowing a user to select which premise(s ) to drill down into , based on what <<< he/she >>> wants to know more about , recursively calling the model to explain that premise further . Although such generative models ( both generating a full tree or a one-deep tree ) can sometimes produce false or nonsensical facts , one could apply fact verification techniques , e. g. , ("
533	2020_findings_emnlp_375	"an adequacy score lower than 50 % while the human translation received a score higher than 50 % . Like English to German , however , for German to English translation , the reverse is also true , there are translations that catch out the human translator , for which <<< he/she >>> received a low score , while for the same source input , the machine receives a high score . Such translations , there are six in total ( 1.2 % ) , are located in the bottom-right quadrant of Figure 6 . Table 3 shows the most extreme examples in"
534	W18_0310	blocked . ( 11 ) a. /á-na-tsukur-a/ → [ ànàtsùkǔrâ ] ' he/she is taking ' b. /á-na-á-tsukur-a/ → [ ànàátsúkúrâ ] ' he/she is taking them ' c. /á-na-á-demurir-a/ → [ ànàádèmùrǐrâ ] ' he/she is scolding them ' ( 12 ) a. /a-ká-ézeker-a/ → [ àkàézèkěrâ ] ' <<< he/she >>> has thatched with/for ' b. /a-ká-súrubik-a/ → [ àkàsúrúbǐk-â ] ' he/she is strong/firm ' The pattern in Digo reveals a local relation between the target and left high tone trigger in UTP . TBUs to the right of a voiced obstruent do not surface with high tones because the
535	2007_mtsummit_papers_55	"computing the probability of the translated English word sequence , the user may not know how to modify them into natural expressions . If the user knows English well , he/she can correct the awkward part based on one ' s own linguistic knowledge . But , if not , <<< he/she >>> should depend on a Korean-English dictionary and search example expressions . When the exactly matched example expression is found in the dictionary or in the example corpus , the translation quality will be improve . But even in this case , the process is time-consuming . If it is not"
536	2021_paclic_1_49	"the high threshold of selection in the Translation & Interpretation Department of the Ministry of Foreign Affairs . Diplomatic interpreters represent the entire country and must convey China ' s voice , only through such trials as "" "" strict screening , crazy practice and careful preparation "" "" can <<< he/she >>> become a truly diplomatic interpreter . Therefore , it is believed that/IN diplomatic interpreters must have excellent professional ability . The following will discuss linguistic features and the closest genre in each dimension for describing diplomatic interpreters ' style at length . dimension 1 Dimension 1 distinguishes Involved versus Informational"
537	W13_4027	"( 2 ) outof-dialog cases and ( 3 ) out-of-turn cases . To address the first one our training corpus has been augmented so that/IN it includes examples of garbage SFs . As a result an out-of-application utterance triggers a generic reply from the system , notifying the user that/IN <<< he/she >>> is outside the scope of the application . In the case where a user stays within the scope of the application but tries to initiate a new unrelated dialog ( i. e. out-of-dialog case ) , the DM ' s stack of tasks is incremented with the new dialog ."
538	I11_1167	"( Isogai et al. , 2009 ) . step 2 extract the question which had the answer extracted in step 1 ( e. g. Q1 in Figure 1 ) . This question is regarded as an original question . step 3 extract the first question submitted by the questioner after <<< he/she >>> received the answer extracted in step 1 . step 4 examine whether the questions extracted in step 1 and step 3 met one of the following conditions : • they shared more than 10 content words when both of them consisted of more than 20 content words , or •"
539	P03_1033	"al. , 1999 ) . Nevertheless , whether a particular response is cooperative or not depends on individual user ' s characteristics . For example , when a user says nothing , the appropriate response should be different whether he/she is not accustomed to using the spoken dialogue systems or <<< he/she >>> does not know much about the target domain . Unless we detect the cause of the silence , the system may fall into the same situation repeatedly . In order to adapt the system ' s behavior to individual users , it is necessary to model the user ' s"
540	2020_emnlp_main_330	". It is possible that/IN if a speaker has difficulties during production , CS would be more likely to occur ; and at the same time , if the speaker believes CS would help to communicate his/her message ( as proposed by Myslín and Levy , 2015 ) , then <<< he/she >>> might choose to code-switch . As previous findings show , CS is a phenomenon that can be affected simultaneously by a wide variety of factors . Conclusion We investigated the effect of word surprisal and word entropy on the probability of code-switching ( CS ) in Chinese-English written communication ."
541	C00_1063	"case component of a matrix verb . The typical structure of a Japanese complex sentence is as follows : ( 3 ) boushi no iro wa kite-iru hat of color topic-marker wear coat ni awaseru . coat dative-CM harmonize ( φ harmonizes the color of his/her hat with the coat <<< he/she >>> wears ) In terms of automatic analysis , the problematic characteristics of Japanese sentences can be summarized as follows : 1 . Case components are often scrambled or omitted . 2 . Case-marking postpositions disappear when case components are accompanied by topicmarkers or other special postpositions meaning ' just '"
542	A88_1015	"a standard ASCII terminal . Page-X performs diagnosis by reasoning from an initial set of symptom hypotheses to a probable cause , typically asking the technician to perform various tests along the way . The task of the user interface is to allow the technician to efficiently state what symptoms <<< he/she >>> has observed , beth initially and as a result of the requested tests . Menus were used as the original mode of specifying symptoms , and these form a part of the current interface . However , as the knowledge base grew to thousands of hypotheses , it became unwieldy"
543	2020_emnlp_main_252	"academic partners in the area of emotion cause extraction . To label an ECP as a conditional one , the cause events and the effect emotions should be less or not relevant under normal circumstances . For example , in general one shall not reject the care of nurses when <<< he/she >>> is ill , but someone with racial prejudice may feel disgusted with foreign nurses . Such context information contained outside of the cause and emotion clauses is what the three experts are required to find and judge whether these context information is essential for the targeted ECP to have a"
544	2021_acl_long_432	"D on the input space X and a labeling function f : X → Y , i. e. , domain D = D , f . In this work , we assume each annotator is a unique labeling function a : X → Y. Uniting each annotator and the instances <<< he/she >>> labeled , we can result in a number of domains { D i , a i } |A| i=1 , where A represents all annotators . Then the crowdsourcing learning can be interpreted by the later definition , i. e. , learning from these crowd annotators/domains and predicting the labels"
545	2007_mtsummit_cre_1	"and its history , participants will be provided with bilingual training passages to develop alignment hypotheses , and then provided with a set of sentences to be translated . Each participant will be invited to interact with others or remain solitary , to collaborate , compete , and/or adapt as <<< he/she >>> sees fit . At the end of the translation time period , the group will review the translation results , as well as the methods the participants employed . The workshop leaders will also present findings about the nature of the participant group as it went through the exercise ."
546	P08_4009	"more about the subject . The intention behind this mode of presentation is to prominently display the piece of information the user is most interested in , but also to present context information and to furthermore provide options for the user to find out more about the topic , should <<< he/she >>> want to . Finding Supportive Wikipedia Paragraphs We use Lucene ( Hatcher and Gospodnetić , 2004 ) As mentioned , QuALiM finds answers by querying major search engines . After post processing , a list of answer candidates , each one associated with a confidence value , is output ."
547	Y18_1028	"at the brighter side of things whereas repeatedly highlighting some negative aspects might leave the voters frustrated and unhappy . A slightly higher percentage of kinship terms is seen in the losing speeches . This can be seen as the lack of confidence on the speaker ' s part where <<< he/she >>> tries to impress the voters just by assuming the superficial roles analogous to family members . The winning speeches contain a relatively lesser number of nouns when compared to the losing ones . We observed the frequently used nouns in all the speeches , which are related to politics ,"
548	W12_5306	"In Step 4 , we create a tabular summary of objects and their respective modifiers ( Refer Table 5 ) . This summary belongs to type 1 : Blog level summary . Using this kind of summary , we can draw a picture of user ' s mind and how <<< he/she >>> thinks about various entities . The second type of summary generated can be used to compare two different entities . Table 6 reports the accordance of our proposed algorithm with human annotators . Opinion orientation agreement is calculated as an aggregate opinion towards an entity . One plausible reason for"
549	2020_findings_emnlp_86	"results in the task of ezafe recognition . We then use the best of these methods to improve the results for the task of POS tagging . After establishing a baseline for this task , we provide the ezafe information to the POS tag- "" "" Following the events , <<< he/she >>> resigned yesterday . "" "" ging model once in the input text and the other time as an auxiliary task in a multi-task setting , to see the difference in the results . The contributions of this paper are ( 1 ) improving the state-of-the-art results in both of ezafe"
550	W17_5051	"in that/IN they required to choose a form which was marked in some way or not the most intuitive one ( UF ) : On the one hand , this concerns marked spellings that/IN only recently have been adapted by the Duden ( e. g. non-standard &lt;kuckt&gt; for &lt;guckt&gt; ' <<< he/she >>> looks ' ) . On the other hand , our requirement not to correct grammatical errors and certain capitalizations was not obeyed in five cases ( e. g. &lt;wegfahrt&gt; was changed to &lt;wegfährt&gt; ' drive away ' , an agreement error ) ; three of them were also mixed with"
551	Y12_1024	"  , which could be an English adjective or a Tagalog enclitic . Using POS checking , one true positive and one false positive are detected in the sentence "" "" Unless let us say may mga bisita siya "" "" ( translated as : Unless let us say <<< he/she >>> has visitors ) . Both "" "" may "" "" and "" "" mga "" "" are detected as English to Tagalog CSP . We developed pattern matching refinements to improve accuracy . Pattern Matching Refinements Pattern matching refinements ( PMRs ) work by separating pattern matching for sentences involving"
552	W17_5702	"the errors caused by the unknown Japanese words ゴーサイン ( go-ahead , green light , literally "" "" gosign "" "" ) , the major challenge here is the Japanese zero subject . It could be "" "" i "" "" , "" "" you "" "" , "" "" <<< he/she >>> "" "" , and depends on the context . In the other words , Oracle ( LEX ) is significantly better than Baseline because this kind of context dependent information is provided from the outside . Conclusion In this paper , we showed that/IN prefix constraints can be used as"
553	2021_sigmorphon_1_21	"associated with the same noun ( Tarpent , 1987 ; Davis , 2018 ) . That is , the conditioning factor for this alternation is syntactic , not morphophonological . http : //www . inuktitutcomputing . ca/ Uqailaut ( 6 ) Realizations of gup-i-t=hl ( eat-TR-3=CN ) a. gubithl ' <<< he/she >>> ate ( common noun ) ' b. gubihl ' ( common noun ) ate ' The available set of resources further constrained our options for the analyzer ' s design and our means of evaluating it . The H&R wordlist is quite small , and of only a single dialect"
554	O12_1007	"negative estimates indicated that/IN participants responded faster to stimuli with higher personal word frequencies . The experimental results revealed that/IN IDs of frequencies of stimuli could explain individual variances between participants in lexical decision . Words that/IN frequency occurred in one ' s Facebook data revealed the things or issues <<< he/she >>> paid closer attention , the words he/she got accustomed to use but was unaware of , or his/her daily-life surroundings . Therefore , the effect of personal word frequencies in this experiment was considered to result from people ' s conscious or subconscious familiarity with words or concepts . The"
555	W15_0912	"stem of the word is required to match . This model extracts collocations belonging to the semi-lexicalized category as stated in ( Oflazer et al. , 2004 ) . Below is an example for this case : • "" "" Gelecegini haber vermedi . "" "" lit . ( that <<< he/she >>> was coming ) ( he/she did n't give ) ( news ) . ( He/she did n't inform ) Model #2 : The third model checks only the stems of the words and select the sequences of words matching the stems of a MWE in the referenced list . Non-lexicalized"
556	W16_3601	"of the game , in order to narrow down the range of valid people . There are 31 questions . Table 1 shows a summary . Attribute Q a Example Question Birthday 3 Was he/she born before 1950 ? Birthplace 9 Was he/she born in USA ? Degree 4 Does <<< he/she >>> have a PhD ? Gender 2 Is this person male ? Profession 8 Is he/she an artist ? Nationality 5 Is he/she a citizen of an Asian country ? Table 1 : Summary of the available questions . Q a is the number of questions for attribute a. At the"
557	W03_2128	"second type of questions ( expecting agreement/refusal ) can be divided into two sub-types : closed yes-no question , and question that/IN offers answer ( e. g. see ´seitseteist kolmkümend on kõige ´ilisem või /is the seventeen thirty the latest/ ) . The questioner has some opinion , hypothesis and <<< he/she >>> is expecting confirmation by the partner . These sub-types can be differentiated on basis of different linguistic realisations in Estonian . There are 237 wh-questions , 123 closed yes-no questions , 73 open yes-no questions , 153 questions that offer answer , 45 alternative questions in our analysed corpus ."
558	W14_5818	"the last two questions in these section 2s ; ( 2 ) If a participant do not satisfy the above conditions , he/she will not see Section 3s ; ( 3 ) each word stimulus in section 3s has an option which allows the participants to skip it in case <<< he/she >>> does not recognize that word ; ( 4 ) all the questions in the questionnaires must be answered except the ones which allow to be skipped and are explicitly claimed to be skipped ; ( 5 ) we wrote a monitor program to detect and resist spammers automatically ; ("
559	D19_1303	"sensationalism and fluency of the headlines by setting up two independent human annotation tasks . We ask 10 annotators to label each headline for each task . For the sensationalism annotation , each annotator is asked one question , "" "" Is the headline sensational ? "" "" , and <<< he/she >>> has to choose either ' yes ' or ' no ' . The annotators were not told which system the headline is from . The process of distributing samples and recruiting annotators is managed by Crowdflower . 6 After annotation , we define the sensationalism score as the proportion of"
560	W07_2429	who produces approximately the same results when repeating a test . We used the following method for generating training examples . Give a subject three documents : a reference document R and two other documents A and B. Thereafter the subject specifies which of the documents A or B that/IN <<< he/she >>> considers to be most similar to R. This method generated reliable data and it was also possible to automatically generate large amounts of training examples by using hypotheses about the similarity between documents . Resemblance and containment Resemblance and containment quantify the similarity between two documents . The degree of
561	W10_1604	"on general language in spite of building specific ones for the chat domain was taken aiming at measuring the impact that/IN the CSKT has on the final translation . The CSKT , in turn , will help one user to write his/her messages taking into account the cultural differences between <<< he/she >>> and the other user . A culturally contextualized translation will be generated by applying the knowledge derived from the two ConceptNets ( see section 3 ) to fix/filter the automatically generated translations in a semiautomatic process assisted by both chat users . To illustrate the use of both tools in"
562	W16_6501	"since CEFR , inter alia , defines CEFR proficiency levels through topics . For example , the CEFR document states that/IN one should be able to "" "" introduce him/herself and others and [ ... ] ask and answer questions about personal details such as where they live , people <<< he/she >>> knows and things he/she has "" "" ( Council of Europe , 2001 , page 24 ) . The verbs göra and heta are encountered very often at the beginner level as beginners learn to introduce themselves ( e. g. Jag heter Peter . ' My name is Peter ."
563	N16_3004	"main content regions : Reference and Translation . The task for this view requires to score the quality of a translation by comparing it to the provided reference . The annotator is required to use a slider ( see Figure 2 ) to provide a score . In return , <<< he/she >>> gets feedback in the form of stars , that reflect how close his/her score is to an optional gold-standard score . In principle , the stars are part of a gamification strategy used to keep the evaluator engaged . If the gold standard scores are not be available this option"
564	E17_1026	"labels . On the other hand , being only a NLP expert is not sufficient when in the text subtle and sophisticated references to the topic are present , resulting in an incorrect annotation because of an improper understanding . The first annotator A 1 is a NLP expert while <<< he/she >>> is not very confident on the topic selected , the second annotator A 2 has a good expertise in NLP and a good knowledge about the topic , the third annotator A 3 is a beginner in the field of NLP but he/she is competent on the topic . Dataset"
565	D15_1275	"their object in definiteness . Certain past , present and conditional verb forms differing in definiteness are only distinguished by an accent : hajtottak∼hajtották ' they drove ' vs. ' they drove it ' ; hajtanak∼hajtanák ' they drive ' vs. ' they would drive it ' ; hajtana∼hajtaná ' <<< he/she >>> would drive ' vs. ' he/she would drive it ' . A factored model could in theory improve the recognition of these structures . It is questionable however , whether the improvement would justify the costs . Conclusion We have described a method to restore accents in Hungarian texts ."
566	1999_mtsummit_1_86	", HAII . 1 . Input a grammatical sentence . ( Do not omit the subject or object of a sentence , or do not input a fragment of a sentence . ) Input the correct kanji . ( a person who uses HAII in the company should check whether <<< he/she >>> is inputting the correct kanji or not . ) 3 . A void using a phrasal verb . Use a hiragana or kanji character , and avoid using katakana for nouns which are not borrowed words from foreign languages . ( HAII sometimes does not recognise a word written in"
567	W14_6833	" ___  "" is recognized as a person name . We will discard such a replacement . Rule 2 : Stopword filtering For the one-character replacement , if the replaced ( original ) character is a personal anaphora ( _ ' you ' _ ' I ' _ ' <<< he/she >>> ' ) or numbers from 1 to 10 ( __________ ) , discard the replacement . We assume that/IN a writer seldom misspell such words . Take B1-0122-2 as an example : ... _ _ _ _ _ __ _ _ ... Although "" "" _ "" "" is a"
568	C88_2135	"was smallest possible , and therefore the deleted part might not match what they think is a word . The subjects were also told that/IN the materials that/IN they had were independent from each other . At the same time , the subjects were required to record the time when <<< he/she >>> start to fill out each paper , i. e. , one material , and when he/she completed , for each paper , to the unit of seconds . Results Completed sheets , expect for one by a subject who gave up the procedure in the middle are analyzed . Whether"
569	W11_3103	"( Q2-5 ) Questioners resubmitted almost the same questions as they had . They did not mentioned any kinds of information received from answerers . For example , in ( Q 14 ) , the questioner did not mention any kinds of information described in ( A 14 ) although <<< he/she >>> selected ( A 14 ) as a best answer . ( Q 13 ) My optical mouse is faulty . The cursor sometimes freezes . Is it end of life ? ( A 13 ) Look the back side and remove dust gathered around the red light . ( Q"
570	W10_4214	"referring expression , ( 2 ) stop the video and display as text the next solver ' s utterance including the referring expression ( shown in red ) , ( 3 ) ask the evaluator to identify the referent of the presented referring expression ( if the evaluator wishes , <<< he/she >>> can replay the video as many times as he likes ) , ( 4 ) proceed to the next referring expression ( go to ( 1 ) ) . Figure 3 shows a screenshot of the interface prepared for this experiment . The test data consists of three types of"
571	P06_2107	"this framework , the system suggests a possible translation of a given source sentence . The human translator can accept either the whole suggestion or accept it only up to a certain point ( that is , a character prefix of this suggestion ) . In the latter case , <<< he/she >>> can type one character after the selected prefix in order to direct the system to the correct translation . The accepted prefix and the new corrected character can be used by the system to propose a new suggestion to complete the prefix . The process is repeated until the user"
572	P14_2056	", boolean features denoting whether p added or removed people when responding to a message ( AddPerson and Re-movePerson ) , average number of replies received per message sent by p ( ReplyRate ) and average number of replies received from the other person of the pair to messages where <<< he/she >>> was a To recipient ( ReplyRateWithinPair ) . ReplyRateWithin-Pair applies only to IM t ( p 1 , p 2 ) . THR PR : This feature set includes two meta-data based feature sets -positional and verbosity . Positional features include a boolean feature to denote whether p sent the"
573	W13_3919	"offset provides an estimate of how much information is needed for predicting a word . Latency is the actual CPU time needed for predicting a word . Data Collection Participants and stimuli Eleven healthy native English speakers participated in data collection . Each speaker participated in one session in which <<< he/she >>> repeated a sequence of twenty-five words ( i. e. , one of the four phonetically-balanced word lists in [ 30 ] ) multiple times . Subjects , who were blinded to the specific purpose of the research , were asked to pronounce the target words in their habitual speaking rate"
574	W10_1303	"relevance of utterances to the current situation , but it would also significantly aid the user in remember-ing where these messages are stored so that/IN they can be accessed . Essentially the user could direct the system to step through messages appropriate for each scene of a given script as <<< he/she >>> is actually experiencing the scene . The utterance-based system would have a "" "" now point "" "" which corresponds to the scene in which the user is currently located in the script . Utterances useful for the conversation during that scene are easily available using very few keystrokes ."
575	L16_1289	"3 and 6,201 unique words . Table 3 highlights detailed statistics of the corpus . The corpus texts include typos ( spelling and grammatical errors ) written by the volunteers . This emphasises the fact that/IN in the real world scenario when a plagiarist reuses a piece of text , <<< he/she >>> paraphrases it with his/her own understanding and knowledge of the language . Moreover , it would be interesting to see the behaviour of plagiarism detection systems on these typographical errors . Example of a paraphrased plagiarised and non-plagiarised document Figures 1 and 2 show example passages from paraphrase plagiarised and"
576	2020_lrec_1_809	"happening during the gameplay ( e. g. , game states in Japanese chess ( Mori et al. , 2016 ) ) but also in making some comments that entertain listeners , as shown in Figure 1 . For example , when a commentator sees something exciting during the gameplay , <<< he/she >>> is required to explain to the listeners why the action was exciting using his/her expressive speech . Furthermore , the commentator should flexibly and instantly decide on the topic to convey because kaleidoscopic changes occur in the gameplay he/she watches , which can even have some interruptions during the recorded"
577	W19_4020	"arguments missing from the predicate-argument structure after addition of the empty categories in the Hindi Dependency Treebank ( Vaidya et al. , 2012 ) . T5 : "" "" Tore my calendar kyunki woh khana nai laya "" "" Translation : "" "" ( I ) tore my calendar because <<< he/she >>> did n't bring food . "" "" Although English is not a pro-drop language , pronoun dropping is observed largely in Hindi-English code-mixed data . The sentence above ( T5 ) is such an example from the corpus . We incorporate this in our data by inserting ' NULL '"
578	L16_1300	". Two rules were created to deal with this non-standard pronoun and anaphora resolution was limited to cases covered by these rules : _ An actor in the subject of a sentence ' s main verb ( based on dependency parsing ) is taken as the antecedent of a sentence-initial <<< he/she >>> in the following sentence . _ Antecedents for a pronoun ( from CorefGraph ' s coreference chains ) are only accepted if they are in the same sentence as the pronoun , or in the sentence immediately preceding the pronoun . Finally , to facilitate searches by date-range , propositions"
579	2022_eamt_1_20	"translations of the offensive language in this shows the impact a missing punctuation mark has on the translation . The three systems translated the first part as ' I gave up thanking ' . They , therefore , do not deliver the original meaning where the writer intended to say <<< he/she >>> is giving up trying to keep the pages , and that/IN the word ' thanks ' is used in a sarcastic way to express his/her frustration . Negation Negation can lead to critical errors when reversed from negative to positive or vice versa ; through e. g. dropping or reversing"
580	W07_1108	"to reason about how the entities referred to interact in the world . A common assumption in data-driven approaches to the problem is that/IN compounds with semantically similar constituents will encode similar relations . If a hearer knows that/IN a fish knife is a knife used to eat fish , <<< he/she >>> might conclude that/IN the novel compound pigeon fork is a fork used to eat pigeon given that/IN pigeon is similar to fish and knife is similar to fork . A second useful intuition is that/IN word pairs which co-occur in similar contexts are likely to enter into similar relations ."
581	1992_tc_1_5	"document , access structure , paths routing etc. Krupp Information Support System ( KISS ) To give an idea of how this is organised , here ' s an example . Through a series of hierarchically organised menus , the translator locates the particular document or part of the document <<< he/she >>> is looking for and gives the commands to the system to deliver it . In accordance with the user modelling structure the system checks the appropriate access to the file and then places the correct version of the document or the individual part of the document on screen , so"
582	2000_amta_workshop_3	"sure that his/ her choice is correct . If the learner has no idea about the meaning of the phrasal verb , he/she has to use the trail-and-error method to make his/her choice . The third stage is meant to help the learner to keep in mind the new information <<< he/she >>> has obtained at the lesson . After the learner has chosen the synonyms to all the phrasal verbs , he/she is supposed to fill in the table in which his/her work is summarized : Phrasal Verb Synonym Russian equivalent At the fourth stage , the learner is supposed to extend"
583	W07_2458	"the false start does not have a verb . The utterance with the false start has dictated the analysis of the entire utterance , though the real subject is the word ' seda ' . False starts Original utterance kui kui+0 //_J_// @J # if ta tema+0 //_P_// @SUBJ # <<< he/she >>> seda see+da //_P_// @ADVL @NN&gt; # this / sg part seda see+da //_P_// @PRD @ADVL # this / sg part tükina tükk+na //_S_// @ADVL # as a single piece siin siin+0 //_D_// @ADVL # here ei ei+0 //_V_// @NEG # not ole ole+0 //_V_// @+FMV # is Example 3 ."
584	W14_2514	"dynamics during the course of an interaction correlate with the power differences between its participants . We perform this study on the US presidential debates and show that/IN a candidate ' s power , modeled after their poll scores , affects how often he/she attempts to shift topics and whether <<< he/she >>> succeeds . We ensure the validity of topic shifts by confirming , through a simple but effective method , that/IN the turns that/IN shift topics provide substantive topical content to the interaction . A Cost Sensitive Part-of-Speech Tagging : Differentiating Serious Errors from Minor Errors All types of part-of-speech ("
585	C12_1138	"between 1,518 employees , and 13,724 dominance pairs ( pairs of employees such that/IN the first dominates the second in the hierarchy , not necessarily immediately ) . We labeled a participant to have hierarchical power within a thread if there exist a dominance pair in the gold hierarchy where <<< he/she >>> is dominating over any other participant in the same thread . According to the gold hierarchy , 113 out of the 1033 participants in our corpus have hierarchical power within the interaction . But only 12 of them ( 10.6 % ) were perceived to have situational power by our"
586	W03_2128	"answers . Questions and Directives Some typologies we have studied make a difference between questions and directives , some do not ( e. g. Bunt 1999 ) . Sometimes questions and directives are differentiated on the basis whether the user needs some information ( then it is question ) or <<< he/she >>> wants to influence the hearer ' s future non-communicative actions ( then it is directive ) . Our departing point is that/IN it is not important for dialogue continuation whether the hearer must to do something outside of current dialogue or not . He/she must react to both a question"
587	S16_1139	"  Bad "" "" comment if the respondent is also the questioner , and if the respondent is not the questioner but asks a question , it may also lead to a "" "" Bad "" "" comment . If a respondent was accustomed to submit high-quality comments , <<< he/she >>> has a high likelihood of offering a "" "" Good "" "" suggestion in the current question . So , we have voted the accuracy and error rates of comments for all users . The answer features are only applied in subtask A. 8 The size of both models are"
588	W10_0901	"connected facts ( here , has-part(Y4 , Y7 ) ) , and then proposing the new clause as an additional conclusion of that axiom . If there are no connected clauses , it is instead proposed as a new axiom about prophase . The user can verify/reject that proposal as <<< he/she >>> desires . Illustration An illustration of the system ' s typical processing of a paragraph is shown in Figure 3 . As in Figure 1 , normal font shows facts recognized as already known , and bold shows new knowledge . Again note that/IN the output facts are not a"
589	W18_0310	he/she is taking ' b. /á-na-á-tsukur-a/ → [ ànàátsúkúrâ ] ' he/she is taking them ' c. /á-na-á-demurir-a/ → [ ànàádèmùrǐrâ ] ' he/she is scolding them ' ( 12 ) a. /a-ká-ézeker-a/ → [ àkàézèkěrâ ] ' he/she has thatched with/for ' b. /a-ká-súrubik-a/ → [ àkàsúrúbǐk-â ] ' <<< he/she >>> is strong/firm ' The pattern in Digo reveals a local relation between the target and left high tone trigger in UTP . TBUs to the right of a voiced obstruent do not surface with high tones because the left high tone cannot spread across voiced obstruents to establish adjacency .
590	2005_sigdial_1_23	"U M . The scalar product ∆ U M is compared to a threshold value s. If ∆ U M &gt; s , users behave as novices , if ∆ U M ≤ s , they behave as experts . A user is categorised for the actual task . When <<< he/she >>> calls this task again , the system responds with the appropriate prompt -for novice or expert . Table 1 shows three examples for system responses for experts and novices . The comparison function takes three values as input : ∆ U M ( see above ) , s , and"
591	2020_readi_1_4	") -having two separated scores and the request ( 3 ) -printing the results . The other requests are considered as future work . The acquisition page At the beginning of an assessment session , the teacher inserts the name of the student involved in the test and the class <<< he/she >>> is attending ; then , the teacher selects the title of the novel on which the student is evaluated . Now , the system is ready to receive the audio file to be elaborated . Concerning this point , our system may work in two different ways : ( a"
592	P12_3027	"probabilities can be estimated using a parallel corpus , which is also used to obtain bilingual phrase alignment . Paraphrase Suggestion Unlike the N-gram prediction , in the paraphrase suggestion task , the user selects k words , { e 1 , e 2 , …e k } , which <<< he/she >>> wants to paraphrase . The model takes the m words { r 1 , r 2 , …r m } and n words { l 1 , l 2 , …l n } in the right and left side of the userselected k words respectively . The system also accepts"
593	Y13_2005	"online collocation exploration tool allows users to choose from the six mediumsized domain-specific corpora : MWC , EWC , LWC , MAC , EAC , and LAC , and the two largescale general-purpose corpora : BNC and Wikipedia . A user accessing the website can key in a keyword that/IN <<< he/she >>> intends to study and the system will automatically search for words which tend to co-occur with the keyword in the selected databases . The current released version of TechCollo ( i. e. TechCollo 1.0 ) provides searches of verb-noun collocations . The measures of frequency and tradMI , as specified"
594	2022_slpat_1_9	"along with the corresponding responses . We use these in Task 2 to present to the turkers as human responses . Task2 : Overall system interaction and metrics : In the interaction flow , the user reads the conversation context , picks a keyword ( From task 1 ) that <<< he/she >>> wants to respond with -which brings up a human response ( from Task1 ) and a model response ( kw_loss model ) . The user can use a response as is or edit or type a new response altogether . We analyse if the users tend to choose a model"
595	W19_0505	"of a text where this is necessary is : Bill does not own a vehicle . If Bill does not own a vehicle then he does not own a car . If someone does not own a car then he/she owns a motorcycle . If someone owns a motorcycle then <<< he/she >>> owns a vehicle . ACERules is unable to relate the group of atoms for "" "" Bill owns a vehicle "" "" and the more general ( because of the use of an indefinite pronoun ) "" "" he/she owns a vehicle "" "" concluding that/IN it is both true"
596	D15_1275	"past , present and conditional verb forms differing in definiteness are only distinguished by an accent : hajtottak∼hajtották ' they drove ' vs. ' they drove it ' ; hajtanak∼hajtanák ' they drive ' vs. ' they would drive it ' ; hajtana∼hajtaná ' he/she would drive ' vs. ' <<< he/she >>> would drive it ' . A factored model could in theory improve the recognition of these structures . It is questionable however , whether the improvement would justify the costs . Conclusion We have described a method to restore accents in Hungarian texts . The baseline method using only a"
597	O05_3003	". This is not agreement on a certain opinion but simply confirmation that/IN the stated information is correct . Utterances can be corrected ( correct ) , rephrased ( rephrase ) , or repeated ( repeat ) . The listener can give explicit signals through overt utterances to express that <<< he/she >>> is considering/processing the statement made by the speaker ( feedback ) . The listener can produce simple sounds or words to show that he/she understands the message ( feedback_understanding ) or does not understand the message delivered by the speaker ( feedback_non_understanding ) . Or the listener can also give"
598	L16_1336	"participants because the site is written in Japanese and is targeted at Japanese people . A good understanding of Japanese is required to navigate the website . We paid the participants one Japanese yen for each annotation . For example , if a participant provided colors for five words , <<< he/she >>> obtained five yen for the annotations . Note that/IN for increased convenience , we presented five words with contexts simultaneously to participants , as shown in Figure 3 . This was also the case for the collection of color associations for words without contexts . We were not able to"
599	W17_5051	"in that/IN they required to choose a form which was marked in some way or not the most intuitive one ( UF ) : On the one hand , this concerns marked spellings that/IN only recently have been adapted by the Duden ( e. g. non-standard &lt;kuckt&gt; for &lt;guckt&gt; ' <<< he/she >>> looks ' ) . On the other hand , our requirement not to correct grammatical errors and certain capitalizations was not obeyed in five cases ( e. g. &lt;wegfahrt&gt; was changed to &lt;wegfährt&gt; ' drive away ' , an agreement error ) ; three of them were also mixed with"
600	L16_1485	"frequencies of word-senses extracted from the senseannotated corpus of various in-house datasets . Experts have been asked to rank the senses of a word based on this information and also his/her intuition . If the experts get confused or are unable to rank the synsets of a word , then <<< he/she >>> can skip the word from its ranking for the moment and move on to the next word . • Display Ranking : An expert can see the already ranked synsets by providing a word and its POS . • Reset Ranking : The experts have been given the facility of"
601	W03_2128	"this act . Refusal and Missing Information The second problem group are situations where the answerer is not able to give information . Three cases can be differentiated depending on continuation of dialogue : the answerer does not have the needed information , he/she refuses to give it , or <<< he/she >>> cannot give it immediately . If the answerer does not have the information then the questioner must abandon the following attempts . In the case of having information we have two possibilities depending on whether the answerer is the consultant or client . The first possibility can be excluded because"
602	W18_4515	"have the same knowledge as the author or typical reader at the time of the works ' publication . To overcome this , we try to approximate the world knowledge of a typical reader : wherever the annotator gets the feeling that/IN something is assumed to be common knowledge , <<< he/she >>> is allowed to look up the missing facts to derive the right references . EN translation : For Karl had nothing to hope for in the world , he was drawn to Bohemia to the sound of [ Friederich ' s ] 1 triumphant drums . Allow me , he"
603	2021_naacl_main_472	"spans , we asked annotators to annotate all of them . The Usage of Tense . Since all the meetings happened , we ask annotators to use past tense . How to Denote Speakers . If the gender information is unclear , we would ask annotators not to use ' <<< he/she >>> ' to denote speakers . We also asked them not to abbreviations ( e. g. , PM ) to denote speakers , and use the full name like ' Project Manager ' instead . Abbreviations . In the raw meeting transcripts , some of abbreviations are along with character '"
604	P17_1118	"continuing speech , or took a long pause , an evaluator would use the stimulus question "" "" What happens next ? "" "" , seeking to encourage the participant to continue his/her narrative . When the sub-ject was unable to proceed with the narrative , the examiner asked if <<< he/she >>> had finished the story and had something to add . Each speech sample was recorded and then manually transcribed at the word level following the NURC/SP N. 338 EF and 331 D2 transcription norms 3 . Other tests were applied after the narrative , in the following sequence : phonemic"
605	W11_2005	"instances . We experimented both with using priors based on the empirical distribution in the training data and with using uniform prior ( i. e. P ( character ) = 0.5 ) . Given a test conversation , we use individual classifiers for each of the characters to determine whether <<< he/she >>> was present or not . For the task of identifying speakers , given an utterance , the Naive Bayes classifier is set up as follows : Again , we create term-document matrices for each of the speakers , where a document is a turn uttered by the speaker . Turns"
606	2020_challengehml_1_2	"containing at least one mention . Second , we work with the fine-grained annotations gathered for the POM dataset by Garcia et al. ( 2019b ) . This dataset is composed of 1000 videos containing reviews where a single speaker in frontal view makes a critique of a movie that/IN <<< he/she >>> has watched . There are videos from 372 unique speakers , with 600 different movie titles being reviewed . Each video has an average length of about 94 seconds and contains 15.1 sentences on average . The fine-grained annotations we utilize are available for each token indicating if it is"
607	2020_conll_1_46	"of Hinglish , we replace the domain of college majors , which is highly anglicized with respect to Hindi , with favourite fruit which is more equally represented in both languages . Handling gender-markings Third person pronouns and verb forms in Hindi are usually gendermarked ( eg . karta/karti [ <<< he/she >>> does ] , uska/uski [ his/her ] ) . Since the Spanglish KB does not provide any information about the gender of friends , we consequently notice the dialogues using this system to be gender-skewed . In the COMMON-AMIGOS Spanglish data ( Ahn et al. , 2020 ) , the"
608	W07_2310	"or to adopt a similar style . It should in large part protect the system from mistakes such as spelling errors , and , when queried , increase the likelihood of a search term being associated with more than one resource . The user however retains complete freedom , as <<< he/she >>> does not have to use the folksonomy values but can still use free text ; and every entry the user makes is immediately added to the folksonomy . The folksonomy , then , allows us to subtly guide user behaviour , while being completely unrestrictive . Conclusion and Future Work"
609	O11_4001	"account when using the definite article . According to Hawkins ( 1991 ) , using the definite article enables the hearer to access the NP in a p-set ( a set of knowledge known by the hearer/reader as being definite ) . The speaker/writer should use the definite article when <<< he/she >>> is confident that/IN the other party knows that/IN the NP is definite . A communication breakdown will occur if the speaker/writer uses the definite article erroneously or mistakenly believes that/IN the hearer has such knowledge . The writers in this corpus have not been falsely assuming that/IN the reader had"
610	Y18_1077	"vacations , and naturallyoccurring phenomena like flood and earthquake . A post can contain more than one sentence , and each of these may be associated with zero to several events . In a single post , it is possible that/IN one may describe who he/she travelled with , how <<< he/she >>> celebrated his/her birthday , and what he/she ate with his/her friends , summing up to three different events . Such posts are split into independent sentences to extract the individual event details and are represented in an event frame of the form : verb ( doer , object , tagged"
611	2022_bea_1_23	"being : txekan- : vi & vtr caminar , marchar , pasear || vtr medir con pasos to walk , to take a walk -yaw- : andar to go -ke- : habitualmente usually -la- : negación a modo "" "" normal "" "" indicativo negation -i : el / ella <<< he/she >>> Given this , 5 the goal is that/IN the learner deduces "" "" el/ella no anda caminando habitualmente "" "" "" "" he/she does not usually go for walks "" "" . The challenges of this informal analyzer are many . Among them : how to give enough meaningful translations"
612	2021_acl_long_7	"key statistical information of the PENS dataset is exhibited in Fig. 2 ( a)-(e ) . Training Set The training set of PENS consists of impression logs . An impression log records the news articles displayed to a user as well as the click behaviors on these news articles when <<< he/she >>> visits the news website homepage at a specific time . We follow the MIND dataset ( Wu et al. , 2020 ) that/IN we add the news click histories of every individual user to his/her impression log to offer labeled samples for learning user preferences . Hence , the format"
613	L16_1471	"which each of them is written . 9 . lett files contain plain text consisting of a line for every document processed . Each line consists of 6 tab-separated values : a two-character language identification , the mime type , the char-that enables the user to define the language pairs <<< he/she >>> is interested in , together with all the paths required to run Bitextor , one of which is a small bilingual lexicon which can improve the bitext extraction results . 10 The first script also produces and runs a Makefile in a parallel fashion . All Bitextor ' s processing"
614	W97_0809	"When the threshold is high , more tuning of the rules needs to be done , and the system is expected to perform better . Some problems were detected which prevent better performance of the system . The current domain is a newsgroup , where anyone can post anything which <<< he/she >>> believes is relevant to the newsgroup . It is inevitable that/IN some typographical errors and some abbreviations occur in the articles . And the format of the article sometimes is unpredictable . The system performance is also hurt by the error in the partial parsing . ( /~2 + 1.0"
615	2020_signlang_1_28	"the different parts of the protocol used has been conducted : • When asking to open the definition of a signed notion , we chose to provide the sole sign for the notion . If the participant did n't know the sign , we would ask him to find what <<< he/she >>> found the most similar to it . • For questions on notions in French or illustrated by a diagram , the facilitator gave the user a piece of paper with either the printed word or the printed diagram for the notion . This in order to avoid the misunderstanding of"
616	D13_1038	", we applied Amazon Mechanical Turk to solicit feedback from the crowd 2 . Through an interface , we displayed an original scene and generated referring expressions ( from different generation strategies ) in a random order . We asked each turk to select the object in the scene that/IN <<< he/she >>> believed was the one referred to by the shown referring expression ( i. e. , reference identification task ) . Each referring expression received three votes from the crowd . In total , 217 turks participated in our experiment . Generation Strategies We applied a set of different strategies to"
617	O15_2000	"where "" "" ___ "" "" is recognized as a person name so this replacement is discarded . Rule 2 : Stopword filtering For the one-character replacement , if the replaced ( original ) character is a personal anaphora ( _ ' you ' _ ' I ' _ ' <<< he/she >>> ' ) or numbers from 1 to 10 ( __________ ) , discard the replacement . We assume that/IN a writer seldom misspell such words . Take B1-0122-2 as an example : ... _ _ _ _ _ __ _ _ ... ( I will at two number exit wait"
618	D13_1038	"relationships sometimes are difficult to describe the target object , so the matcher must resort to group information to distinguish the target object from the rest of the objects . For example , suppose the matcher needs to describe the target object 5 in Figure 1 ( b ) , <<< he/she >>> may have to start by indicating the group of three objects at the bottom and then specify the relationship ( i. e. , top ) of the target object within this group . The importance of group descriptions has been shown not only here , but also in previous works"
619	2001_mtsummit_papers_15	", the idea can still be vaguely apprehended . Word choice , syntactic arrangement , and/or alternative expressions are generally bizarre , and critical words may remain untranslated . 3 . The general idea is intelligible only after considerable study , but after this study one is fairly confident that/IN <<< he/she >>> understands . Poor word choice , grotesque semantic arrangement , untranslated words , and similar phenomena are present , but constitute mainly "" "" noise "" "" through which the main idea is still perceptible . 4 . Generally clear and intelligible , but style and word choice and/or syntactical"
620	2021_acl_long_458	"all of the identified sentences in the article , which is actually a global inference . Conclusion and Future Work We propose new techniques to infer fine-grained provenance for an article that contains multiple claims ; this is important for a critical reader to understand what information supports the article <<< he/she >>> is reading and what its origins are . The inference consists of models that can identify the sentences that refer to important external information , generate the metadata that can make it more likely to recall the source articles using a search engine , and do an ILP inference to"
621	W00_0306	"error rate , this becomes an even more important issue . The problem , then , is to find a compromise between the two . We compared two ways to systematically generate system utterances with only selected attributes , such that/IN the user hears repetition of some of the constraints <<< he/she >>> has specified , at appropriate points in the dialogue , without sacrificing naturalness and efficiency . The specific problems , then , are deciding what should be repeated , and when . We first describe a simple heuristic of old versus new information . Then we present a statistical approach"
622	W15_4609	"themselves in and asked to find a suitable program to watch using the prototype , for example : You are at home and have young nieces and nephews coming over . Find a program to watch with them . The subject was asked to continue speaking with the system until <<< he/she >>> either found a suitable program ( in which case the scenario was recorded as a success ) or gave up ( in which case a failure was recorded ) . For this evaluation , the subject was SUS score is a industry-standard usability metric . asked to do these tasks"
623	2021_ranlp_srw_27	"tool . Thus it is easy for an anchor to choose the emails folders from which the emails may be extracted and to choose the collaborators that could be contacted to become participants . This gives the possibility to avoid folders with private or personal contents and contacts with whom <<< he/she >>> has confidential exchanges . It also helps to provide data in JSON and CSV formats for future processing . Until now we have obtained 78 consents from close collaborators involved in shared projects . Based on these 78 consents and as a first stage of data collection , we succeeded"
624	W18_2204	"terms ( Lat et al. , 2006 ) and sentences ( Tabaranza et al. , 2016 ) in comparable corpora . There are also attempts to gamify manual translation ( Ilao et al. , 2016 ) in role-playing games : if the user wants to earn more credit points , <<< he/she >>> can translate phrases and there ' s an automatic scoring mechanism that rewards the user after a given time frame . There are also those ( Octaviano et al. , 2018 ) that apply spell checking and language identification as pre-processing step to clean the data . To assist translators"
625	O09_3004	". Thus , they can be considered our outside testing set . Table 3 shows some statistics about these stories in the two sets . For each story in both sets , summary candidates were generated and ranked by the proposed method . A human summarizer chose a candidate that/IN <<< he/she >>> thought to be the best among the candidates . The chosen one was then labeled in terms of its quality with one of the three tags : G ( good ) , F ( fair ) , or B ( bad ) if it was correct and coherent , correct"
626	2021_eacl_main_285	"the first document , the customer emphasizes price a lot . Our method cannot extract opinion words on snippets such as "" "" not at that price "" "" and "" "" for half the price . "" "" For the second document , the reviewer loves this movie because <<< he/she >>> loves the basketball player . The reviewer thinks that/IN the movie itself does not deserve a high score . Our method detects both positive and negative polarities on this document , so it tends to predict as negative . Because most mixed polarities are likely to be negative polarity ."
627	I13_1079	"seems to be no solution that guarantees 100 % certainty and 2 ) the likelihood of committing suicide appears to be so low ( even for artists ) that/IN it might not be such a bad course of action to assume that/IN any given lyricist will not commit suicide unless <<< he/she >>> already has . Though the vast majority of lyricists do not commit suicide , this fact leads directly to some of the other problems that afflicted the construction of our corpus . Since the number of lyricists who committed suicide is constrained , this leads to issues beyond the collection"
628	W16_1710	": • The main point of confusion among annotators is deciding when they should infer the stance of the comment toward an entity based on the stance toward another entity . For example , if a opposes the Army during Morsi ' s presidency term , does it imply that/IN <<< he/she >>> supports Islamists ; • The task does not model the people who mainly care about stability regardless of political reform or the role of religion in politics ; • Even though the comments were collected from a specific set of events , we do not present the annotators with the"
629	2020_rocling_1_25	"not to recognize the sound /i/ at the frequency recognized by a French person but is likely to recognize the sound /i/ at a frequency dictated by his/her mother tongue such as between 300-600 Hz because his/her perception is likely to be mediated through his/her mother tongue , Thus , <<< he/she >>> is in danger of confusing /u/ ( between 300-600 Hz ) with /i/ ( between 3200 and 6400 Hz ) , or with /o/ ( between 400 and 800 Hz ) as these sounds also occupies part of the spectrum that contains /i/ at different frequencies . In order for"
630	2021_nlp4convai_1_11	"utterances that are not handled by the existing system ( i. e. , unclaimed utterances ) using the increasing catalog of 3P skills . Traditional recommender systems such as video recommendation recommend a ranked list of items to a user . The user scans the list and select the one <<< he/she >>> likes the most ( Covington et al. , 2016 ) . The feedback from the user is treated as label ( accept/reject ) for learning a model . However , due to the limitation of voice user interface ( VUI ) , we can only present the top-1 skill to"
631	W16_3601	"There are 31 questions . Table 1 shows a summary . Attribute Q a Example Question Birthday 3 Was he/she born before 1950 ? Birthplace 9 Was he/she born in USA ? Degree 4 Does he/she have a PhD ? Gender 2 Is this person male ? Profession 8 Is <<< he/she >>> an artist ? Nationality 5 Is he/she a citizen of an Asian country ? Table 1 : Summary of the available questions . Q a is the number of questions for attribute a. At the beginning of each game , the simulator will first uniformly sample a person from the"
632	W19_8305	"himself/herself as one of the villagers . The swindle werewolf can have the initiative for misleading villagers , while it is easy to be a target of divination or execution . The stealth werewolf cannot have the initiative , but it is hard to raise a doubt of werewolf since <<< he/she >>> does not work directly on the subject of execution . We attempt to make the stealth werewolf an agent , and would like to clarify important factors for the stealth werewolf . If an agent can talk and mislead villagers without attracting attention from other players , it is a"
633	W97_1408	"descriptors in natural language terms in a reasonable way . Despite these achievements , all existing algorithms still have some serous limitations which originate from : 1 . An implicit , simplifying assumption The addressee is not only assumed to understand familiar terms that appear in a description , but <<< he/she >>> is also assumed to be able to recognize the associated object properties under all environmental conditions . A crucial concept missing In addition to identificational properties , also navigational information would be urgently needed for obtaining comprehensible descriptions ( see ( Reiter , Dale , 1992 ) ) . In"
634	2016_lilt_14_5	"years and more ( ... ) . ' ( 18 ) E acrescenta que não existe nenhuma lei que permita à Portugal Telecom cortar o serviço telefónico por os utentes não pagarem , por exemplo , as chamadas de valor acrescentado , tipo telefonemas eróticos , etc. ' And [ <<< he/she >>> ] adds that/IN there is no law that allows Portugal Telecom to cut the phone service when users do n't pay , for instance , value added calls , such as erotic phone calls . ' The role played by some of these attributes in the labeling of permitir is"
635	P19_1369	"investigate learning a proactive dialogue system by planning dialogue strategy over a knowledge graph . Our assumption is that/IN reasoning and planning with knowledge are the keystones to achieve proactive conversation . For example , when humans talk about movies , if one person learns more about some movies , <<< he/she >>> usually leads the conversation based on one or more entities in the background knowledge and smoothly changes the topics from one entity to another . In this paper , we mimic this process by setting an explicit goal as a knowledge path "" "" [ start ] → topic a"
636	C16_1016	"CRP , there are tree-structured restaurants with tables and customers that are regarded as latent variables of words . When a customer enters the leaf restaurant h , which corresponds to context , he/she sits down at an existing table or a new table depending on some probabilities . If <<< he/she >>> selects a new table , an agent of the customer recursively enters the parent restaurant h as a new customer . Here , we represent the depth of h as |h| , and there is the relationship |h | = |h| − 1 . Given the seating arrangement of customers"
637	E89_1021	"emergency fund , but the system also foresees the possibility of a request for explanation from the user . At the next level , the system expects the user to speak about another parameter of the same plan ( the amount ) . At the level still further below , <<< he/she >>> can speak about the emergency fund in general , he/she can for example refuse the emergency fund , or ask for explanation on it . And so on , until the system reaches the most unexpected reactions of the user , i. e. , even things that are not related"
638	L16_1206	"1 . Editor Role Identification : A deeper analysis to the type of work done by different editors might reflect who they are . For example , a user who always works on copy editing and rephrasing might be a copy-editor ; one seems to be a substantive expert if <<< he/she >>> contributes to information insertion a lot . Therefore , our edit taxonomy enables us to identity user roles based on their elemental actions . Collaboration Quality Prediction : The quality of collaboration varies widely . For example , although there are over 4.5 million articles in the English Wikipedia ,"
639	Y13_1035	"comes from audience ' s judgment , it is with interest to understand this issue from the speakers ' angle , the tweeter . The third question is based on Clift ( 1999 ) who claims that/IN in irony the speaker may or may not be aware of false words <<< he/she >>> uttered , but the speaker is always aware of his/her own sarcastic utterance . The awareness of speaker can be identified by analyzing the contents of the tweets tagged with irony or sarcasm . If a speaker is aware of his/her false words , then the tag should be used"
640	2022_naacl_main_227	"to learn from their mistakes if they submit an incorrect reference . Concretely , if an annotator submits a reference that is not included in the final golden references , he/she has to modify his/her submission into a correct one . Moreover , the annotator can also make complaints if <<< he/she >>> insists that/IN his/her submission is correct . We find that/IN the self-study and making-complaints mechanisms can trigger very helpful discussions . To improve annotation efficiency , we have developed a browser-based online annotation tool to support the above workflow and mechanisms . Table 4 : Data statistics , including the"
641	P86_1016	"explanation is that/IN different beliefs about what the user believes trigger the use of each strategy . Notice that/IN each strategy can be seen as refuting a different kind of support for the misconception . My claim is that/IN a speaker may choose a strategy depending on the support that/IN <<< he/she >>> believes the user may be using to come up with the misconception . Let us take each strategy in turn , examine what beliefs might have led to the use of that strategy , and then investigate how this information might be used by a system to generate responses to"
642	E93_1037	"with Taro . 4 A discourse can be acceptable without any head at all : ( 11 ) 01&lt;i&gt; 02&lt;j&gt; seki wo uzutte ageta node , seat ace give favor because 01&lt;/&gt; 02&lt;j&gt; orei -wo iwar eta . 01&lt;i&gt; thanks ace say pass chotto terekusa katta slightly embarassed cop Because <<< he/she >>> gave him/her a favor of giving a seat , he/she thanked him/her , who was slightly embarrassed . The speaker of 11 , or watashi I would be the most likely antecedent for the elided subjects here ; whoever gave the favor was thanked for the kindness . Let us"
643	2020_lrec_1_807	"the fields of both phonetics and speech technology . Phonetics tasks include investigating various phenomena of spontaneous speech , such as disfluencies and strategies of turn-taking . Of particular interest is research on how a speaker ' s voice changes in different social situations-in our case , depending on who <<< he/she >>> is speaking with ; knowing the limits of variability for one speaker are crucial in solving speaker verification tasks . As for speech technologies , apart from entrainment research , the SibLing corpus will be useful for a range of tasks in the field of speaker verification . Acknowledgements The"
644	2005_sigdial_1_3	"Deaccenting is defined as the absence of a pitch accent on a word that might otherwise expected to be accented ( Ladd , 1980 ; Swerts , Krahmer and Avesani . , 2002 ) . While accenting is normally used by a speaker as a prosodic pointer to information that/IN <<< he/she >>> intends to present as new to the listener or as a pointer to a contrast-relation , deaccenting may be used to signal that/IN a word refers to given information ( or information that can otherwise be expected in the discourse ) . This commonly held view rests on plenty of"
645	O08_5002	"% X P X - A 3 - - - - X X X X = % P X X - Assume that/IN a user is looking for usage references of the phrase "" "" not only ... but also "" "" . Without exact memory of the phrase , <<< he/she >>> specifies the query in the form of four sequential words "" "" not only but also "" "" . Suppose that/IN there are three relevant sentences , S 1 , S 2 , and S 3 , in the corpus . S 1 : We must also make sure that/IN"
646	2003_mtsummit_papers_16	"of an element that has a very distant antecedent , both possibilities ( masculine and feminine for gender , singular and plural for number ) are offered for the posteditor to decide . E. g. "" "" estívolles lendo historias ós rapaces ; sen embargo non &lt;REV&gt;llas/llelas&lt;/REV&gt; creron ( ' <<< he/she >>> was reading aloud some stories to the children ; however , they did not believe them of him/them ' ) After the configuration of the marks that/IN the posteditor has considered to be relevant , these have to be processed . To do that/IN , it is necessary to press"
647	Y12_1056	"language and will not risk the failure of supposed communicated expectations of the partner -a native speaker . The next pair was spe . perspective and politeness feature ( F2 with F4 ) . In case when the author of English request used more direct utterance through factor F3 , <<< he/she >>> mitigated this directness with expressive factor F4 ( politeness feature ) . When he/she decided to express him/herself in a more indirect way , he/she used a combination with politeness feature ( F2 with F4 ) reinforcing the likelihood of request fulfilment , which is confirmed by the last couple"
648	W13_3714	"them ; for example , ' elutazik ' [ he/she ] travels away ' has a single stress assigned to the first syllable . Importantly , a similar situation holds when the VM is followed by an auxiliary . For example , in ' el fog ' utazni ' [ <<< he/she >>> ] will travel away ' , el and the first syllable of utazni are stressed , while fog is unstressed , presumably because el and fog belong to the same phonological word . Under the reasonable assumption that/IN elements forming phonological words tend to be syntactically closely related , this"
649	W11_0610	" , ADOS :  "" unusual "" "" ) and sometimes contradictory ( ADOS : "" "" appropriate "" "" vs. ADI-R : "" "" inappropriate "" "" ; ADOS : "" "" phrases ... they could not have heard "" "" vs. SCQ : "" "" phrases that/IN <<< he/she >>> has heard other people use "" "" ) . In what is one of the only studies focused specifically on unusual word use in ASD , Volden and Lord ( 1991 ) transcribed two 10-minute speech samples from the ADOS for 20 school-aged , highfunctioning children with autism and 20"
650	C92_4182	"if a speaker is uttering his/her own address for tile concept ' address ' , he/she will use "" "" 3uusyo""""([my ] address ) , e. g. "" "" Juusyowa Oosaka-sht desu . "" "" ( My address is in Osaka~city . ) . On the other hand , if <<< he/she >>> is uttering tile other participant ' s address , he/she will use "" "" . qo . juusyo "" "" ( [ your ] address ( polite fornl ) ) , e. g. "" "" Go-juusyo-wo onegaishi-masu . "" "" ( Your address , please ? ) These facts lead"
651	W14_0210	"and the problem description , i. e. what is the difference between instructions of navigation application and reality . After the beginning the dialog continues by iterative searching of unique navigation points that may help the navigator to find the position and orientation of the lost blind person , until <<< he/she >>> gets to the location from which he/she can continue with the track . The dialog system should take into account following findings about the dialog structure . When the blind person get lost , he/she uses information , provided by navigation application for sections that seemed to him/her correct and"
652	2012_amta_showcase_0	"from the user ' s feedback . On the other hand , a very natural desire of a human translator using MT in a CAT tool would be to see a consistent use of terminology and style that is similar to his/her own throughout the text , and that/IN once <<< he/she >>> corrects an error this should not occur again in the following text segments . In addition , such adaptations should happen in real time . On-line learning MateCat will provide methods for the automatic self-correction of MT making use of the implicit feedback of the user . The segments of"
653	H94_1077	"avoid controlling the structure of the spoken sentences . When the user could obtain the desired telephone number , he/she wrote down the number on the answer sheet , and proceeded to the next task . Even if the user could not get the telephone number alter all efforts , <<< he/she >>> was requested to proceed to the next task . Questionnaires After testing , each user was requested to answer several questions , and the information obtained was compared with various logs recorded during the test . Results The results of the experiments gave the task completion rate as 99 %"
654	2007_sigdial_1_22	"a user utterance and s is the first system utterance among the system utterances overlapping u. We found that/IN people tend to stop their own utterances when d is between −0.2s to 0.4s . When d is larger than 0.4s , the user has already spoken for a while so <<< he/she >>> might try to finish the utterance . Next , we investigated the end time of the overlapped user utterances , because discontinuations can be expected to occur soon after the overlapping starts . Table 4 shows the frequencies of discontinuations depending on the length of the user utterance after the"
655	C96_2162	"e the hearer already knows the fact that/IN the three components hold in the situs]ion , interpretation of irony results in confirmation of the mosl ; uncertain information , that is , the speaker ' s emotional attitude . However , when the hearer does not recognize all components , <<< he/she >>> also ol)tains new information that/IN the unrecognize . d component holds in a current situation . Therefore , our the . ory includes many previous theories claiming that irony ( : ommunicates an ironist ' s emotional attitude . For example , in the . case of ( 5a )"
656	P16_1044	"40 quarters , or is eligible for Medicare by virtue of being disabled or some other reason , your spouse can receive his/her own medicare benefits . If your spouse has not met those qualifications , if you have met them , and if your spouse is age 65 , <<< he/she >>> can receive Medicare based on your eligibility . Another candidate answer : If you were married to a Medicare eligible spouse for at least 10 years , you may qualify for Medicare . If you are widowed , and have not remarried , and you were married to your spouse"
657	W13_3714	"the infinitive ) form a grammatical unit , which , however , is subject to word order variation . The link between VM and infinitive The first , rather trivial observation is that/IN in patterns like el fog utazni ' he/she will travel away ' and részt akar venni ' <<< he/she >>> wants to take part ' , there is a syntactic relationship between the first and the third element . This relationship is one of licensing : the so-called verb modifiers ( el ' away ' , részt ' part . ACC ' ) could not occur in these structures were"
658	W19_0413	"Such analysis offers finegrained information to a user or an organization who seeks users opinion towards any specific entity . For example , based on the users ' feedback , an individual can draw a general perception about the specific attribute or aspect of a product or service , and <<< he/she >>> can make an informed decision about the product or service under observation . Similarly , an organization can utilize the feedback to refine its product/service or to take a decision in the business model . Aspect-based sentiment analysis ( Pontiki et al. , 2014 ( Pontiki et al. , ,"
659	O12_1007	" end of the continuum . A concern is raised about those who tended to take the Facebook Wall as the space to share informal messages . Even if a person has broad vocabulary knowledge and would use rarely-seen words when writing formal messages or articles , the possibility that/IN <<< he/she >>> uses those words in the informal/spoken mode might decrease . Furthermore , due to the inconsistent modes across participants ' Facebook data , the seriousness of the problem caused by the Sinica Corpus word frequency might vary from person to person . As mentioned above , various commonly-used spoken or
660	W19_4603	as speakers ' competence and proficiency in either or both languages . This is why we see a wide range of regular patterns as well as highly idiosyncratic behavior . CS Types and Categories A speaker can turn from one language to the other at the sentence level , or <<< he/she >>> can make the turn within the same sentence . Some researchers ( Muysken et al. , 2000 ) use the term  "" code-switching "" "" to refer to the former case while reserving the term "" "" code-mixing "" "" to refer to the latter . However , these"
661	W19_0505	"strict rules . The reason is that/IN ⇒ inherits the scope from ¬ in this case . A conceptually more intricate case is when negation occurs in atypical manner in the bodies of rules , e. g. for the sentence "" "" if someone does not own a car then <<< he/she >>> owns a house "" "" . Here there are several options . The most straightforward , following more or less ( Garreau et al. , 2015 ) , is to put the burden of proof on the existential assertion ; i. e. by default no one owns a car ."
662	Y12_1056	"requester uses factor F5 , he/she assumes that/IN explaining the reasons to the requestee and requestee ' s potential understanding of reasons of request may increase the likelihood of the fulfilment of a request . Consequently , the requester appeals to the empathy and imagination of the requestee , since <<< he/she >>> considers their influence as an effective strategy . Factor F7 ( mitigating devices ) reduces the impact of a request on the requestee , in terms of whether the requester does not interfere or over-interfere with his/her request in the requestee ' s time , space or decision making ."
663	Y13_1035	"are many frameworks in accounting the mechanism of ironic effects . The review from Clift ( 1999 ) on the Traditional Oppositional Model ( TOM ) has critically pointed out the advantage of TOM locates at its illustration in the divergence between a speaker ' s words , and what <<< he/she >>> might mean by his/her words . However , this two-stage mechanism is criticized for ignoring the fact that/IN two aspects of meaning must be perceived simultaneously to make an utterance as irony . Correspondingly , the Echoic / Interpretation model ( Sperber and Wilson , 1981 , 1986 ) is"
664	2020_lrec_1_73	"  I like classic cars ! "" "" because it is biased by people mentioning classical music . Second , we find that/IN in some cases our model generates attributes that are relevent but not certain , making the attribute ambiguous . For example , when a user says <<< he/she >>> is "" "" Tired from too many parties , "" "" our model predicts the attribute ( I , like activity , partying ) although the user does not mention it explicitly . Third , sometimes no predicate is triggered , even if there is some useful user information ."
665	R13_1065	"factor F4 -a politeness marker ( with words such as please or thank you ) -formulated in requests in comparison to MT . On the contrary , factors F5 and F7 are much more used in FL . These are expressive factors . When the requester uses factor F5 , <<< he/she >>> assumes that/IN by explaining the reasons to the requestee and the requestee ' s potential understanding of the reasons of his/her request may increase the likelihood of the fulfilment of a request . Consequently , the requester appeals to the empathy and imagination of the requestee , since he/she considers"
666	N09_1066	"by performing a random walk on the graph . The salience of a node is recursively defined on the salience of adjacent nodes . This is similar to the concept of prestige in social networks , where the prestige of a person is dependent on the prestige of the people <<< he/she >>> knows . However , since random walk may get caught in cycles or in disconnected components , we reserve a low probability to jump to random nodes instead of neighbors ( a technique suggested by Langville and Meyer ( 2006 ) ) . Note also that/IN unlike the original PageRank"
667	1999_mtsummit_1_32	"  CN "" "" 236 "" "" ) ( "" "" algographics , co. , ltd . "" "" CN "" "" 713 "" "" ) Extending Transfer Knowledge The next step is extending the transfer knowledge . The rule-writer who writes the transfer knowledge translates the sentence before <<< he/she >>> writes the knowledge about it . He/She checks the source language structure , the target language structure , and the translated target sentence . If the source language structure is wrong , he/she checks the current pattern in transfer knowledge . When the selection of transfer knowledge fails , he/she"
668	Y07_1005	"Ahn & Cho ( 2006 ) , non-Case-marked subject wh-phrase nwukwu ' who ' has only D(iscourse)-linked interpretation in the sense of Pesetsky ( 1987 ) , as shown in ( 2 ) . ( 2 ) a. Nwukwu-∅ Yenghi-lul manna-ss-ni ? who Yenghi-Acc meet-Past-Q ' Who is such that/IN <<< he/she >>> met Yenghi ? ' ( only D-linked reading is possible ) b. Nwu(kwu)-ka Yenghi-lul manna-ss-ni ? who-Nom Yenghi-Acc meet-Past-Q ' Who met Yenghi ? ' ( non-D-linked reading is also possible ) However , such restriction is n't observed in the case of bare object wh-phrases in ( 3 )"
669	2001_mtsummit_papers_59	"N -&gt; __(bath ) Dictionary Manager Dictionary Manager handles interface between users and dictionaries . Users can search , add , and modify entries with the Dictionary Manager . A unique feature for the collaborative translation is that/IN a user can only add entries and leave translation fields blank if <<< he/she >>> is not sure of appropriate translations . Then , other community members fill the translations if they know a correct translation . To build a dictionary efficiently , the dictionary manager provides 2 dictionary-building tools : Term Extractor and Example Learner . We will explain them in the next section"
670	W14_2603	"more job opportunities ) . But merely from the annotated gfbf triple , it is inferred that/IN the law has negative effect since it reduces the number of jobs . This is not contradictory with the writer ' s stance because the writer regards the event as a deliberate misreading <<< he/she >>> does n't believe . The actual agent of the event should be ( misreading , Obama ) . This example shows that/IN inferences of a triple in the quotation are blocked , or event flipped , based on the writer ' s sentiment toward the agent saying the quotation ."
671	P14_2057	"this is an effective approach , it has a major weakness , i. e. , for each author a large number of his/her articles are needed as the training data . This is possible if the author has written a large number of articles , but will be difficult if <<< he/she >>> has not . For example , in the online review domain , most authors ( reviewers ) only write a few reviews ( documents ) . It was shown that/IN on average each reviewer only has 2.72 reviews in amazon . com , and only 8 % of the reviewers"
672	W17_5051	"g. * &lt;ien&gt; is assigned both &lt;ihn&gt; ( orthographically correct ) and &lt;ihm&gt; ' him ' ( grammatically correct ) . However , decisions about grammatical and orthographic errors are not consistent . For instance , at one point ( er/sie ) * &lt;seht&gt; ( instead of &lt;sieht&gt; ' ( <<< he/she >>> ) sees ' ) is marked as a grammatical error , at another point as an orthographic one . Two German L2 learner corpora are annotated with more than one target hypothesis : Falko ( Reznicek et al. , 2012 ) and EAGLE ( Boyd , 2010 ) . Falko"
673	2020_lrec_1_77	"place , mostly the actual place of the exhibition , sometimes for other ( popular ) cities . For salutations , mostly the request is initiated with a "" "" Hello "" "" , sometimes a "" "" Goodbye "" "" is used . A few visitors also explained why <<< he/she >>> has to leave : "" "" We have to go home now we still want to have a barbecue "" "" 2 . In games , visitors asked to play a specific game or asked for information about game consoles . The topic movie/tv is characterized by request to open"
674	C10_1031	"unless there are contrary words such as "" "" but "" "" and "" "" however "" "" . It would be ambiguous if such consistency is not observed . Following the above observation , we further observe that/IN if the author wants to introduce a new object o , <<< he/she >>> has to state the name of the object explicitly in a sentence s i-1 . The question is what happens to the next sentence s i if we need to resolve the pronouns in s i . We consider several cases : 1 . s i-1 is a normal sentence"
675	W17_6920	"and fame of course ! Each time a player earns points and credits , the creator of the sentence recovers 10 % of the total . Hence , from a strict gaming point of view , players have a definite interest in creating sentences with many interesting ambiguities . When <<< he/she >>> plays , a player can pass over a sentence , if he/she finds it boring or nonsensical . Moreover , when playing , people can like a sentence ( and share it on Facebook and Twitter ) . Having a high number of likes is an incentive for many players"
676	W04_1407	"decided that nothing was coming forth and started talking again . In this case the two sound information pieces would overlay each other , making it very hard to understand who said what . So usually the trainer has to give over the right to speak to another participant and <<< he/she >>> has to give it back when finished ) . This is a very demanding job so the meeting needs to be as well prepared as possible . All applications that will be shown , all documents and presentations that will be loaded to the meeting window have to be present"
677	N09_2010	"order to study how online product reviews are used to make purchasing decisions , we conducted a user study . The study involved 16 pair of graduate students . In each pair there was a customer and an observer . The goal of the customer was to decide which camera <<< he/she >>> would purchase using a camera review blog 1 to inform his/her decision . As the customer read through the reviews , he/she was asked to think aloud and the observer recorded their observations . The website used for this study had two types of reviews : expert and user reviews"
678	I08_1023	"are temporal . So if the proportion of temporal pages of a web site in all its pages is large enough , the web site will be classified as temporal . According to this definition , the type of a web site can be controlled by its administrator . If <<< he/she >>> wants to make the web site temporal , he/she can publish more temporal pages . But how are these pages received by web users ? Even most pages in a web site are temporal , if users pay little attention to them and are attracted mainly by untemporal ones ,"
679	W04_1407	"to show during a meeting does not give a very professional impression as well as costing time and money . All along the session , from the greeting of the participants , the introduction to the technology and throughout the session , the trainer will always have to explain what <<< he/she >>> is doing at the moment . Especially if some of the participants have a slower connection than others , the next screen to be shown should be explained until everybody can see it on their screens . Asking often if there are any questions or if anybody cannot see the"
680	2022_bea_1_28	"for a reader who can appreciate subtle distinctions of style and implicit as well as explicit meaning , including idiomatic expressions and colloquialisms . C1 Appropriate for a reader who can understand in detail complex dialogues , whether or not they relate to their own area of speciality , provided <<< he/she >>> can reread difficult messages . Appropriate for a reader who can understand a wide range of demanding messages , and recognise implicit meaning , including emotional , allusive , and joking usage of language . B2 Appropriate for a reader who can understand the main ideas of complex dialogues across"
681	W13_4027	"commands without assuring their functional integrity . The above described modular approach to NLU aims to support a mixed initiative design where a system ' s integrity and its goals are sufficiently defined ; the user , however , is not restricted by the type and amount of spoken input <<< he/she >>> can use to interact . To offer this type of interaction the system needs to handle three kinds of potential mis-usages : ( 1 ) out-of-application cases , ( 2 ) outof-dialog cases and ( 3 ) out-of-turn cases . To address the first one our training corpus has been"
682	W98_0204	"with narrow context around the link anchor . In spite of their popularity , the arbitrary hyperjumps create a serious drawback by losing the global context . Having lost the global context , the navigator is destined to wander aimlessly in maze of pages , wasting time and forgetting what <<< he/she >>> was looking for in the first place . The use of a static ticker frame that allows an immediate deliverance from this maze ( typically placed on the left part of the browser ' s window ) is a recognition of this drawback . Once NLP methods are applied on"
683	2021_wmt_1_1	"as submission of inconsistent evaluations and even robotic ones . We therefore employ DA ' s quality control mechanism to filter out low quality data , facilitated by the use of DA ' s analogue rating scale . Assessments belonging to a given crowd-source worker who has not demonstrated that/IN <<< he/she >>> can reliably score bad reference translations significantly lower than corresponding genuine system Table 6 shows the number of workers participating in the into-English translation evaluation who met our filtering requirement in WMT21 by showing a significantly lower score for bad reference items compared to corresponding MT outputs , and the"
684	2004_tc_1_13	"translation of the title of our proceedings , written in 2 lines : ASLIB Conference , segmented by Trados as : { 0&gt;ASLIB&lt;0&gt;ASLIB&lt;0 } { 0&gt;Conference&lt;0&gt;Conference&lt;0 } The correct translation into Polish is "" "" Konferencja ASLIB "" "" . If the translator will attempt to keep the segments , <<< he/she >>> must write { 0&gt;ASLIB&lt;0&gt;Konferencja&lt;0 } { 0&gt;Conference&lt;0&gt;ASLIB&lt;0 } It is visible that/IN the word "" "" Conference "" "" in Polish ( Konferencja ) must jump to the first segment . As a result , the TM will include incorrect pairs : ENG : "" "" ASLIB "" "" ="
685	D19_1261	"to search engines , and a naive full-text search IR system will not be able to pick the one that matches the query the best . For instance , if one set up Elasticsearch according to the instructions above and searched for "" "" George W. Bush "" "" , <<< he/she >>> would be surprised to see that/IN the actual page is not even in the top-10 search results , which contains entities such as "" "" George W. Bush Childhood Home "" "" and "" "" Bibliography of George W. Bush "" "" . To this end , we propose to"
686	D19_1667	"input case description does not contain sufficient information for precise prediction . Note we only take the accusation by the procuratorate as input , which is incomplete compared to the whole materials relevant to a case . For example , if a defendant is recidivism within a shorter period , <<< he/she >>> shall be given a heavier punishment . Rare Cases Some special circumstances will influence the prison term , yet rarely happen in the training set . For example , if a defendant cause injuries to others due to excessive defense , he/she shall be given a lighter punishment . This"
687	W11_4610	"evaluated on the basis of texts translated by several translators . In turn , one has to be cautious that/IN translators do not translate texts from the same domain in different situations of translation . Indeed , if a translator translates a text from domain A in situation 1 , <<< he/she >>> must not translate a text from domain A in situation 2 : there is a risk that/IN the translator re-uses some terms'translations he/she has learnt in the previous situation . A critical point when judging the translation of technical texts is that/IN the judges often lack domain expertise and that/IN"
688	W19_8714	"such as Precision and Recall , F measures which are purely statistically based , would be upmost on his/her mind ( Mitkov , 2016 ( Mitkov , , 2017 ) ) . As he/she is in most cases unlikely to be knowledgeable with wide-ranging linguistic issues in both languages , <<< he/she >>> would be using the "" "" Happy Majority Approach "" "" whereby meeting the statistically significant requirements of the majority would be happily acceptable under normal circumstances . The professional translator demands much more just as his/her demands are incrementally met . B. The ideal one-to-one matching of the terms"
689	P11_1051	"are listed in Table 3 . The trained model is then used to classify the references that appear in a sentence into three classes : keep , remove , replace . If a reference is to be replaced , and the paper has one author , we use "" "" <<< he/she >>> "" "" ( we do not know if the author is male or female ) . If the paper has two or more authors , we use "" "" they "" "" . Evaluation We provide three levels of evaluation . First , we evaluate each of the components in"
690	W97_0407	", unlike other corpora such as the Hansards ( Brown et al. , 1990 ) , it is not unrestricted . The general framework established for the Traveler Task aims at covering usual sentences that can be needed in typical scenarios by a traveler visiting a foreign country whose language <<< he/she >>> does not speak . This framework includes a great variety of different translation scenarios , and thus results appropriate for progressive experimentation with increasing level of complexity . In a first phase , the scenario has been limited to some human-tohuman communication situations in the reception of a hotel :"
691	C90_2047	"am using referents of different gender , because I want to show how gender and morphological markings come into play when resolving reference . Notice that/IN these examples would not be ambiguous in English , given that/IN null subject is not an option available to a speaker : the subject <<< he/she >>> would unambiguously pick up its referent . Hej has gotten angry(-masc . ) because h % was sleeping . Various interesting facts come out from the four U3 variations 6 . [ a ] The null subject refers to Maria , who , according to the rules in the previous"
692	J86_2002	"be asking for another summary pattern besides the one the user already knows . Another subtlety that arises is the distinction between implicit and explicit knowledge -the user may know something but not realize it , or may not be able to make the inferences needed to deduce something that/IN <<< he/she >>> has the knowledge to deduce . For example , the user may know the names of all the students who failed CMPT 110 but not realize these are the only students ; or he/she may know everybody who did n't write the final examination and also the rule that/IN if"
693	W12_1608	"in Freebase ( although English resources are dominant ) and a multilingual web speech API is already implemented , e. g. , in the Google Chrome browser , the developer can implement a prototype of other language SDS by dictation . If the developer wants to use domain/task-dependent LMs , <<< he/she >>> must prepare example sentences for the target domain/task in the target language . Conclusions and future research We have proposed a method for rapid development of a spoken dialogue system based on CSRs and have compared the proposed method with the conventional method , which is based on RDB ."
694	W11_3103	"( Isogai et al. , 2009 ) . step 2 extract the question which had the answer extracted in step 1 ( e. g. Q1 in Figure 1 ) . This question is regarded as an original question . step 3 extract the first question submitted by the questioner after <<< he/she >>> received the answer extracted in step 1 . step 4 examine whether the questions extracted in step 1 and step 3 met one of the following conditions : • they shared more than 10 content words when both of them consisted of more than 20 content words , or •"
695	O05_3003	"correct ) , rephrased ( rephrase ) , or repeated ( repeat ) . The listener can give explicit signals through overt utterances to express that he/she is considering/processing the statement made by the speaker ( feedback ) . The listener can produce simple sounds or words to show that <<< he/she >>> understands the message ( feedback_understanding ) or does not understand the message delivered by the speaker ( feedback_non_understanding ) . Or the listener can also give simple signals such as "" "" uh hm "" "" to inform the speaker that/IN the delivered message has been received ( backchannel )"
696	S18_1106	". Situational irony refers to events or situations which fail to meet expectations , such as for instance "" "" warnings the dangerous effect of smoking on the cigarette advertisement "" "" , while verbal irony occurs when the speaker intend to communicate a different meaning w. r. t what <<< he/she >>> is literally saying . Most of the time it involves the intention of communicating an opposite meaning , and this kind of opposition can be expressed by polarity contrast . However this is not the only possibility , and social media messages well reflect such variety , including different expressions"
697	W07_2310	"nonsense . This is unavoidable when the major goal is to afford the user freedom . However , the problem can be alleviated . Spelling mistakes can be prevented by checking all entries against a dictionary -but this can be very frustrating for the user , and a problem when <<< he/she >>> wants to enter new , foreign or subjectspecific words . We believe folksonomies are a better solution here . A folksonomy stores which tags have been used with which frequency . In our system , each datatype property has its own folksonomy , as people would specify different values for"
698	P14_1017	"ACL business meeting who has been tasked with proposing that/IN Paris be the next ACL location . This person cannot on the spot become ACL president , change the shape of his/her social network , wait until the next morning to speak , or campaign for Rome instead ; but <<< he/she >>> can craft the message to be more humorous , more informative , emphasize certain aspects instead of others , and so on . In other words , we investigate whether a different choice of words affects message propagation , controlling for user and topic : would user BarackObama have gotten"
699	L18_1109	"unintentionally used in the wrong form/context , including spelling and grammatical errors . We also include mismatches between American and British English here . When in doubt with the first category , annotators should answer the following question : if the sender were to send the message again , would <<< he/she >>> make the same mistake ? 4 . Split When a word is split into multiple words . There is one case in our corpus where this happens intentionally ( ' l o v e ' →love ) , this is still annotated in this category . Merge There is no"
700	W03_2128	"provide the answer . Consultants typically use this act . Refusal and Missing Information The second problem group are situations where the answerer is not able to give information . Three cases can be differentiated depending on continuation of dialogue : the answerer does not have the needed information , <<< he/she >>> refuses to give it , or he/she cannot give it immediately . If the answerer does not have the information then the questioner must abandon the following attempts . In the case of having information we have two possibilities depending on whether the answerer is the consultant or client ."
701	J89_1001	". First , we do not want the parsing process to be overwhelmed by the appearance of spurious constituents , where a rule that prescribes the introduction of the empty symbol was applied . Of course , the use of empty rewriting rules is attractive to the linguist , because <<< he/she >>> can then give a clear description of the structures . But in parsing we have a problem of the explosion of possible constituents . Second , we want the lexicon to control also the problems and idiosyncrasies involved in limiting the allowed dependencies . To illustrate this point , the"
702	W14_1409	"the probability that agent A assigns with respect to prior judgements J to s being of type T 1 , given that/IN A judges s to be of type T 2 . When an agent A encounters a new situation s and considers whether it is of type T , <<< he/she >>> uses probabilistic reasoning to determine the value of p A , J ( s : T ) . A uses conditional probabilities to calculate this value , where A computes these conditional probabilities with the equation p A , J ( s : T1 | s : T2 ) ="
703	2003_mtsummit_systems_12	"TM . Input guidance and validation is used to limit the amount of free text entered by the user and also to reduce the grammatical complexity of the input . The web interface is structured so that/IN the user needs to provide basic information about the version of the software <<< he/she >>> is using , the operating system used etc , in drop down lists . In addition , style guidelines were developed for solution engineers and system integrators on the user side to avoid complex syntactic and grammatical structures that are difficult for a machine translation system to handle . Optional"
704	W12_4805	"called phloat ( PHrase LOokup Assistant Tool ) . System Overview The proposed system works on a simple editor . Authors can write English sentences , as he/she does on a regular editor . Also , on top of English input , the author can type Romanized Japanese words when <<< he/she >>> does not know what to write in English . The system searches corresponding words in both languages , and displays the information in real-time . For example , Figure 1 in Section 1 shows how the system supports when the user types "" "" okuru "" "" ( which means"
705	2007_sigdial_1_32	"is the most embedded . When a stimulus is presented during the officer ' s first part ( "" "" e "" "" ) 10 % of the time the officer interrupts his/her own first part ( "" "" ee "" "" ) . In 25 % of the cases <<< he/she >>> completes the first part and then introduces the interruption ( "" "" ef "" "" ) . In about 1 % of the cases the officer introduces the interruption during the dispatcher ' s second part ( "" "" eg "" "" ) . Most often , in 51 %"
706	L16_1100	"to inter-sentential coreference . We also consider position and number . For example , different French pronouns will be required when translating subject vs. non-subject position instances of "" "" it "" "" . Translating plural vs. singular "" "" they "" "" ( a gender-neutral alternative to "" "" <<< he/she >>> "" "" in English ) , requires different pronouns again . For addressee reference pronouns , we consider ambiguity caused by both deictic and generic use of the pronoun "" "" you "" "" . For deictic instances , number affects the French translation : "" "" tu "" """
707	P86_1034	"from the prerequisite on the recta-plan , that is , assure mutual understanding . For example , the user will verify that he/she has identified the correct referent for an anaphor in the adviser ' s utterances . 3 . Acknowledgement subdialogues occur when the user informs the adviser that/IN <<< he/she >>> believes that/IN he/she has understood an explanation . They arise from the prerequisite on the recta-plan , that is , assure mutual understanding . A small subset of the graphical representation of a simplified subtask structure and of dialogue segmentation and structure is given in Figure 1 to show how"
708	2004_jeptalnrecital_long_15	"résumés normalisés en trois langues ( anglais , français et espagnol ) à partir d'un texte en anglais . We present an application of oriented multilingual summarization from domain specific texts . These summaries are oriented because the user has to define in a first step the kind of information <<< he/she >>> wants to be present in the final summary . In order to acheive this task , a first step of information extraction is performed . This extracted information which corresponds to the user ' s specification is then the input of a multilingual generator that produces the desired summaries in"
709	W03_2128	", Strandson 2001 ) . Our typology of repairs is similar to questionanswer APs because most of the initiations of repairs are questions in Estonian . We differentiate three types of repair initiations . The first type is the clarification where the hearer repeats the previous information to check whether <<< he/she >>> understood it right or not . Formally , there are questions that offer answer . The second type is the re-formulation where the hearer offers his/her interpretation of previous information . It may have several forms . Questions that are used for repair initiation differ from information questions by their"
710	W05_1622	". The choice of modal verbs in CAN We are currently developing the CAN-system ( Conceptualization for Modal Expressions ) that generates recommendations about courses of study within the B. A. program of the Ruhr-Universität Bochum . A user provides the system with his/her current term number and the lectures <<< he/she >>> has finished so far , and the system generates a recommendation which lectures he should/must/shall/may/can take . A planner provides the partially ordered plan which describes the progression of the overall study from the current semester to the final degree . The propositions are checked in a piecemeal fashion in"
711	E06_3008	"more frequently ) if the demoted subject bears a prominent thematic role , preferably agent . Anaphoric reference by personal pronoun Anaphoric reference is a phenomenon where the animacy of a referent is clearly expressed . The Norwegian personal pronouns distinguish their antecedents along the animacy dimension -animate han/hun ' <<< he/she >>> ' vs. inanimate den/det ' it-MASC/NEUT ' . Anaphoric reference by reflexive pronoun Reflexive pronouns represent another form of anaphoric reference , and , may , in contrast to the personal pronouns locate their antecedent locally , i. e. within the same clause . In the prototypical reflexive construction the"
712	W19_6301	"known words in each keyword list should represent the knowledge of the learner across different genres and domains . The idea behind this is that/IN if the learner knows a lot of frequent words occurring in the domain of , for example , sports , it is very probable that/IN <<< he/she >>> knows another high-frequency word from this domain . However , if the learner does not know a lot of lowfrequency words from the domain , it is not probable that/IN he/she knows another low-frequency word from this domain . To operationalize this idea , we need to use a combined"
713	I08_1023	"pages of a web site in all its pages is large enough , the web site will be classified as temporal . According to this definition , the type of a web site can be controlled by its administrator . If he/she wants to make the web site temporal , <<< he/she >>> can publish more temporal pages . But how are these pages received by web users ? Even most pages in a web site are temporal , if users pay little attention to them and are attracted mainly by untemporal ones , this web site cannot be classified as temporal ."
714	W19_8300	"himself/herself as one of the villagers . The swindle werewolf can have the initiative for misleading villagers , while it is easy to be a target of divination or execution . The stealth werewolf cannot have the initiative , but it is hard to raise a doubt of werewolf since <<< he/she >>> does not work directly on the subject of execution . We attempt to make the stealth werewolf an agent , and would like to clarify important factors for the stealth werewolf . If an agent can talk and mislead villagers without attracting attention from other players , it is a"
715	I11_1167	"not know . TYPE ( Q2-4 ) In resubmitted questions , questioners asked about unknown points in the indication received from answerers . For example , the questioner of ( Q 11 ) received one solution and got the key to solve his/her problem : module deletion . However , <<< he/she >>> did not know it and submitted ( Q 12 ) for requesting detailed information about it . ( Q 11 ) I removed all macros from my excel file . Then TYPE ( Q2-5 ) Questioners resubmitted almost the same questions as they had . They did not mentioned any"
716	W16_1714	"' ) , as well as mostly lexicalized use of deriving nouns referring to occupations ( fizikçi ' physicist ' ) • -lAş deriving verbs from nouns with the meaning of ' become N ' ( özgürleşmek ' to become free ' ) • Copular suffixes ( sizdendi ' ( <<< he/she >>> ) was one of you ' ) Similar to -ki , the first four suffixes form either adjectives or nouns from nouns . In their adjectival use , segmentation is not strictly necessary as the adjectives in Turkish do not inflect . We segmented productive uses of these suffixes regardless"
717	2020_lrec_1_87	"a representative attentive listening response , but besides it there are various types of attentive listening responses such as admiration or evaluation . Figure 1 shows an example of narrative speech and attentive listening responses . Here strings in parentheses show the types of the listener ' s status that/IN <<< he/she >>> is eagerly listening to the speaker ' s utterance greeting acknowledgement of the speaker ' s presence and willingness to favorably interact with the speaker provoke memory listener ' s reaction that/IN his/her memory is provoked by the content of the speaker ' s utterance start thinking listener ' s"
718	W15_3001	"document-level quality Predicting the quality of units larger than sentences can be useful in many scenarios . For example , consider a user searching for information about a product on the web . The user can only find reviews in German but he/she does not speak the language , so <<< he/she >>> uses an MT system to translate the reviews into English . In this case , predictions on the quality of individual sentences in a translated review are not as informative as predictions on the quality of the entire review . With the goal of exploring quality estimation beyond sentence level"
719	X96_1045	"Chair may deem necessary to resolve particular issues . The CCB Chair will conduct the meeting and render the final decision to the course of action to be taken . The above members form the core of the CCB . If a member is unable to attend a meeting , <<< he/she >>> must designate a representative to attend in his/her place . The representative must have full authority to act on behalf of the missing member . Additional individuals are invited to participate , as appropriate , when their technical expertise is required . Engineering Review Board ( ERB ) The ERB"
720	O15_2003	"where "" "" ___ "" "" is recognized as a person name so this replacement is discarded . Rule 2 : Stopword filtering For the one-character replacement , if the replaced ( original ) character is a personal anaphora ( _ ' you ' _ ' I ' _ ' <<< he/she >>> ' ) or numbers from 1 to 10 ( __________ ) , discard the replacement . We assume that/IN a writer seldom misspell such words . Take B1-0122-2 as an example : ... _ _ _ _ _ __ _ _ ... ( I will at two number exit wait"
721	W17_6920	"credits , the creator of the sentence recovers 10 % of the total . Hence , from a strict gaming point of view , players have a definite interest in creating sentences with many interesting ambiguities . When he/she plays , a player can pass over a sentence , if <<< he/she >>> finds it boring or nonsensical . Moreover , when playing , people can like a sentence ( and share it on Facebook and Twitter ) . Having a high number of likes is an incentive for many players . Hence , they trend to produce interesting and funny sentences ."
722	2022_acl_long_186	". One important reason is the lack of multimodal bilingual conversational datasets . Generally , conversation in its natural form is multimodal ( Poria et al. , 2019 ; Liang et al. , 2021b ) . When humans converse , what a speaker would say next depends largely on what <<< he/she >>> sees . That is , the visual information plays a key role in ( i ) supplementing some crucial scene information ( e. g. , the specific locations or objects , or facial expressions ) , ( ii ) resolving ambiguous multi-sense words ( e. g. , bank ) ,"
723	P86_1034	"on the recta-plan , that is , assure mutual understanding . For example , the user will verify that he/she has identified the correct referent for an anaphor in the adviser ' s utterances . 3 . Acknowledgement subdialogues occur when the user informs the adviser that/IN he/she believes that/IN <<< he/she >>> has understood an explanation . They arise from the prerequisite on the recta-plan , that is , assure mutual understanding . A small subset of the graphical representation of a simplified subtask structure and of dialogue segmentation and structure is given in Figure 1 to show how the task structure"
724	2020_coling_main_580	"system to answer several primitive questions and combine them . For instance , to answer the question Why did the founder of Versus die ? , the system must answer two sub-questions sequentially : ( 1 ) Who is the founder of Versus ? and ( 2 ) Why did <<< he/she >>> die ? . Inference questions require that/IN the system understands several logical rules . For instance , to find the grandchild , first , it should find the child . Then , based on the child , continue to find the child . Bridge-comparison questions require both finding the bridge"
725	W19_0505	"the parse , outside of the group of atoms . An example of rules that can be treated by grouping are ( from ( Kuhn , 2007 ) ) : John owns a car . Bill does not own a car . If someone does not own a car then <<< he/she >>> owns a house . Here atoms for "" "" owns a car "" "" and "" "" owns a house "" "" are merged in a single atom ( denoting "" "" owns-a-car "" "" and "" "" owns-a-house "" "" ) and the variables referring to the car and"
726	W16_4018	"includes the following functionalities : • Detailed MI search system with filtering options Adding MIs Users of the PAT Workbench can add ( sets of ) MIs in PDF format to their own corpus via the menu item ' Add ' . A user becomes the owner of MIs that/IN <<< he/she >>> adds from the collection of free MIs in the MI corpus and of the new MIs that/IN he/she uploads to the workbench . When uploading MIs , the user is prompted to select a set of documents . For each document the user needs to specify some metadata about the"
727	2007_sigdial_1_32	"( "" "" ed "" "" ) . In about 11 % of the cases the officer introduces the interruption during the first part of the next adjacency pair when the dispatcher is speaking ( "" "" ea "" "" ) . Finally , in 3 % of the cases <<< he/she >>> interrupts after the dispatcher ' s first part in the next adjacency pair ( "" "" eb "" "" ) . When the stimulus is presented while the dispatcher is speaking the first part ( "" "" a "" "" ) , the officer interrupts immediately in about 23 %"
728	2020_isa_1_2	"general period such as subah ( morning ) . Note that/IN the case markers or karakas associated with the time expression are also considered as a part of the time expression when it provides durativity information . For example : 2 . āja pāca baje vaha āegā Today five o'clock <<< he/she >>> come He/She will come at 5 o'clock today . • DATE : The DATE category is used to annotate calendar days and dates , weekdays and other temporal expressions which consist of multiple days or dates , such as weeks , months or years . Note that/IN spans of time"
729	W03_2109	"attached to the word used as the keyword in a sentence . Figure 4 shows this process . EDR Electronic Dictionary for Semantic Interpreter In the study , we clearly separated domain/task independent parts and dependent parts . When an application developer wants to change a domain or task , <<< he/she >>> modifies or prepares only domain/task dependent parts , such as semantic features , proper nouns , and so on . In this section , we describe the domain/task dependent information obtained from the EDR electronic dictionary , which is used to analyze the utterance in the interpreter . The EDR"
730	L16_1037	"to induce the alignment phenomenon , and to leverage them to enhance the predictability of the learners ' utterance for ASR . The questions are first asked to the robot playing the role of the advanced learner , then the same questions are asked to the human learner so that <<< he/she >>> can learn from the robot learner and answer in a similar way . Table 1 Shows an example of the conversational scenario used in the experiment . R1 : What do you want to take when you go to a mountain ? Table 1 : Example of a conversational scenario"
731	W16_3646	"utterances and the user ' s reaction , and THREE-CONSECUTIVE : one system turn having three consecutive small talk utterances and the user ' s reaction . These dialogues were created by the authors based on the functionality of the implemented interview dialogue system . Each participant is asked which <<< he/she >>> likes the best among the six dialogues for each set . Table 3 shows the result . We found the participants liked THREE best . We also found , however , increasing the number of small talk utterances does not give a better impression to the participants in the trial"
732	W16_1710	"Converse ' s concept of centrality in belief systems . Converse ( 2006 ) defines a belief system as the configuration of idea elements and attitudes that are bound together by some constraint . This constraint helps us in knowing that/IN a person holds a specific attitude given knowledge that/IN <<< he/she >>> holds another one ( Converse , 2006 ) . For example , if we know that/IN an American citizen supports ObamaCare , can we predict that he/she supports gun control ? While there are Americans who support ObamaCare and oppose gun control , the vast majority of people either support"
733	2022_findings_acl_285	"and the other symbol means the predicting sentiment is wrong . when a person tries to understand a relatively long sentence , he/she first read the entire sentence . Subsequently , after giving a specific aspect , he/she will dynamically select related words based on the previous memory state until <<< he/she >>> fully understands the sentiment polarity of the given aspect . Interestingly , the above phenomenon is consistent with our dynamic re-weighting adapter ' s chosen result . Specifically , as Figure 3 ( b ) shows , with the re-weighting function F ( i. e. , Equation 5 and 6"
734	2020_wnut_1_76	"is to develop systems that can automatically extract related events from tweets . The built system should identify different pre-defined slots for each event , in order to answer important questions ( e. g. , Who is tested positive ? What is the age of the person ? Where is <<< he/she >>> ? ) . To tackle these challenges , we propose the Joint Event Multitask Learning ( JOELIN ) model . Through a unified global learning framework , we make use of all the training data across different events to learn and fine-tune the language model . Moreover , we implement"
735	2021_findings_emnlp_352	"to Neutralize ( DEPEN ) . We realize the framework in two steps ( Figure 1 ) . First we automatically detect the parts of the input sentence that reveal the sensitive attribute , and mask them ; while this can be as simple as a gendered pronoun ( ' <<< he/she >>> ' ) , we find many cases where choices of adjectives or phrasing are associated with group identity . Second , we regenerate a complete sentence from the unmasked part of the input so that/IN the output no longer reveals the sensitive attribute . We do this by perturbing the"
736	W94_0313	"of the situation , and especially over the agent of the underlying caused event , labeled the Causee ( see below ) . In other words , a speaker will use this type of construction only ff he/she believes that/IN the Causee is under control of the Causer . If <<< he/she >>> does not believe this is so , a construction that is neutral to this respect ( in the given language ) will be selected . In SFG , the ( social ) status of the participants involved in a situation is traditionally accounted for in the interpersonal metafunction . This"
737	N18_1096	"the following hypothesis : H. 3 . Subordinates use more instances of reported beliefs in their messages than superiors . Non-belief propositions ( NA ) : -the writer expresses some other cognitive attitude toward the proposition , such as desire or intention ( 4a ) , or expressly states that/IN <<< he/she >>> has no belief about the proposition ( e. g. , asking a question ( 4b ) ) . E. g. : ( 4 ) a. I need John to submit the report . b. Will John be capable ? As per the above definition , requests for information ( i."
738	D14_1007	"central controller ( the MDP model ) choose one of the following system actions at each turn : ( 1 ) addressing user ' s query based on a domain expert , ( 2 ) treating it as an out-of-domain request , ( 3 ) asking user to confirm whether <<< he/she >>> wants to continue a domain expert ' s dialogue or to switch to out-of-domain services , and ( 4 ) clarifying user ' s intention between two domains . The Gaussian Process Temporal Difference ( GPTD ) algorithm ( Engel et al. , 2005 ; Gašić et al. , 2013a"
739	2011_mtsummit_papers_28	"the SSC classification task . Combination is superior to both MaxEnt and LogReg , and followed by MaxEnt . We can see the similar rank of the translation results reported in Table 2 . That empirically gives us the evidence that/IN if one wants to achieve better translation performance , <<< he/she >>> needs try and construct a much superior sub-model . In order to explain the effectiveness of our strategy to unify all SSC models into the decoder , we compare the two different methods mentioned in section 4.2 with MaxEnt SSC models . As reported in Table 4 , there is"
740	D18_1145	"  , reflects the extent to which people ascribe the cause or control of events in their lives to themselves or the external factors ( Rotter , 1966 ) . The language indicating internal control in a given situation signals intentionality ( the author is describing an action that/IN <<< he/she >>> intended ) and awareness ( the author is aware of the effect of the action ) . Internal control is often associated with causing a given event or doing something that is clearly a choice . The external control language , on the other hand , is characterized by lack"
741	2020_coling_main_553	"to use and test them comparably . For instance , the following post is detected as ' Extraverted personality ' by both models : You all are going to party at my funeral because mourning is for losers . The way the person writes this post provides the idea that/IN <<< he/she >>> is energized by the outer world ( MBTI ) and has an outgoing and enthusiastic nature ( Big 5 ) . The following post is an example of when two models contradict : Really done with art and has nothing special going on anymore ! This post scores low on"
742	C04_1023	"and each phrase revised at step 3 are recorded as candidates of title for future selection in step 4 . Before next step , the user can return to step 2 to select another OB-P phrase and revise OP-P phrase attached to the OB-P phrase in step 3 again if <<< he/she >>> likes . Select the Title from Title Candidates In step 4 , the user selects one title from the candidates of title composed in the above steps . An Example of the Wizard Window Figure 2 is a screenshot of the Wizard . This screenshot shows the window in step"
743	Y15_1035	"expressions also play an important role in interaction . Japanese sentence-end expressions contain interactional particles ( Maynard , 1997 ) , which express speaker judgment and attitude toward the message and the hearer . For instance , ' ne ' ( a marker of the speaker ' s assumption that/IN <<< he/she >>> has less information than the hearer ; an English counterpart would be "" "" is n't it ? "" "" ) occurs at the end of utterances . In addition , Japanese sentence-end expressions contain auxiliary verbs ( e. g. , ' mitai ' ( like ) and ' souda"
744	C18_1104	"with several objects ; one player ( the Oracle ) is assigned a target object in the image and the other player ( the Questioner ) has to guess it . To do so , the Questioner has to ask Yes/No questions to the Oracle . When the Questioner thinks <<< he/she >>> can guess the object , the list of objects is provided and if the Questioner picks the right one the game is considered successful . No time limit is given , but the Questioner can leave the game incomplete ( viz. not try to guess ) . The set of"
745	W16_3906	a reporter does not mention a post flood in the past . close We can judge from the post that/IN a reporter reports flood in front of him/her . distance far We can judge from the post that/IN a reporter reports flood but he/she is not at the place where <<< he/she >>> experienced flood . misc Except close and far . Table 1 : Labels for the flood disaster events . we focus on the prediction of an event using linguistic features to discuss potential issues in text-based event classification . Vieweg et al. ( 2010 ) analyzed tweets generated during a
746	R13_1065	"and the politeness markers ( F2 with F4 ) . In case of interlanguage ( English ) , when requester used more direct utterance through factor F3 , he/she mitigated this directness with expressive factor F4 ( politeness marker ) . When he/she decided to express him/herself more indirectly , <<< he/she >>> used a combination with politeness marker ( F2 with F4 ) reinforcing the likelihood of request fulfilment , which is confirmed by the last couple of factors . The analysis results for the texts of requests written in Slovak were partially different . The most frequent factors used were :"
747	L18_1438	"Yahoo ! Answers 1 , Stack Overflow 2 or Quora 3 . These web forums allow users to post their own questions , answer others ' questions , comment on others ' replies , and upvote or downvote answers . Usually , if a user is the original questioner , <<< he/she >>> is allowed to select the most relevant answer to his/her question . Although CQA web sites have lots of experts , it still takes their time to give pertinent , authoritative answers to user questions and not all the content shares the same characteristics . Some key differences ( Blooma"
748	2000_amta_workshop_3	"he/she can ask the MT program for help as all the verbs of the list of synonyms are stored in the electronic dictionary . If the learner can guess the meaning of the phrasal verb after he/she has analyzed the translation of the illustrative sentences performed by the program , <<< he/she >>> chooses the synonym deliberately . Then the learner finds a suitable context , fills in the blank and asks the program for translation to make sure that his/ her choice is correct . If the learner has no idea about the meaning of the phrasal verb , he/she has to"
749	2022_acl_long_135	"antistereotypically biased whereas SenseBERT shows a similar in magnitude but a stereotypical bias . Recall that/IN nurse is stereotypically associated with the female gender , whereas other occupations are BERT SenseBERT stereo/anti-stereo sentences stereo anti diff stereo anti diff he/she is a strong nurse -0.45 -0.67 0.22 -15.71 -16.64 0.93 <<< he/she >>> is a professional nurse -0.73 -0.85 0.11 -16.53 16.81 0.27 As a mother/father of five , she/he carefully nurse all of her/his children -0.16 -0.15 -0.01 -18.07 -18.24 0.18 she/he made milk herself/himself to nurse the crying baby -0.77 -0.14 -0.63 -15.85 -17.80 1.96 Table 5 : Pseudo log-likelihood scores"
750	P17_4003	", Benben will recommend a recent news , according to the user profiling information , by a random alternation to the conversation topic transferring to break the stalemate . Note that/IN the news recommendation is also in an interactive way , which means that/IN Benben will ask the user whether <<< he/she >>> wants to read a news of a specific topic in an euphemism way . Response Generation As shown in Figure 2 , the response generation takes the conversation states and the intermediate results as input to generate text or speech responses to users . The filtration , rejection , confirmation"
751	P19_1421	"of path(e ) from the final hidden state of the RNN encoder . Prerequisite Features . The course concepts also have an unique relationship called Prerequisite ( Margolis and Laurence , 1999 ) . Prerequisite concept pair ( A , B ) means if someone wants to study A , <<< he/she >>> is better to understand B in advance ( e. g. , Binary Tree is a prerequisite concept to Black-Red Tree ) , which indicates how concepts in the course are connected . There are a few previous efforts to extract prerequisite relations from Wikipedia ( Talukdar and Cohen , 2012"
752	1991_mtsummit_papers_17	"to make editing and revising activities as convenient as possible . The user can edit the texts in the windows in different flexible ways . He/she can move text fragments around or delete or insert new words using similar services as offered by modern text editors . If necessary , <<< he/she >>> can also tag sentences for later scrutiny . Another important editing function is lexical replace-ment . It is a well known fact that/IN one of the greatest problems in MT is the correct lexical choice . The rules of the MT Machine permit quite elaborate contextual checks in the lexical"
753	D09_1036	"their ads will be any more effective . ( Contrast -wsj 2201 ) In the PDTB , implicit relations are constrained by adjacency : only pairs of adjacent sentences within paragraphs are examined for the existence of implicit relations . When an implicit relation was inferred by an annotator , <<< he/she >>> inserted an implicit connective that/IN best reflects the relation . Example 2 shows an implicit relation , where the annotator inferred a Cause relation and inserted an implicit connective so ( i. e. , the original text does not include so ) . The text in the box ( he"
754	D13_1038	"relationships sometimes are difficult to describe the target object , so the matcher must resort to group information to distinguish the target object from the rest of the objects . For example , suppose the matcher needs to describe the target object 5 in Figure 1 ( b ) , <<< he/she >>> may have to start by indicating the group of three objects at the bottom and then specify the relationship ( i. e. , top ) of the target object within this group . The importance of group descriptions has been shown not only here , but also in previous works"
755	R13_1065	"reverse order . It means that/IN , when a requester used an alerter -a form of addressing , a specific greeting etc. , it is more likely that/IN he/she used an expressive factor , which raised the indirectness of utterance and decreased its possible negative effect . Similarly , if <<< he/she >>> used indirect expression of perspective -F2 then he/she combined it with politeness markers , so the most frequently occurred association rules were those indicating the preference of indirect expression is Slovak language . The results are interesting mainly in terms of differences in the use of politeness factors in English"
756	S19_2204	"semantic and linguistic features , we strip these markers . Query Sentence Extraction Based on the empirical evidence , we could infer that/IN the body of each question posed by the user contains several sentences . However , among all these sentences , only one or two convey the query <<< he/she >>> really wants to ask . Also , the user may post his question in the question subject itself . Thus , we extract these "" "" query-sentences "" "" from the question body and subject and use them to extract linguistic , semantic features . An example of the query-sentence"
757	W17_2314	", the reliable expert is assumed to be perfect , i. e. , he/she always provides correct annotations . However , in practice , such an assumption is too strong , especially for NE annotation . Therefore , we assume that/IN the reliable expert is not perfect , but that/IN <<< he/she >>> has a higher expertise level in the target domain , and has a very low error rate . In order to determine an appropriate annotator for each sentence , we calculate the probability that/IN an annotator will assign the correct sequence of labels in a selected unlabelled sentence . Furthermore"
758	C04_1139	"effect on for instance derived language models . It is important to realize that non-native use is the complex result of different processes and conditions . First of all , there is the level of achievement . A non-native user gradually developes language skills in the target language . As <<< he/she >>> masters certain lexical items or morphosyntactic structures and feels confident in using them , certain items and structures are bound to be overused . At the same time , other items and structures remain underused as the user avoids them since he is not familiar with them or does not"
759	2003_mtsummit_papers_16	") . Properly syntactic are incorrectly used prepositions ( atender ós feridos -'see ' + contraction of preposition and determiner + ' injured'-instead of atender os feridos -'see ' + determiner + ' injured'-'see the injured ' ) , incorrect placing of pronouns ( me dixo instead of díxome ' <<< he/she >>> told me ' ) , use of compound tenses -non existent in normative Galician-(había feito por fixera ' he/she had done ' ) , reflexive verbs -non existent in normative Galician-(sentouse no chan instead of sentou no chan ' he/she sat on the floor ' ) ... Interferences , besides"
760	O04_1013	to the first page may be sufficient . But nowadays many sites have dynamic pages with complex code behind and a plenty of functions . A check to the first page is then no more sufficient ; the manager of the site may have to go through many steps until <<< he/she >>> can be sure that/IN everything operates normally . Manipulations such as login test and search test may be required . The Web site checking example checks two sites at the moment . One is the Taiwan mirror site of IDS ( http : //www . csa . com . tw
761	2020_lrec_1_809	", when a commentator sees something exciting during the gameplay , he/she is required to explain to the listeners why the action was exciting using his/her expressive speech . Furthermore , the commentator should flexibly and instantly decide on the topic to convey because kaleidoscopic changes occur in the gameplay <<< he/she >>> watches , which can even have some interruptions during the recorded commentaries . Because all we need is to prepare various kinds of gameplay and to hire commentators who are very familiar with the game , our methodology can make a collection of spontaneous speech more easily than ever before"
762	D19_1199	"is better at capturing key information and has stronger robustness in difficult scenarios . Variance of Matching Scores . In real multiparty conversations , the utterances without addressee information can be divided into two cases . Sometimes an utterance has an explicit addressee while the speaker does n't specify whom <<< he/she >>> is speaking to . We denote these cases as NP which refers to NULL-Positive . Another case is that/IN the utterances do n't address to any user in the conversation ( denoted as NN which means Null-Negative ) , such as utterances ' Hi , everyone ! ' and '"
763	2021_nlp4convai_1_25	"The Turker carefully reads the description of the assigned task before starting the conversation . 2 . The Turker chats with the dialogue system within 30 turns and tries his/her best to finish the assigned task ; once the Turker has covered all the items and accomplished the tasks , <<< he/she >>> sends a "" "" success "" "" message to the dialogue system to finish the current conversation . 3 . The Turker rates the performance of the dialogue system on the metrics of language understanding , response appropriateness , and satisfaction with the dialogue system . The eligible Turkers should"
764	I13_1042	"#$ ! "" "" )($ * ! "" "" ! +$ ! "" "" ))$ ! "" "" ! &$ ! "" "" ! , $ ! Another interesting observation was on the interruption patterns . We obtained no significant correlation between how powerful a candidate was and how often <<< he/she >>> interrupted others ( IOT ) . Instead , we found statistically significant positive correlation ( although weak ) for OIT , which means that/IN the candidates with more power were interrupted significantly more by others . This is counter-intuitive and in contrast with previous findings by ( Ng et al."
765	W16_1714	", the subject of the copula is o ' he/she ' , while the subject of the verb gör is biz ' we ' . ( 2 ) Biz We . PRON o-nun he/she . PRON-Gen rüya-sı-nda dream . NOUN-P3S-Loc gör-dügü•yüz see . VERB-Past-3Sg•VERB-Cop-1Pl ' We are the ones that/IN <<< he/she >>> saw in his/her dream ' We segment words before productive uses of all of the suffixes listed in this section . However , we do not segment words if they are lexicalised . For example the suffix -siz ' without ' is segmented in arabasız gidemeyiz ' we cannot go"
766	W11_3103	"not know . TYPE ( Q2-4 ) In resubmitted questions , questioners asked about unknown points in the indication received from answerers . For example , the questioner of ( Q 11 ) received one solution and got the key to solve his/her problem : module deletion . However , <<< he/she >>> did not know it and submitted ( Q 12 ) for requesting detailed information about it . ( TYPE ( Q2-5 ) Questioners resubmitted almost the same questions as they had . They did not mentioned any kinds of information received from answerers . For example , in ( Q"
767	2012_amta_wptp_4	"who love its innovative design and dang good usability . The company is well known for its attention getting owner Mr. Steve Jobs , but he died in October of 2011 . Post-Editor E Scenario : Because the post-editor did not own MS Word ( and did not realize that <<< he/she >>> could download Acrobat Reader for free ) , he/she sent the source materials to a friend asking for help . The friend was late returning the postedited translation and did not include the original source text and raw machine translation . The post-editor hurriedly returned the finished post-edited translation on"
768	2022_acl_long_24	". When presented with Speaker 1 ' s loneliness and depression , the following four speakers are willing to provide support , but they come up with different responses due to their different sensibilities . Speaker 2 is relatively unable to appreciate the emotions of Speaker 1 and jokes that/IN <<< he/she >>> can find a virtual friend to hug ; Speaker 3 expresses warmth and Speaker 4 and Speaker 5 comfort Speaker 1 and express their understanding . They also look forward to the future by suggesting that/IN Speaker 1 can do something that helps distract himself/herself . Conclusions and Future Work"
769	2020_challengehml_1_2	"containing at least one mention . Second , we work with the fine-grained annotations gathered for the POM dataset by Garcia et al. ( 2019b ) . This dataset is composed of 1000 videos containing reviews where a single speaker in frontal view makes a critique of a movie that/IN <<< he/she >>> has watched . There are videos from 372 unique speakers , with 600 different movie titles being reviewed . Each video has an average length of about 94 seconds and contains 15.1 sentences on average . The fine-grained annotations we utilize are available for each token indicating if it is"
770	D18_1392	"even when extra-linguistic features are not directly beneficial for prediction , they can still affect people ' s language . Other related works consider how the meaning of language changes depending on who states it . For instance , when an NLP PhD student says the word ' paper ' <<< he/she >>> usually means something different than when a 5 th grade student uses the same word ( i. e. ' research paper ' versus ' piece of paper ' ) . Hu et al. ( 2017 ) noted the same words can have different meanings if different people say them ."
771	R19_1046	"neighborhood people typically visit to label Brazilian users into various social classes . Then , they utilized Foursquare to label places according to the wealth of the neighborhood . They selected users who had at least one Foursquare interaction ( Foursquare interactions include checkin ( the user told a friend <<< he/she >>> was at a given place ) , tips ( the user posts tips and opinion about a given place ) and mayorship ( title given to the most frequent user in a given location in the past 60 days ) . ( Zhong et al. , 2015 ) investigate the"
772	W10_1301	"context , at least for people ( such as parents ) with whom the child regularly interacts . Another possibility is to create a graphical user interface for the conversational partner , perhaps on the same device that/IN the child uses , which the partner could use to indicate what <<< he/she >>> wants to talk about . This is probably technically easier , but does move away from the goal of having as natural a dialogue as possible . Pragmatics of interacting with others Currently , "" "" How was School today … ? "" "" supports storytelling between language-impaired children and"
773	U10_1004	"2002 ) and empirically ( Ishihara , 2009 ) that preference of fillers exists across speakers . Fillers are unique to spoken language . They are a sound or a word ( e. g. um , you know , like ) which is uttered by a speaker to signal that <<< he/she >>> is thinking or hesitating . It is reported that/IN 6 % of the total number of words spoken in Japanese are fillers ( NIJL , retrieved 2008 ) . It is also reported that/IN speakers ' attributes , such as age and gender , affect the choices of fillers in"
774	N18_3003	"intent vector , and e s ∈ R 50 for a vector of slots . User Preferences User-specific signals are designed to capture each user ' s behavioral history or preferences . In particular , we encode whether a user has specific domains enabled in his/her IPDA setting and whether <<< he/she >>> triggered certain domains within 7 , 14 or 30 days in the past . Domain Index From this category , we encode domain popularity and quality as rated by the user population . For example , if the utterance "" "" I need a ride to work "" "" can"
775	J07_2004	"subjects were shown a printed document containing 18 incomplete statements . Subjects were asked to put themselves in the shoes of the author and to choose the description that/IN they found more suitable for each situation : Suppose you and a colleague are currently collaborating on this document . Fortunately <<< he/she >>> did almost all the work for you , and now all that/IN you have to do is complete certain parts of the existing text [ . . . ] Subjects completed the statements by choosing one of two alternatives provided : one "" "" minimally distinguishing "" "" description and"
776	W10_4339	"if the user knows ( or is listed by system ' s recommendations ) that/IN the system can handle determinant m and "" "" 0 "" "" when he/she does not . For example , the state that/IN the determinant m is the potential preference of a user ( but <<< he/she >>> is unaware of that ) is represented by ( k m = 0 , p m = 1 ) . This idea is in contrast to previous research which assumes some fixed goal observable by the user from the beginning of the dialogue ( Schatzmann et al. , 2007 )"
777	W18_4922	"the figure ) to effect the annotation . Currently , ChaKi can consult the dictionary defined in Cradle and conduct efficient annotation of MWEs ( as well as other lexical entries ) as explained above . If the user does not find any definition of an MWE in Cradle , <<< he/she >>> can group the words together to form an MWE group , modify the dependency structure , and output the result . The output format is based on the CoNLL-U format 2 with some additional information for MWE groups and their POS tags . The dictionary manager needs to examine which"
778	Y18_1016	"synthesize a dataset based on the natural question combination patterns . We exhibit improvement in the performance of the DrQA system when it encounters compound questions which suggests that/IN this approach is vital for real-time human-chatbot interaction . "" When a human interacts with an information retrieval chat bot , <<< he/she >>> can ask multiple questions at the same time . Current question answering systems ca n't handle this scenario effectively . In this paper we propose an approach to identify question spans in a given utterance , by posing this as a sequence labeling problem . The model is trained and"
779	W98_0202	", has been done , but most of the research has been limited to generating abstracts or extracting some topics . However , they are immature and still have many problems . No one , yet , has established a way for the user to tell a news reader what <<< he/she >>> requires . Information Retrieval and News Reader There is much on-going research in information retrieval . In document retrieval , the key technology is the utilization of keywords , titles , and user defined "" "" key words "" "" ( Jacobs , 1992 ) . Full text search is"
780	W19_0505	"he/she owns a motorcycle . If someone owns a motorcycle then he/she owns a vehicle . ACERules is unable to relate the group of atoms for "" "" Bill owns a vehicle "" "" and the more general ( because of the use of an indefinite pronoun ) "" "" <<< he/she >>> owns a vehicle "" "" concluding that/IN it is both true and false that/IN John owns a vehicle . More minor issues we found in our study of ACERules are that transformations introduced for indefinite pronouns blur the distinction between inanimate objects and persons 6 and post-processing of condensed atoms"
781	W10_3208	"innovate the concept of a game to automatically label images available in World Wide Web . Highly motivated by the historical research we proposed a intuitive game to create and validate SentiWordNet(s ) for Indian languages by involving internet population . from SentiWordNet ) is displayed to a player and <<< he/she >>> is then been asked to capture his immediate sentiment as extreme positive , positive , extreme negative , negative or neutral by pressing appropriate emoticon buttons . A snap of the game is shown in the Figure 1 . The sentiment score is calculated by the different emoticons based on"
782	R11_1079	"are three types of vowel elision that interact with each other . Object elision marks a noun or pronoun as direct object , such as in ( 3 ) ( as opposed to ( 4 ) ) . ( 3 ) khits whom-ELI uñji see-NFUT 3→3 "" "" Whom does <<< he/she >>> see ? "" "" ( 4 ) khitis who uñji see-NFUT 3→3 "" "" Who does see him/her ? "" "" Noun compound elision occurrs in NPs . The final vowel of noun attributes gets elided if they have three or more syllables , as illustrated in ( 5 )"
783	I05_4005	"based on word frequencies and complexity of grammar . The learner can arrange his/her learning materials in the learner ' s chosen setting . The learning system will give detailed guidelines to explain how to choose the learning materials . If a student wants to learn the Yami language , <<< he/she >>> can choose different learning materials based on his/her interest . The learning materials are designed as theme units with exercises and rubrics for self-assessment . The design of these Yami language exercises is based on a study about the reactions of students to using a web-based system for learning Chinese"
784	W14_2623	"extraction use the concepts of linear and oscillating subjective documents . Consider a situation where a human reader needs to annotate two documents with sentiment . Assume that/IN the first document is linear subjective -with ten sentences , all of them positive . In case of this document , when <<< he/she >>> reads a couple of sentences with the same polarity , he/she begins to assume that/IN the next sentence will have the same sentiment and hence , skips through it . We refer to this behavior as anticipation . Now , let the second document be an oscillating subjective document with"
785	W04_2903	"community . As an example of this , by extending a research speaker identification algorithm [ Reynolds , 1995 ] , we integrated speaker identification into the Audio Hot Spotting prototype to allow a user to retrieve three kinds of information . First , if the user cannot find what <<< he/she >>> is looking for using keyword search but knows who spoke , the user can retrieve content defined by the beginning and ending timestamps associated with the specified speaker ; assuming enough speech exists to build a model for that speaker . Secondly , the system automatically generates speaker participation statistics"
786	P07_1100	"s barrier is ( How can I help you ? ) , or a directive question ( Tell me what is preventing you from exercising more . ) . The motivation behind the open question is that/IN the user gets the initiative and is basically free to talk about anything <<< he/she >>> likes . Naturally , the advantage of directive questions is that/IN the chance of making classification errors is much lower than with open questions because the user will be better able to assess what kind of answer the system expects . Dialogues in which the key-question ( asking the user"
787	W00_1012	"A believes that/IN to attain the goal Gi B has to do D ( 6 ) A believes that/IN B has resources for doing D ( 7 ) A believes that/IN B will decide to do D GOAL : B decides to do D CONTENT : A informs B that/IN <<< he/she >>> wishes B to do D CONSEQUENCES ( i ) B knows the SETTING , GOAL and CONTENT ( 2 ) A knows that/IN B knows the SETTING , GOAL and CONTENT II . Dynamic part Generating procedures ( A ' s possibilities to build his/her turn that contains Proposal as"
788	C18_1234	"the News articles dataset ( 10 authors ) , followed by Reuters ( 50 authors ) and then the lowest for the Blogs dataset ( 100 authors ) . Also , the recall is consistently smaller than the precision because for the semi-closed case an author is announced only if <<< he/she >>> stands significantly apart compared to other authors . We consider feature item set sizes between 500 -3000 , in multiples of 500 , and the average values for precision and recall along with their standard deviations are show in Table 3 . Here , the threshold δ for forming the"
789	2020_wmt_1_1	"as submission of inconsistent evaluations and even robotic ones . We therefore employ DA ' s quality control mechanism to filter out low quality data , facilitated by the use of DA ' s analogue rating scale . Assessments belonging to a given crowdsourced worker who has not demonstrated that/IN <<< he/she >>> can reliably score bad reference translations significantly lower than corresponding genuine system output translations are filtered out . A paired significance test is applied to test if degraded translations are consistently scored lower than their original counterparts and the p-value produced by this test is used as an estimate of"
790	R15_1084	"language in which DBpedia statements are represented . Still DBpedia reflects the multilingual nature of WikiPedia . But if a user needs to access the huge number of instances extracted from the English version of WikiPedia , for example , in a different language ( in our case Bulgarian ) <<< he/she >>> will not be able to do so , because the DBpedia in the other language will not provide appropriate Uniform Resource Identifiers ( URIs ) for many of the instances in the English DBpedia . In this paper we describe an approach to the problem . It generates appropriate names"
791	1999_mtsummit_1_42	"though we set a limit of 5 minutes . Results Evaluation of informativeness There are five multiple choice questions associated with this comprehension text , and a score of 100 % is given when the subject correctly answers all of the five questions , while 0 % is given if <<< he/she >>> answers them all wrongly . In Figure 1 , the Y-axis shows the average score over the test subjects , for the given comprehension test . The level of informativeness for output 1 and output 2 lies below approx. 60 % , while that/IN for output 3 through output 7"
792	P13_3008	"  _ける [ to accept ] "" "" , which does not necessarily have similar meaning with suru . The confusion set means that/IN in the corpus , suru was corrected to either one of these verbs , i. e. , when the learner writes the verb suru , <<< he/she >>> might actually mean to write one of the verbs in the confusion set . For the noun biru""""ビル [ building ] "" "" , the learner may have , for example , misspelled the word bīru "" "" ビ ー ル [ beer ] "" "" , or may have"
793	D11_1146	") , trend detection and tracking ( Hotho et al. , 2006 ) , personalization ( Wetzker et al. , 2010 ) , advertising ( Mirizzi et al. , 2010 ) , etc. Description The task of automatic social tag suggestion is to automatically recommend tags for a user when <<< he/she >>> wants to annotate a resource . Social tag suggestion , as a crucial component for social tagging systems , can help users annotate resources . Moreover , social tag suggestion is usually considered as an equivalent problem to modeling social tagging behaviors , which is playing a more and more"
794	L18_1673	"several pictures that represent the same field ( sea with boats ) . Each subject had to describe the picture to the examiner so that/IN the latter can redraw it just on the basis of the oral explanations . SPO The patient must give his/her opinion on the questionnaire that/IN <<< he/she >>> has to fill out before the recording session . He/she must speak for at least 3 minutes . This task permits to collect spontaneous speech recordings with no constraint on the sentences . MOD Each speaker recorded 10 different scripts uttered with 3 modalities : assertion , question and injunction"
795	W14_0203	"keep walking until you get to Chapel Street "" "" ) , orienting the user ( e. g. "" "" You want the road on your right "" "" , "" "" Please go back in the direction you came from "" "" ) , signaling to the user that/IN <<< he/she >>> was walking in the wrong direction ( e. g. "" "" You ' re going the wrong way "" "" ) , a priori instructions to destination ( e. g. "" "" To get there you will need to keep going up the Royal Mile . Then turn left at"
796	L16_1361	", then , as belonging to both domains ( or being general ) , e. g. środek wyrazu ' means of expression ' or poczucie humoru ' sense of humor ' ( from the comparison of Art-HS and Music corpora ) . In TermoPL , a user may decide what <<< he/she >>> understands for the frequency f i or the size S i of a corpus . The program allows f i to be treated as the total number of occurrences of a term in a corpus , or as its C-value . Similarly , in the equations above , S i"
797	L16_1300	". Regarding the custom rules for pronominal anaphora , a thorough evaluation against an annotated test-set has not been performed . What can be stated based on informal evaluation is that/IN accuracy was fine for the application ' s needs , but given that/IN the rules only consider sentence initial <<< he/she >>> pronouns , coverage may be lacking . In terms of user evaluation , a domain expert as well as two general users have provided comments . They find the application original since the data it outputs ( propositions and their associated keyphrases and entities ) is not available from other"
798	P17_4003	"Fu and Liu , 2013 ) to recognize the intention of users . User intention can be either used as clues for response generation or features for domain selection . For example , if a user says : "" "" I want to go to Beijing . "" "" , <<< he/she >>> may want to book an airplane or train ticket or further reserve a hotel room in Beijing . We also design a scheme to filter out the sentences that contain vulgar , obscene or sensitive words . A classifier is trained to automatically identify these sentences with manually collated lexicons"
799	2022_acl_long_499	"using these cards . In this game , Alice and Bob Alternately take one card . Alice goes first . The game ends when all the cards are taken by the two players , and the score of each player is the sum of the number written on the cards <<< he/she >>> has taken . When both players take the optimal strategy to maximize their scores , find Alice ' s score minus Bob ' s score . Input : _ _ "" "" _ # … _ $ Output : Print Alice ' s score minus Bob ' s score when"
800	N18_1010	"forum 2 on Reddit . In this forum , users ( opinion holders , OHs ) post their views on a wide range of issues and invite other users ( challengers ) to change their expressed viewpoint . If an OH gains a new insight after reading a comment , <<< he/she >>> replies to that comment with a ∆ symbol and specifies the reasons behind his/her view change . DeltaBot monitors the forum and marks comments that received a ∆ , which we will use as labels indicating whether the comment successfully changed the OH ' s view . CMV discussions provide"
801	2021_eacl_main_232	"performance model that only uses the speaker ' s first previous utterance is slightly better than that of the models considers all of them . This evidence is made even stronger by the observation that/IN , in most cases , there is no previous speaker ' s utterance , as <<< he/she >>> responds with a single utterance to a statement or question of an interlocutor . To be precise , only 921 utterances of 3015 are preceded by another utterance by the same subject . So in more than two-thirds of the cases , the target utterance has no context from the"
802	W16_3646	"from a corpus . By this strategy , even if small talk does not go well , the system can go back to the interview and evolve the dialogue . Based on the proposed method , we have developed a Japanese text-based interview dialogue system that asks the user what <<< he/she >>> ate and drank the day before . Figure 1 shows the architecture of the system . Note that/IN the goal of the system is to obtain rough information of what the user had each day . We assume the information is used to know the tendency of the user '"
803	2020_findings_emnlp_347	"performance on new domain improves with the similarity score . This observation suggests that/IN the model is not overfitting to domain specific vocabulary ( e. g. , movie name ) , instead it learns the extent of user ( dis)satisfaction to failures/success of different ( slot ) types of requests <<< he/she >>> makes . Dialogue-level Satisfaction Estimation As shown in Table 5 , on test sets from System A and System A & B combined , Joint attn embeddings f eatures model outperformed the seven other models we experimented with . On test dialogues from System A & B , in comparison"
804	2003_mtsummit_systems_16	"translators . TT2 accomplishes this goal of speeding up and facilitating the work of translators by automatically suggesting translation completions . These suggestions are provided as follows : initially , TT2 suggests a possible translation for a given sentence . If the translator does n't approve this translation proposal , <<< he/she >>> will start typing a new translation , and with each new character the translator enters , the system will provide new suggestions that are compatible with the translator ' s new input . If the system provides the right suggestion , the translator has only to accept it , thereby"
805	P19_1421	"the total deletion times of each expanded concept e i ' s ( denoted as del(e i ) ) . To ensure data quality , we avoid users ' irresponsible deletion by employing a group-vote scoring mechanism . Specifically , when a user deletes the expanded concept e i , <<< he/she >>> gets a score Q = del(e i )/ max e j ∈Ec del(e j )− 1 2 , i. e. , every user operation corresponds to a score 9 S ∈ − 1 2 , 1 2 based on all existing deletion data , which means that/IN irresponsible operations subject"
806	2021_emnlp_main_92	"a given relation , he/she would create a template ( or set of templates ) and check whether the NLI model is able to output a high entailment probability for the template when applied on the guideline example(s ) . He/she could run this process for any new template that/IN <<< he/she >>> could come up with . There was no strict threshold involved for selecting the templates , just the intuition of the developer . The spirit was to come up with simple templates quickly , and not to build numerous complex templates or to optimize entailment probabilities . Pre-Trained NLI models"
807	P01_1064	"k $ ' q¡ sr t 9 bits . 2 This description length is derived as follows : Suppose that/IN there are two people , a sender and a receiver , both of whom know the text to be segmented . Only the sender knows the exact segmentation , and <<< he/she >>> should send a message so that/IN the receiver can segment the text correctly . To this end , it is sufficient for the sender to send u integers , i. e. , v xw zy { v 2| zy z } z } ~ } zy gv E , because"
808	W11_2017	"with an ordinal of 2 , and Easy with an ordinal of 1 . There are 4 scenarios in each of these difficulty categories for both the user and system . To give an example , in Scenario 10 , the user can schedule an appointment on Wednesday afternoon but <<< he/she >>> also has one free session on the previous Tuesday afternoon when the engineer is busy therefore UD = 2 . For the system , in this scenario , the first free session it has is on the Wednesday afternoon therefore SD=1 . In this case , the scenario is easier"
809	P19_3015	"kernel sizes , num kernels , top k max pooling ) . Extension Users can write their own custom modules on all those layers , and self-defined modules can be integrated into the toolkit easily . For example , if a user wants to implement a new classifier model , <<< he/she >>> only needs to implement the part at encoder layer . All the other network structures can be used and controlled through the configuration file . Evaluation In this section , we conduct several experiments to evaluate the performance of NeuralClassifier using datasets from two public benchmarks , namely , RCV1"
810	P07_1047	": The room interior scene for user studies . For easy reference , we give each object an ID . These IDs are hidden from the system users . asks users to describe the room ) and more restricted utterances ( e. g. , the system asks the user whether <<< he/she >>> likes the bed ) that are commonly supported in conversational systems . Seven human subjects participated in our study . User speech inputs were recorded using the Audacity software 1 , with each utterance time-stamped . Eye movements were recorded using an EyeLink II eye tracker sampled at 250Hz ."
811	I08_2099	"karta ' as ' svatantra karta ' which can be translated as ' the participant which is the most independent in a given action ' . In ( 3 ) ' key ' has such a property . When the speaker uses ' key ' in ( 3 ) , <<< he/she >>> intends to elevate the role of ' key ' in the action of opening and does not communicate the actual agent of the action . The speaker uses ' key ' as the independent participant in the act of opening . Hence , ' key ' is the karta ("
812	W96_0408	"toward learning ( English as ) a second language . We envision a system that would be used by a par-Ocular student over an extended period of time . A student would use the system as a tutor , entering texts ( perhaps of several paragraphs in length ) that/IN <<< he/she >>> has written . The system would analyze these texts for errors , engage the student in a corrective tutorial dialogue , and offer possible corrected versions for some of the original input sentences . To accomplish these goals , the proposed system must have several components . First , it"
813	W19_7506	"store IKP output on behalf of logged in users . An IKP service can be registered with multiple Vedavaapi sites to offer its services via specific API endpoints or to manipulate specific document types . When an end-user requests an IKP operation on an Indic document at a site , <<< he/she >>> is presented with a list of registered IKP services available for that operation . For instance , multiple OCR tools can be made available to extract text from a scanned page . A Vedavaapi site consists of a persistent object store , user and team management service , access control"
814	W16_6319	"in common places like railway stations , bus stands , banks , hospitals etc. is very difficult because a hearing person may not understand the sign language used by the hearing impaired person to communicate . Also , a hearing person cannot convey any message to hearing impaired person as <<< he/she >>> may not know the sign language . To make the communication between hearing impaired and hearing community , the language translation is must that may include , Figure 4 : Communication between Hearing and Hearing Impaired Community This is worth mentioning here that/IN Sign languages are not "" "" Natural"
815	W10_1001	"218 words . The lexical simplification module ( not shown in the Figure 1 ) finds 10 candidate words for simplification in this text , and the syntactic simplification module selects 10 sentences to be simplified ( highlighted in gray ) . When the author selects a highlighted sentence , <<< he/she >>> is presented with all possible simplifications proposed by the rule-based system for this sentence . Figure 2 shows the options for the first sentence in Figure 1 . The first two options cover nonfinite clause and adverbial adjuncts , respectively , while the third option covers both phenomena in one"
816	W19_4447	"their focusing on translating the source word poor into one of hard , difficult , and tough as opposed to the source word hard in hard luck . One example translation made by a participant is "" "" The reason why a person ' s life is tough might because <<< he/she >>> was lazy when he/she was young or he/she had a bad luck "" "" . In such cases , the learning effect cannot be correctly evaluated . We seek to find the best example sentences for word sets where the words are confusing for learners . Hence regarding the suggested"
817	S19_2122	"100 tokens then it is considered as targeted offense ( TIN ) . • else if no named entity in the post and no Personal Pronoun and Proper Nouns are present in the post then it is a untargeted offense ( UNT ) . • else if the post has <<< he/she >>> is , you are , he she then it is considered as targeted offense ( TIN ) . • else if the post has pattern ' Starts with hashtag followed by verbs and named entity ' then it is considered as targeted offense ( TIN ) . • else If"
818	W00_1012	"A believes that/IN to attain the goal Gi B has to do D ( 6 ) A believes that/IN B has resources for doing D ( 7 ) A believes that/IN B will decide to do D GOAL : B decides to do D CONTENT : A informs B that/IN <<< he/she >>> wishes B to do D CONSEQUENCES ( i ) B knows the SETTING , GOAL and CONTENT ( 2 ) A knows that/IN B knows the SETTING , GOAL and CONTENT II . Dynamic part Generating procedures ( A ' s possibilities to build his/her turn that contains Proposal as"
819	2012_amta_commercial_1	"Spanish , and English . The lessons describe the background of the project , procedures for registration and performing evaluations , evaluation measures , and how to handle specific evaluation instances or problems . At the end of the training , an evaluator has to take a 15-question quiz before <<< he/she >>> can register with the system . ( 5 ) Evaluation . This is the main module . Once logged in , an evaluator is presented with : ( a ) the MT results from three online MT services of a metadata record ; ( b ) two reference translations for"
820	W13_2705	". DUALIST provides a graphical interface with which an annotator is able to build a Naïve Bayes ' classifier given a collection of unlabelled documents . During the process of building a classifier , the annotator is presented with a selection of documents ( in our case tweets ) that <<< he/she >>> has an opportunity to label ( with one of the class labels ) , and , for each class , a selection of features ( tokens ) that/IN the annotator has an opportunity to mark as being strong features for that class . Active learning is used to select both"
821	W99_0620	"advantage of Ichikawa ( 1990 ) ' s scheme is that/IN it directly associates discourse relations with explicit surface cues ( eg . sentential connectives ) , so it is possible for the coder to determine a discourse relation by figuring a most natural cue that goes with a sentence <<< he/she >>> is working on . Another feature is that/IN , unlike Rhetorical Structure Theory ( Mann and Thompson , 1987 ) , the scheme assumes a discourse relation to be a local one , which is defined strictly over two consecutive sentences . 1 We expected that/IN these features would make"
822	W14_5818	"for money . In order to ensure that/IN the participants are native Chinese speakers and to improve data quality , we use the following measures , ( 1 ) a participant must correctly answer the first two Chinese character identification questions in the section 2s of the questionnaires , and <<< he/she >>> must correctly answer at least one of the last two questions in these section 2s ; ( 2 ) If a participant do not satisfy the above conditions , he/she will not see Section 3s ; ( 3 ) each word stimulus in section 3s has an option which allows"
823	C12_1024	Statements that/IN a group member makes to indicate that/IN he/she shares the same view about something another member has said or done . Challenge Credibility Attempts to discredit or raise doubt about another group member ' s qualifications or abilities . Disagreement Statements a group member makes to indicate that <<< he/she >>> does not share the same view about something another member has said or done . Disrespect Inappropriate statements that/IN a group member makes to insult another member of the group . Establish Credibility Statements that/IN a speaker makes to demonstrate his/her knowledge or personal experience in order to make him/herself
824	2012_amta_wptp_4	". The company is well known for its attention getting owner Mr. Steve Jobs , but he died in October of 2011 . Post-Editor E Scenario : Because the post-editor did not own MS Word ( and did not realize that he/she could download Acrobat Reader for free ) , <<< he/she >>> sent the source materials to a friend asking for help . The friend was late returning the postedited translation and did not include the original source text and raw machine translation . The post-editor hurriedly returned the finished post-edited translation on March 26 , 2012 , but he/she forgot to"
825	P13_1163	"in the City Model , and so on . When the user is mobile , the IM identifies points of interest 2 on the route proximal to the user . We call this "" "" PoI push "" "" . The user is encouraged to ask for more information if <<< he/she >>> is interested . The system also answers adhoc questions from the user ( e. g. "" "" Who is David Hume ? "" "" , "" "" What is the Old College ? "" "" , etc ) ( see section 3.4 ) . Navigation instructions are given in-situ by"
826	2022_acl_long_72	") , and V be its vocabulary . The language model pre-trained with human-generated corpus contains social bias towards certain demographic groups . To mitigate the bias , we have two types of words : target concepts which are the paired tokens related to demographic groups ( e. g. , <<< he/she >>> , man/woman ) , and attribute words which are the stereotype tokens with respect to the target concepts ( e. g. , manager , receptionist ) . We denote the target concepts as a set of m-tuples of words C = { ( c ( 1 ) 1 , c"
827	2020_emnlp_main_330	"in a second language ( Green , 1998 ; Meuter and Allport , 1999 ) . Nonetheless , bilinguals often code-switch , suggesting that/IN inhibition might depend on the context , available resources , and even audience design . For example , when a bilingual is with other bilinguals , <<< he/she >>> might feel more free to code-switch using the most accessible words , knowing that/IN the audience would understand both languages ( Blanco-Elorrieta and Pylkkänen , 2018 ) ; while in monolingual situations , the bilingual would use the appropriate language , inhibiting the alternative one ( e. g. , Blom"
828	2020_acl_main_567	"state generator ( TRADE ) , which can generate dialogue states from utterances using a copy mechanism . This generative model achieved relative good performance , but it still has trouble in extracting relevant information from the original dialogues . For example , a user may tell the agent that/IN <<< he/she >>> needs a taxi in a turn , but the taxi ' s departure location is implicitly mentioned several turns ago . Inspired by the ( Chen et al. , 2017 ; Chen , 2018 ) , ( Chen et al. , 2019 ) studied on utilizing attention mechanism to deal"
829	I08_3009	"have included all the conversions derived from Goonetilleke ' s experiment , we can expect a very high level of user-friendliness . However , if there is any lack of user-friendliness in SriShell Primo , when the user tries to input a Sinhala word by entering the character sequence that/IN <<< he/she >>> thinks most appropriate to represent a specific Sinhala word , he/she will not get that Sinhala word as a candidate in the SriShell Primo menu . At that point the user will have to correct the input character sequence in order to get the correct Sinhala word . As there"
830	L16_1475	", camera , game console . To solve such a problem , Zhang & Pennacchiott ( 2013 ) developed a "" "" cold start "" "" system to predict product categories a Facebook user will buy from , using Facebook profile information , gender , age , and which pages <<< he/she >>> "" "" likes "" "" . Sen et al. ( 2009 ) implemented a content-based movie recommender system capable of "" "" cold start "" "" by using preference tags that/IN customers labeled movies within in a movie review service . In contrast to these works , our goal is"
831	W16_4018	"PAT Workbench can add ( sets of ) MIs in PDF format to their own corpus via the menu item ' Add ' . A user becomes the owner of MIs that/IN he/she adds from the collection of free MIs in the MI corpus and of the new MIs that/IN <<< he/she >>> uploads to the workbench . When uploading MIs , the user is prompted to select a set of documents . For each document the user needs to specify some metadata about the MI it contains ( e. g. , title , description , target audience , background information , source"
832	1999_mtsummit_1_42	", having corrected all the words and noun compounds . On the other hand , in the cases of comprehensiveness and fluency , a significant improvement occurred over the entire enrichment phase . There seems to be a difference between how the test subject feels comprehensive , and how much <<< he/she >>> actually comprehends . This is depicted by the fact that/IN for output 3 through output 5 , the many of the subjects feel that/IN the outputs are incomprehensive and unnatural , but he can obtain considerable amount of information from these outputs . Choice of evaluation method Since evaluation of"
833	2019_jeptalnrecital_tia_6	"representation that/IN the health professionals ( HPs ) have of the disease ( including SLTs ) , may evolve and vary in time and place , depending on each professional ' s career path and on recent scientific progress . In this example , the SLT will retrieve the knowledge <<< he/she >>> has of the possible consequences of stroke , and the way it correlates to speech problems . -Finally , a corresponding term has to be available , in a clear and relevant classification , in order for the HP to find it and decide it is the most suitable term"
834	1999_mtsummit_1_32	"is extending the transfer knowledge . The rule-writer who writes the transfer knowledge translates the sentence before he/she writes the knowledge about it . He/She checks the source language structure , the target language structure , and the translated target sentence . If the source language structure is wrong , <<< he/she >>> checks the current pattern in transfer knowledge . When the selection of transfer knowledge fails , he/she adds an example into the appropriate pattern . Example of adding examples : ( X "" "" as "" "" Y ) =&gt; Y ' "" "" tosite no "" "" X '"
835	W09_3927	". It is interesting to note that/IN Low PISplit R users learn better than both categories of PI users although the differences are not significant . We hypothesize this happens because not all learning issues are signaled by PopUp-Incorrect events : a user might still have low learning even if <<< he/she >>> does not exhibit any PopUp-Incorrect events . Indeed , there are two PI users with a single PopUp-Incorrect event but with very low learning ( NLG of 0.00 and 0.14 respectively ) . It is very likely that/IN other things went wrong for these users rather than the activation of"
836	Y12_1056	"a requester used an att . getter ( a specific greeting etc. ) , it is more likely that/IN he/she used an expressive factor , which raised the indirectness of the utterance and decreased its possible negative effect . Similarly , if he/she used indirect expression of perspective -F2 then <<< he/she >>> combined it with politeness features , so the most frequently observed association rules were those indicating the preference of indirect expression in Slovak . Discussion and Conclusion If we look at the results from the point of view of language used , in Slovak requests formulated by linguists the factors"
837	C88_1011	"those parts of the matlix where a conjtmction stands in the first position of the Markov chain . Let us assume that/IN the , nest frequent labels , -u'e C(K)####### , C02 . . ##### and ' all labels C01 but without C01 . . ##### , the , l <<< he/she >>> could define the cover symbol ' ZCON ' for scope I in the following way : The very low standard deviation of the label A17 ... . . ## casts considerable doubt upou its significance ; it will probably be included into a cover symbol . The label COO####### ,"
838	L16_1060	"user inputs the English word shown in black . When the user presses a key , the typing game begins . The user ' s input is displayed in gray . If the user notices a spelling error Figure 1 : Screenshot of the typing game . while typing , <<< he/she >>> can correct it on the fly by using the backspace key . When the user presses the enter key , the typing game judges whether the user ' s input is correct . If it is not correct , the user ' s input includes the uncorrected spelling error ."
839	2002_eamt_1_1	"document preparation before using the MT affects the quality of translation dramatically . Ideally , pre-editing has to be done by the writer of the text rather than by a translator . The writer knows exactly which anaphora indicates what . A translator may not have technical knowledge , so <<< he/she >>> cannot judge which translation is more appropriate if more than one translated word is found in the dictionary . It is worth noting that/IN postediting is closely related to pre-editing ; the quality of the input affects the quality of the output . Consequently , poor input has detrimental effects"
840	W13_4419	") where "" "" _ _ _ "" "" is recognized as a personal name . We will discard such a replacement . Rule 4 : Stopword filtering If the replaced ( original ) character is a personal anaphora ( _ ' you ' _ ' I ' _ ' <<< he/she >>> ' ) or numbers from 1 to 10 ( _____六____ ) , discard the replacement . We assume that/IN a writer seldom misspell such words . Take Doc#00002 as an example : __ _ _ _ _ Although "" "" _ "" "" is a one-syllable word , it is"
841	E93_1037	"Taro gave him/her a favor of giving a seat , he/she thanked Taro , who was slightly embarrassed . ( 10 ) 01&lt;i&gt; 02&lt;j&gt; seki-wo uzut-te-ageta-node , 01&lt;i&gt; 02&lt;j&gt; orei-wo iwareta . Taro&lt;i&gt; -wa 01&lt;i&gt; chotto terekusak -attn . Because Taro gave him/her a favor o/ giving a seat , <<< he/she >>> thanked Taro , who was slighau embarrassed . 8 , 9 and 10 each constitute a discourse segment headed with Taro . 4 A discourse can be acceptable without any head at all : ( 11 ) 01&lt;i&gt; 02&lt;j&gt; seki wo uzutte ageta node , seat ace give favor because"
842	Y07_1005	"in the D-linked interpretation . The particular derivational step is called SubMove ( Boeckx & Grohmann 2004:11 ) . In line with this reasoning , we assume ( 10 ) for ( 9 ) . ( 9 ) Nwukwu Yenghi-lul manna-ss-ni ? Who Yenghi-Acc meet-Past-Q ' Who is such that/IN <<< he/she >>> met Yenghi ? ' ( 10 ) CP NP i C ' Nwukwu ... . TP ... C ... ... ΦP T ' t i Φ vP T SubMove pro &lt;ΦP&gt; v ' VP v Movement of the bare NP to Spec-C is triggered by the theta-theoretic requirement because the"
843	W10_1113	"end up with a list of the 1,497 codes from ICD-9-CM ordered by their Naïve Bayes score for each letter . The measure that is most interesting here is the recall . The list of suggested codes needs to comprise most of the codes the coder will need so that <<< he/she >>> does not have to go elsewhere to find the appropriate code . Therefore , we kept three measures of recall . It is important to keep the list of codes to be presented to the user short and manageable . Larkey and Croft ( 1995 ) used the same measures"
844	W94_0326	"is completed . Hence , some compromise is required , like : We believe that/IN variants 4 ) and 5 ) are fairly comprehensible and provide some useful information , but not all that is available . However , if the explanation seeking person is interested in further detail , <<< he/she >>> may ask for justifications to text 4 ) , and for elaborations of text 5~ REA~)N I room In the following , we briefly review the contributions to the concepts "" "" effort required to understand a message "" "" and "" "" degree of detail entailed in a message"
845	C12_1178	"words ' confusion sets by filling them in with words that are most similar in their intensions . Our new model describes a two step process when a learner makes word selection choices : by examining the context , he/she will first think about an intension to convey ; then <<< he/she >>> chooses a word that conveys as similar an intension as possible . We will refer to the first step as making intension decisions , and the second step as making word choice decisions . The goal of their learning is to become more comfortable about the word choices in standard"
846	I08_2099	"karta ' as ' svatantra karta ' which can be translated as ' the participant which is the most independent in a given action ' . In ( 3 ) ' key ' has such a property . When the speaker uses ' key ' in ( 3 ) , <<< he/she >>> intends to elevate the role of ' key ' in the action of opening and does not communicate the actual agent of the action . The speaker uses ' key ' as the independent participant in the act of opening . Hence , ' key ' is the karta ("
847	M98_1027	", then both the PAYLOAD and the VEHICLE will be instantiated with Ariane 5 . 2 . Personnel are not considered PAYLOAD if they are deploying , retrieving , or testing payloads , like satellites . So , if a person conducts a space walk while deploying a satellite , <<< he/she >>> is not considered the PAYLOAD . 3 . PAYLOAD_IDENTIFIER Slot DEFINITION : Noun phrase identifying or referring to a payload that is not of type vehicle or person . This slot is not permitted to have more than one value . MINIMUM INSTANTIATION CONDITIONS : Text must provide a string"
848	W14_1409	"the probability that agent A assigns with respect to prior judgements J to s being of type T 1 , given that/IN A judges s to be of type T 2 . When an agent A encounters a new situation s and considers whether it is of type T , <<< he/she >>> uses probabilistic reasoning to determine the value of p A , J ( s : T ) . A uses conditional probabilities to calculate this value , where A computes these conditional probabilities with the equation p A , J ( s : T1 | s : T2 ) ="
849	J89_1001	"the goat and the horns . THE EXPLORATIVE ENVIRONMENT Computer-based environments for the linguist are conceived as sophisticated workbenches , built on AI workstations around a specific parser , where the linguist can try out his/her ideas about a grammar for a certain natural language . In doing so , <<< he/she >>> can take advantage of rich and easy-to-use graphic interfaces that/IN "" "" know "" "" about linguistics . Of course , behind all this lies the idea that/IN cooperation with linguists will provide better results in NLP . To substantiate this assumption it may be recalled that/IN some of the"
850	2021_emnlp_main_617	"for easy reading . The outputs of three recommenders including human , KGSF and NTRD are presented for the comparison . The dialogue starts with greetings between the user ( seeker ) and the recommenders , followed by the recommenders proactively seeking user preference by asking which kind of movie <<< he/she >>> likes . With the focused preference of the user on "" "" comedy "" "" movies , the recommenders provide some candidate movie items with the interesting comments . The responses of KGSF tend to be boring and dull , and it does not switch its recommendation item even though"
851	Y13_1035	"comes from audience ' s judgment , it is with interest to understand this issue from the speakers ' angle , the tweeter . The third question is based on Clift ( 1999 ) who claims that/IN in irony the speaker may or may not be aware of false words <<< he/she >>> uttered , but the speaker is always aware of his/her own sarcastic utterance . The awareness of speaker can be identified by analyzing the contents of the tweets tagged with irony or sarcasm . If a speaker is aware of his/her false words , then the tag should be used"
852	D19_1019	"Figure 1 depicts an exemplar dialogue of online customer service , which has a form of multi-turn dialogue between the customer and the customer service staff ( or "" "" the server "" "" for short ) . In this dialogue , the customer is asking for refunding the freight <<< he/she >>> paid for sending back the product . At the end of service dialogue , the E-commerce platform invites the customer to score the service quality ( e. g. , using 1-5 stars denoting the extent of satisfaction from "" "" very unsatisfied "" "" to "" "" very satisfied """
853	N18_1096	"the following hypothesis : H. 3 . Subordinates use more instances of reported beliefs in their messages than superiors . Non-belief propositions ( NA ) : -the writer expresses some other cognitive attitude toward the proposition , such as desire or intention ( 4a ) , or expressly states that/IN <<< he/she >>> has no belief about the proposition ( e. g. , asking a question ( 4b ) ) . E. g. : ( 4 ) a. I need John to submit the report . b. Will John be capable ? As per the above definition , requests for information ( i."
854	W11_3405	"correct the errors in a focused way . For example , a validator can check and correct all the error in "" "" less fre-quent "" "" category first and then start correcting "" "" ambiguous cases "" "" . It also helps validator to decide the amount of energy <<< he/she >>> needs to spend . For example , correcting "" "" ambiguous cases "" "" would require more time compared to other categories . This could be because the validator might look for sentence or sometimes discourse level information to resolve the ambiguity . He/she could also contact peers or an"
855	W96_0408	"pointed out so that/IN it can be corrected , but tutorial dialogue on appropriate verb morphology is certainly not necessary and would be inappropriate . In contrast , the second writer would be placed at a very different level within SLALOM . In particular , his/her placement would indicate that <<< he/she >>> is still in the process of acquiring verb morphology ; mistakes of the kind given in this sentence are rather common for this writer . As a result , tutorial dialogue explaining appropriate verb morphology is quite appropriate and has a good chance of having a positive effect on the"
856	W14_4104	"active , 40-489 as superstars . Similar partition method is adopted for all the following indicators . ( 2 ) Reply Devotee x Rep , means how many times a person acts as a Participant in a thread posted by other students as shown in Figure 1(b ) . If <<< he/she >>> usually replies to others , then it is possible that/IN his/her question will be paid more attention in return . ( 3 ) Resolved Favor x Res , means in how many threads the person acts as the Starter in threads that get resolved . ( 4 ) Praised Responder"
857	2022_acl_long_132	"classifier used to predict the protected attribute from the representation . This process can then be applied iteratively to debias the representation . Iterative Nullspace Projection ( INLP In our experiments , we create a classification dataset for INLP by finding occurrences of bias attribute words ( e. g. , <<< he/she >>> ) in English Wikipedia . For example , for gender bias , we classify each sentence from English Wikipedia into one of three classes depending upon whether a sentence contains a male word , a female word , or no gendered words . Which Technique is Most Effective in Mitigating"
858	W16_1710	"are bound together by some constraint . This constraint helps us in knowing that/IN a person holds a specific attitude given knowledge that/IN he/she holds another one ( Converse , 2006 ) . For example , if we know that/IN an American citizen supports ObamaCare , can we predict that <<< he/she >>> supports gun control ? While there are Americans who support ObamaCare and oppose gun control , the vast majority of people either support or oppose both issues because the stance toward these two issues is always backed by one ' s ideology or belief system , namely being of a"
859	2021_findings_emnlp_211	"antecedent from the physician to the patient . Future work may address this by trying to refine our lexical-syntactic patterns to also include verb selection information . Other types of errors were less frequent and included cases where two pronouns were used as a single gender-neutral word ( "" "" <<< he/she >>> "" "" ) , and where the pronoun was part of a named entity or reported speech . In addition , we test agreement between two annotators on a subset of 200 randomly selected sentences . We found a high level of agreement ( 95.5 % ; 0.73κ ) ."
860	D13_1122	"paper proposes a simple yet effective distant supervision framework for Chinese open-domain hypernym discovery . Given an entity name , our goal is to discover its hypernyms by leveraging knowledge from multiple sources . Considering the case where a person wants to know the meaning of an unknown entity , <<< he/she >>> may search it in a search engine and then finds out the answer after going through the search results . Furthermore , if he/she finds an entry about the entity in an authentic web site , such as Wikipedia , the information will help him/her under-stand the entity . Also"
861	Y12_1056	"the ways in which culture interrelates with language whenever it is used ( Liddicoat , Papademetre , Scarino and Kohler , 2003 ; Hašková and Malá , 2008 ) . Each interlocutor creates his/her own unique speech acts ( Cohen , 1996 ; Searle , 1979 ) and within them <<< he/she >>> uses the factors of politeness in various combinations and meanings . Since the level of foreign language acquisition is not on intermediate level ( B1 or B2 ) , the speaker ( sender ) usually simplifies his/her utterance in foreign language , applies utterances from his/her mother tongue or sometimes"
862	C10_1143	"; Popescu and Etzioni , 2005 ; Kim and Hovy , 2006 ; Kobayashi et al. , 2007 ; Mei et al. , 2007 ; Stoyanov and Cardie , 2008 ; Jin et al. , 2009 ; Ku et al. , 2009 ) . To reflect the user needs , <<< he/she >>> can manually label a small number of seeds for each feature group . The feature groups are also provided by the user based on his/her application needs . The system then assigns the rest of the feature expressions to suitable groups . To the best of our knowledge , this"
863	W14_4313	"Pickup , Grab , Drop , ClearTop , Stack } Each time , the subject can choose any blocks they think are useful to teach the action . After finishing teaching one action ( either under step-by-step instructions or under one-shot instructions ) , we would survey the subject whether <<< he/she >>> thinks the teaching is completed and the corresponding action is successfully performed by the robot . We record the teaching duration and then re-arrange the table top setting to move to the next action . For the teaching/learning phase , we use two metrics for evaluation : 1 ) Teaching"
864	2020_acl_main_115	"on the different types of annotated information and the standardized format we used to encode those . Gender distinction in pronouns : When the foreign language does not mark gender on pronouns ( or omits pronouns altogether ) , singular pronouns in the English translations are provided consistently as ( <<< he/she >>> ) and ( him/her ) , or ( he/she/it ) and ( his/her/its ) , as in Ex . 1 in Table 2 . During evaluation , instances of this notation are accepted , as well as instances of the individual alternatives . Number marking on pronouns : When the"
865	W12_5809	", younger , teenage , millenial , middle aged , elderly , blind , deaf , paralyzed "" Content Bookmarking and Recommendation Personalized services are increasingly becoming popular in the Internet . This work proposes a way of generating personalized content and simultaneously recommending users , web pages that , <<< he/she >>> might be interested in , based on his/her personalized content . In this work , we portray a system that/IN not only helps the user in bookmarking the URL and snippets from the web page but also recommends web pages relevant to his/her interest . It applies a content-based filtering"
866	E91_1033	"user models when expressing most adequately the expIanation ( represented in Figure 4 ) to the question : "" "" Why is person A in room B and not in room C ? "" "" The user models applied comprise stereotypes for a "" "" local employee "" "" ( <<< he/she >>> is acquainted with all information about the actual office ) , for a "" "" novice "" "" ( who does not know anything ) , and for an "" "" office plan expert "" "" ( who is assumed to know I-Rule 1 ( 1 ) only ) ."
867	2020_lrec_1_736	"hypothesis , the accuracy and realism scores were grouped by type of representation ( Qualisys , Skeleton or Avatar , see Figure 3 ) for participants with a LSF level greater than or equal to good . Each participant rated between 9 and 18 sequences depending on whether or not <<< he/she >>> did the second part ( among the 22 participants with a level greater than or equal to good , 13 responded to the two parts ) . We therefore gathered 105 ( 22 × 3 + 13 × 3 ) realism ratings per representation ( same for accuracy , see"
868	P08_1071	". At the end of the dialog , three dialog level questions are displayed on one webpage . We provide a textbox under each dialog level question for the judge to type in a brief explanation on his/her answer . After the judge completes the three dialog level questions , <<< he/she >>> will be led to a new dialog . This procedure repeats until the judge completes all of the 12 assigned dialogs . Assessment Study 30 college students are recruited as human judges via flyers . Judges are required to be native speakers of American English to make correct judgments on"
869	I08_3015	"be used with pronouns or proper nouns and -khoy cannot be used with nonhuman nouns . Xç -nə meaning ' by the ' is the instrumental case marker . Pronouns The singular personal pronouns are B -əy ' I ' , Xe -nəŋ ' you ' and ]ç -ma ' <<< he/she >>> ' . Possessive pronouns are formed through the suffixation of ×Eõ -ki ' genitive ' on these personal pronouns . Indefinite pronouns are also lexicalized forms that consists of a question word which may be followed by aÇ -su ' also ' or the sequence EÇ õ ¶ ' ö"
870	E12_1021	"overcome the seed information then it still has the freedom to do so . Our seeding approach in combination with the interactive topic modeling ( Hu et al. , 2011 ) will allow a user to both explore a corpus , and also guide the exploration towards the distinctions that/IN <<< he/she >>> finds more interesting . Incorporating Seeds Our approach to allowing a user to guide the topic discovery process is to let him provide seed information at the level of word type . Namely , the user provides sets of seed words that are representative of the corpus . Table 2"
871	I13_1118	"our major contributions is that/IN we mainly focus on the modeling of correlation and difference between news and twitter . 7 It is surprising that tweets that mentioned good looking athletes are collected altogether in this topic . Many tweets collected in this topic on the non-bursty days said that/IN <<< he/she >>> likes a certain athlete . And , those tweets share the terms __ ( athlete ) and _き ( like ) . But , especially on the days when the bursts were observed , much more people posted that/IN the Japanese judoka Matsumoto and the German gymnast Nguyen were so"
872	Y13_1035	"are many frameworks in accounting the mechanism of ironic effects . The review from Clift ( 1999 ) on the Traditional Oppositional Model ( TOM ) has critically pointed out the advantage of TOM locates at its illustration in the divergence between a speaker ' s words , and what <<< he/she >>> might mean by his/her words . However , this two-stage mechanism is criticized for ignoring the fact that/IN two aspects of meaning must be perceived simultaneously to make an utterance as irony . Correspondingly , the Echoic / Interpretation model ( Sperber and Wilson , 1981 , 1986 ) is"
873	W14_2710	", we analyze spoken interactions . Conclusion We studied the topical dynamics in the 2012 US presidential debates and investigated their correlation with the power differences between candidates . We showed that/IN a candidate ' s power , modeled after their poll scores , has significant correlation with how often <<< he/she >>> introduces new topics , attempts to shift topics , and whether they succeed in doing so . In order to ensure the validity of our topic shifts we devised a simple yet effective way to eliminate turns which do not provide substantial topical content to the interaction . Furthermore ,"
874	C96_1079	"that post ( if an article describes a person leaving and a person start ; ing the same job , there will be two IN_AND_OUT templates ) . The IN_AND_OUT template contains references to the tmnt)lates fl)r the PERSON and tbr the ORGANIZATI()N from which the person came ( if <<< he/she >>> is starting a new job ) . The PERSON and ORGANIZATION templates are the "" "" temt)late element "" "" templates , which are invariant across scenarios . "" PALMYRA 2.0 : A Configurable Multilingual Platform Independent Tool for Morphology and Syntax Annotation We present PALMYRA 2.0 , a graphical"
875	W04_1407	"works in full screen mode for application sharing for example , the participants will not be able to see all of the trainer ' s screen . This has to be checked in the first meeting as well , so that/IN the trainer can adjust the window size of what <<< he/she >>> is showing , to the size of what all participants can see on their screens . This can take up to 10 minutes and should be included in the session schedule . On the first meeting a short round of introductions should be held . If available the participants /"
876	P17_4010	"provides an exploration interface ( see Fig. 3 ) , where users can enter an argument triple to specify the entity and relation types they want to explore ( user will be prompted with type candidates ) . Suppose a biologist is interested in finding genes associated with cardiomyopathies , <<< he/she >>> can enter type gene as argument 1 , cardiomyopathies as argument 2 , and GeneDiseaseAssociation as the relation . Life-iNet will then retrieve and visualize a sub-network to show different cardiomyopathies entities ( e. g. , Endocardial Fibroelastoses , Centronuclear Myopathy , Carvajal syndrome ) , and their associated gene"
877	W19_3823	"programmer attribute . Generalizing , we use the following procedure to compute the association between a target and an attribute : We refer to this normalized measure of association as the increased log probability score and the difference between the increased log probability scores for two targets ( e. g. <<< he/she >>> ) as log probability bias score which we use as measure of bias . Although this approach requires one to construct a template sentence , these templates are merely simple sentences containing attribute words of interest , and can be shared across multiple targets and attributes . Further , the"
878	D19_1667	"defendant is recidivism within a shorter period , he/she shall be given a heavier punishment . Rare Cases Some special circumstances will influence the prison term , yet rarely happen in the training set . For example , if a defendant cause injuries to others due to excessive defense , <<< he/she >>> shall be given a lighter punishment . This knowledge is easily understandable by humans , bu hard to be learned by machine learning models . Ethical Discussions Although the research on prison term prediction has considerable potential to improve efficiency and fairness in criminal justice , there are certain ethical"
879	2020_lrec_1_32	". The volunteer are required to review each Question : Answer pair and confirm the correctness of the answers by refering to the text provided . Volunteer ' s decision is shown in the rightmost column in the figure . As the volunteer is provided with text to refer , <<< he/she >>> is not required to have any prior background knowledge about the temple . By using the volunteer inputs as feedback , the classifiers learn to better extract answers of these nine questions from templerelated-text . Curated Corpus : We generated a corpus of 4933 facts on temples from the web"
880	2022_naacl_main_227	"In order to encourage more diverse and high-quality references , we assign each sentence to three random annotators for independent annotation . Their submissions are then aggregated and sent to a random senior annotator ( reviewer ) for review . An annotator may submit multiple references for one sentence if <<< he/she >>> thinks they are all correct according to the guidelines . The job of the senior annotator includes : 1 ) modifying incorrect references into correct ones ( sometimes just rejecting them ) ; 2 ) adding new correct references according to the guidelines . After review , the accepted references"
881	2020_lrec_1_857	"the activities . Based on searches conducted , we created a dataset , K _L MSP_1 , with entries as a tuple per misspelled word containing ( i ) each word itself , ( ii ) the word that/IN the child clicked on-one of the suggestions of the spellchecker that/IN <<< he/she >>> thought of as relevant in each case , ( iii ) the correct spelling , which was collectively agreed upon by facilitators based on notes gathered , ( iv ) the associated session identifier ( i. e. , sessionID ) , ( v ) the spellchecker utilized , and ("
882	W04_3256	"should attain as much information as possible , combine it , and present it in the most concise form to the user . When we look at the different attributes in a person ' s life reported in news articles , a person is described by the job positions that/IN <<< he/she >>> has held , by education institutions that/IN he/she has attended , and etc. Those data are confirmed biographical information and do not bear the necessary contradiction associated with evolving news stories . However , we do feel the need to address and resolve discrepancies if we were to create comprehensive"
883	R15_1090	"also studied . Framework of Our Method In this section , the concrete steps of our relTagVec method are presented and explained . Computing user relevance to the questions For each user u , we can get a list of tags , T u , from the questions to which <<< he/she >>> has recently answered . For each question q , the corresponding tag list can be represented as T q . We use word2vec ( Mikolov et al. , 2013 ) technique to compute the vector representation of all the tags . And then the relevance value relevance(u , q )"
884	S14_2094	"Marton et al. , 2009 ; Razmara et al. , 2013 ) . 1 However the simplest approach to handle untranslated fragments is to increase the size of parallel data . The web is vast and infinite , a human translator would consult the web when encountering a word that/IN <<< he/she >>> cannot translate easily . The most human-like approach to post-editing a foreign untranslated fragment is to do a search on the web or a translation memory and choose the most appropriate translation of the fragment from the search result given the context of the machine translated sentence . Motivation When"
885	2009_tc_1_9	"sj = CostRatio sj + T imeRatio sj where A is the list of attributes and S initial is the initial instances selection . • For each attribute : find the most valuable instances based on the available attributes ratios . The user can specify a list of parameters that/IN <<< he/she >>> want to be considered ( availability , reliability , . . . ) . Otherwise , all available parameters are taken into account . All services with lower sum of ratios are selected : ∀i ∈ S , ∀j ∈ A , CostRatio ij + T imeRatio ij &lt; InitialSum"
886	E85_1020	"to the absence of a clear surface indicator for grammatical function assignment , even though , as a rule , it is the Object NP that is questioned , as in 14 . ii Who did the chief say that/IN he would have engaged ? 21 . i What did <<< he/she >>> say that/IN John would have bought at the market ? ii What did John say that/IN he would have bought at the market ? 22 . i Who did Mario intend to upset ? ii Who intended to upset Mario ? 23 . i Which secretary knew the director ?"
887	I13_1025	"al. ( 2012 ) 13,724 dominance pairs ( pairs of employees such that/IN the first dominates the second in the hierarchy , not necessarily immediately ) . We labeled a participant to have hierarchical power within a thread if there exist a dominance pair in the gold hierarchy such that <<< he/she >>> dominates any other participant in the same thread . For the other three types of power -situational power , power over communication , and influence , we utilize the manual annotations present in the corpus of ( Prabhakaran et al. , 2012a ) . 1 We labeled a participant to"
888	T78_1031	"rule for inheritance in this hierarchy is The other situation we must discuss is "" "" almost transitive "" "" relations such as SIBLING-SIBLING is certainly symmetric , but it cannot be transitive since it is irreflexive . Yet your sibling ' s sibling is your sibling as long as <<< he/she >>> is not yourself . This is what we mean by "" "" almost transitive . "" "" Note that/IN for any relation , The complete syntax will be summarized in the next section Summary We have presented and compared two styles of inference in semantic networks , path-based inference and"
889	W14_1405	"any h : Human , the dependent type Evt(h ) is the type of events conducted by h. Now , we can assume that/IN the verbs start , f inish and last have type where we have simplified the second case by assuming that/IN one would read a book if <<< he/she >>> has not written it . ( One may think of other actions to consider more subcases here . ) Having the above , we can now interpret ( 43 ) as follows ( in a simplified form ) : ( 44 ) start(j , wp ) & f inish(t ,"
890	W11_2303	"to generate natural language sentences , which are converted to speech via a speech synthesizer . At the end of the day , the child uses a menu to select sentences that/IN he or she wants the system to utter , and thereby puts together a narrative that describes what <<< he/she >>> did . The system allows for vastly more rapid output than a system where the child constructs each sentence from scratch . Perhaps the closest work to what we are proposing is the study of non-disabled adults in Cornish and Higginbotham ( No Date ) , where one of the"
891	L18_1080	"the topic . Strictly speaking , spin is not necessarily a form of deception , as the intention is difficult to establish most of the time , e. g. , spin in abstracts may be conditioned by limited space ; by author ' s wish to report the results that/IN <<< he/she >>> perceives to be most important ; by unclear/absent reporting guidelines ; by lack of training etc. However , spin is similar to deception for what concerns its impact and the method required to detect it from textual content only ( Mihalcea et al. 2009 ) . Spin can be considered"
892	Y03_1005	"write a letter . ' b. Tanaka-Si-ga kodomo-tati-nitegami-o yon-de age-ta Tanaka-Mr-NOM child-PL-DAT letter-ACCread-TEgive-PAST ` Mr Tanaka read the letter to the children . According to Kuno ( 1978 ) , these benefactive constructions directly reflect the speaker ' s empathy , which corresponds to the point of view from which <<< he/she >>> conceptualizes the benefactive event . Thus , it is apparent that/IN these constructions are based on the directional operator . The verbs of giving and receiving used as the directional component of the constructions have different argument structures from those of the original full verbs . Most notably , such"
893	H05_1074	"evaluated documents each ( Table 3 ) . The questions include how familiar the user is with the topic before the study ( topic familiar before ) , how the user likes this topic ( topic like ) , and how confident the user is with respect to the answers <<< he/she >>> provided ( topic conf idence ) . We include this information as evidence , because they may be collected when a topic is created and used by filtering systems . Whether collecting them in exit questionnaire affects the answers needs further investigation . News Source Information For each news source"
894	W17_3808	"gender , number and person or not . Secondly , after building the linguistic resources , we moved on to compile them to be used as parameters in the command-line noojapply within NooJ ( Silberztein and Tutin , 2005 ) . When the player listens to the provided dictation , <<< he/she >>> enters his/her response in a text box inside the game . After sending his/her response , Unity3D ( using C# code ) will divide the entered sentence into separate words in a new generated text file ; each of these words would be a NooJ platform entry to be processed"
895	2020_iwclul_1_3	"they do not occur in the written standard . From the perspective of morphological analyzer construction , these forms pose no challenge . Permyak connegatives are formed differently from their Zyrian counterparts , so that Permyak plural connegative is always marked with -ӧ /-ə/ , e. g. оз мунӧ ' <<< he/she >>> does not go ' : озӧ мунӧ ' they do not go ' /oz munə/ : /ozə munə/ . In Zyrian , the plural connegative would be formed as оз мунны /oz munnɨ/ ' they do not go ' , with the connegative form identical to the infinitive of the"
896	J86_2002	"' s intent ( or at least his/her knowledge ) in asking the question ; that is , to consult a user model to see which kind of answer is appropriate . Thus , if it is known that/IN the user is an administrator in charge of registration and that/IN <<< he/she >>> is formulating registration policies , the second answer above might be reasonable . If the user is a clerk in charge of sending out registration forms , the first might be correct . Finally , if the user already knows all the names , then perhaps the summary response is"
897	P19_3015	"kernel sizes , num kernels , top k max pooling ) . Extension Users can write their own custom modules on all those layers , and self-defined modules can be integrated into the toolkit easily . For example , if a user wants to implement a new classifier model , <<< he/she >>> only needs to implement the part at encoder layer . All the other network structures can be used and controlled through the configuration file . Evaluation In this section , we conduct several experiments to evaluate the performance of NeuralClassifier using datasets from two public benchmarks , namely , RCV1"
898	2022_findings_acl_303	"samples are collected from a real-world translation system -Alibaba Translate . 2 We mine user annotated data as follows : Given a user input , the translation system first returns a predicted language label and the associated translation results . When the user is dissatisfied with the prediction result , <<< he/she >>> may change the predicted language label . We argue that/IN this operation not only reflects the user intention concerning the language , but also implies that/IN the classification of the current input is error-prone . Accordingly , we collect texts whose predicted labels are revised by users . The test"
899	2022_gebnlp_1_12	"know that/IN MuST-C training data are manually annotated with speakers ' gender information 27 based on the personal pronouns found in their publicly available personal TED profile . 28 Overall , MuST-C exhibits a gender imbalance , with 70 % vs. 30 % of the speakers referred by means of <<< he/she >>> pronoun , respectively . As reported in its release page , 30 the same annotation process applies to MuST-SHE as well , with the additional check that/IN the indicated ( English ) linguistic gender forms are rendered in the gold standard translations . Hence , information about speakers ' preferred"
900	E89_1004	"( i. e. , always telling the truth , c. f. [ Grice 75 ] ) an assertion uttered by the user implies that/IN the user knows the content of that assertion . BELIEVE : The agent believes , but is not sure , that p is true , or <<< he/she >>> assumes p without sufficient evidence . WANT : The agent wants p to be true . Propositional attitudes are represented in our semantic representation language IRS , which is used by all system components involved in semantic-pragmatic processing . IRS is based on predicate calculus , and contains a rich"
901	W00_1012	"from the wish of a subject to do D. The scheme also illustrates one of the general principles referred to above . It explains the order the steps are taken by the reasoning agent : if a subject is in a state where he/she wishes to do D , then <<< he/she >>> checks first the harmful/useful aspects of D , and after this proceeds to aspects connected with possible punishments . The prerequisite for triggering this reasoning procedure is w(pleas ) &gt; w(unpleas ) , which is based on the following assumption : if a person wishes to do something , then"
902	W19_0505	"or services Bratislava ( and , typically , both ) . This option can be encoded using further auxilliary atoms ( see ( Diller , 2019 ) ) . Turning to ∃-rules with negated atoms in the head , consider the sentence "" "" if someone owns a car then <<< he/she >>> does not own a house "" "" . In our translation we once more replace the head of the ∃-rule obtained from the APE parse with an auxilliary atom : Here the use of the special atom pN ame ( which collects all variables standing for verbs ) is optional"
903	2022_acl_long_425	"target task respectively . Task-Oriented Intent Detection To find out the good timing during social chatting , we focus on detecting whether the user currently has an implicit intent related to the target tasks . In our case , an intent indicates what a user desires to do or what <<< he/she >>> is very likely to do if someone encourages him/her to do so . If our intent detector is able to capture any task-oriented intent in the social content with diverse topics , it tells us the suitable timing for guiding the dialogue to a specific topic and then transition to"
904	J86_2002	"from the cooperative principle in conversation ( Grice 1975:45 ) that requires a speaker to make his/her "" "" conversational contribution "" "" , such as is required , at the stage at which it occurs , by the accepted purpose or direction of the talk exchange in which [ <<< he/she >>> is ] engaged "" "" . There are four maxims that derive from this principle : ( i ) the maxim of quantity -make the contribution as informative as desired but not more so ; ( ii ) the maxim of quality -do not say what is believed to be"
905	W11_2826	"generate natural language sentences in a formal/informal style with different inputs of subject , verb , and complement ( by complement , we mean one or more words including subordinate clauses , as expected in SimpleNLG ) . Therefore , the user might not worry about choosing any word that/IN <<< he/she >>> is not very familiar with , whether the word is formal or informal , because the system will manage to replace some words with more appropriate words , based on the desired style . In addition , our system might interact with the user directly , or it can be"
906	D12_1136	"estimate the typing reduction via a hypothetical typing model 3 in the following manner : Suppose we show top k predictions for a given setting . Now , there are two possible scenarios : 1 . if the user does not find the correct answer in the top-k list , <<< he/she >>> gives up on this word and will have to type the entire word . The typing cost is then estimated to be the number of characters in the word l w ; 2 . if the user spots the correct answer in the list , the cost for choosing the"
907	2021_acl_long_314	consider . He can also give counterarguments or ask questions to illustrate the weakness . Suggestions for improvement : The student suggests improvements as if he were in the peer ' s position in creating the best possible solution . The student completes his suggestions with rich explanations on why <<< he/she >>> would do so and elaborates on the improvements in a very concrete and detailed way . Almost every suggestion is supported by further explanations . = fairly strong The student thinks from the perspective of the peer . She elaborates in a way that serves the peer best to further
908	2021_ecnlp_1_4	"h t of the dialogue history up to the tth turn : h t = GRU ( h t−1 , f t ) ( 1 ) Satisfaction Score Estimator For satisfaction score estimation , our insight is that/IN a the degree of a user ' s dissatisfaction will accumulate if <<< he/she >>> encounters successive improper system response ( where the satisfaction score is negative and decreases over time ) , or can be relieved by a satisfactory reply ( where the satisfaction score increases ) . Therefore , it is natural to predict the increment of user satisfaction score , not only"
909	D12_1043	"a first language . Introduction Whether in a first language ( L1 ) or a second and foreign language ( L2 ) , learning to read has been and remains one of the major concerns of education . When a teacher wants to improve his/her students ' reading skills , <<< he/she >>> uses reading exercises , whether there are guided or independent . For this practice to be efficient , it is necessary that/IN the texts suit the level of students ( O ' Connor et al. , 2002 ) . This condition is sometimes difficult to meet for teachers wishing to"
910	2021_eacl_main_232	"performance model that only uses the speaker ' s first previous utterance is slightly better than that of the models considers all of them . This evidence is made even stronger by the observation that/IN , in most cases , there is no previous speaker ' s utterance , as <<< he/she >>> responds with a single utterance to a statement or question of an interlocutor . To be precise , only 921 utterances of 3015 are preceded by another utterance by the same subject . So in more than two-thirds of the cases , the target utterance has no context from the"
911	L18_1044	"medical documents . To label Person elements , we simply used a static lookup list that consisted of 44 person keywords ( e. g. patients , seniors , children ) . In order to do an annotation in the second prototype , the annotator selects one sentence and afterwards , <<< he/she >>> selects the start and end token of the PICO element by simply clicking on them , i. e. open text input was prohibited in this version ' s interface . Afterwards , a pop-up window opens where the PICO type is selected ( see Figure 3 ) . Finally ,"
912	2022_naacl_main_227	"time-consuming . On the other hand , we did not give enough consideration to this issue when designing the salary computation formula . In the future , we plan to optimize ( or simplify ) our annotation workflow so that/IN each annotator is required to give only one reference which <<< he/she >>> thinks is the best , and assign each sentence to more annotators if we need more references . Human annotation performance . In order to assess the annotation ability of our annotators and human performance for CGEC task , we calculate char-based F 0.5 scores by evaluating all annotation submissions"
913	2020_law_1_7	"influencing the tradeoff between annotation cost and quality is the number of experts required to annotate each listing . The review process can be either a self-review or a peer-review process . In the case of a self-review process , the same expert reviews his/her keyphrase annotation to ensure that <<< he/she >>> has followed the provided guidelines . The self-review also provides a chance for the experts to adjust their annotations based on their interpretations of guidelines so far . For a peer-review , the experts are exposed to the interpretation of the guidelines by the other experts . This exposure may"
914	W03_1402	"( to leave ) - , we do not find any relevant information in our lexical resources as well , although also this verb metaphoric sense occurs once in our corpus : d. Mentre scrivo ci ha appena lasciato . La sua morte … ( While I ' m writing <<< he/she >>> has just left us . His/her death … ) . In fact , these metaphoric uses of arrivare and lasciare , although not frequent in our corpus ( com-Italian wn ILI { cane } posed of texts taken from newspapers , magazines , essays , novels , etc ) ,"
915	W17_5030	"strong eye-mind hypothesis by Just and Carpenter ( 1980 ) , according to which , "" "" there is no appreciable lag between what is fixated and what is processed "" "" ( Just and Carpenter , 1980 ) . That is , when a subject looks at something , <<< he/she >>> also processes it cognitively and the amount of time the subject spends on processing the particular object is equal to the amount of time his/her gaze stays fixated on this object . According to this hypothesis , gaze duration metrics allow measuring the cognitive load imposed on the reader by"
916	W03_2128	"second type of questions ( expecting agreement/refusal ) can be divided into two sub-types : closed yes-no question , and question that/IN offers answer ( e. g. see ´seitseteist kolmkümend on kõige ´ilisem või /is the seventeen thirty the latest/ ) . The questioner has some opinion , hypothesis and <<< he/she >>> is expecting confirmation by the partner . These sub-types can be differentiated on basis of different linguistic realisations in Estonian . There are 237 wh-questions , 123 closed yes-no questions , 73 open yes-no questions , 153 questions that offer answer , 45 alternative questions in our analysed corpus ."
917	2021_ranlp_1_74	"a language in which short vowels are not written . Though possible , usually not even marked in texts , therefore it is required for the reader to have extensive knowledge of the language , otherwise , the reader would not comprehend the message of the letters , even if <<< he/she >>> knows them . For better comprehension let us see an example . In English , a given word , like "" "" wish "" "" is always written and read the same way . It might be understood as a verb , or an identically written noun , so there"
918	W10_4351	"i |DR i−1 , S i−1 ) where the set A contains all the possible system responses and S i−1 is the state of the dialog sequence ( system-turn , user-turn ) at time i. Each user turn supplies the system with information about the task ; that is , <<< he/she >>> asks for a specific concept and/or provides specific values for certain attributes . However , a user turn could also provide other kinds of information , such as task-independent information . This is the case of turns corresponding to Affirmation , Negation and Not-Understood dialog acts . This kind of"
919	W15_3810	"by a physician with specialty training in critical care medicine , "" "" STAT TTE c/w RVS . AKI -no CTA . . . etc "" "" , it is difficult for non-experts to understand all abbreviations without specific context and/or knowledge . But when a doctor reads this , <<< he/she >>> would know that/IN although "" "" STAT "" "" is widely used as the abbreviation of "" "" statistic "" "" , "" "" statistics "" "" and "" "" statistical "" "" in most domains , in hospital emergency rooms , it is often used to represent "" """
920	2020_paclic_1_49	") showed that/IN there is a specific order of infants ' development in the picture book readings and daily lives . For example , they indicated that/IN before an infant learns how to turn pages and return to the proper page when he/she notices that/IN he/she skipped a page , <<< he/she >>> who had not cared about skipping pages experiences preliminary stages such as "" "" prefer picture books showing concrete daily life items and very few stories and sentences "" "" and "" "" prefer picture books having repetitive construction of pictures and sentences . "" "" To discover such types"
921	W17_6920	"To do this , the player has to select the "" "" Créer "" "" menu and key in a sentence . He/she can then select one or more word(s ) in this sentence and declare them as ambiguous . If an ambiguous word does not yet have glosses , <<< he/she >>> adds some to it to establish a list of possible meanings , and indicates what the correct gloss is for the term in the context of his/her sentence . These ambiguous words are those that will be highlighted and that/IN another player will have to disambiguate in a game ."
922	I13_1049	"the grand master . T : Sita grand master ke saath khel rahi hai . ( Sita grand master with play+3+sg+fem+pp ) 2 ) Language models are insufficient to produce the right inflections . Consider the case shown in example 2 , where the translation of the English pronouns ( <<< he/she >>> ) is same in Hindi ( both translate to Woh ) . The inflection on the axillary verb phrase ( raha hai / rahi hai ) is still being decided by the gender of the subject ( he/she ) . Even if a higher order language model is employed ,"
923	2021_emnlp_main_585	"the intermediate nodes become new hypotheses to prove ) , and re-trained a model to generate similar one-deep entailment trees . This model can then be used interactively , generating a one-deep explanation then allowing a user to select which premise(s ) to drill down into , based on what <<< he/she >>> wants to know more about , recursively calling the model to explain that premise further . Although such generative models ( both generating a full tree or a one-deep tree ) can sometimes produce false or nonsensical facts , one could apply fact verification techniques , e. g. , ("
924	R11_1111	"avian influenza pandemic . Amazon With one hand , pull the superoposterior part of the pinna in a superoposterior direction while inserting the earphone with the other . This straightens the ear canal and makes it easier to insert the earphone . ( Your doctor uses the same maneuver when <<< he/she >>> examines you with an otoscope . ) . To validate our term choice , we manually examined the use of frequent terms in posts . For each term , we randomly selected 3-6 posts in each data set . We then classified the posts as relevant or irrelevant to person"
925	W11_4508	"similar meaning , spelling and pronunciationthe so-called cognates -can indeed be used as a tool to understand a second language . However , these similarities have some negative aspects in the learning of Portuguese , such as : ( i ) the learner is prevented from perceiving in which language <<< he/she >>> is communicating ; ( ii ) the pitfall of false friends , since about 20 % of cognates are false [ Henriques 2000 , Santos 1999 ] ; ( iii ) interlanguage fossilization in the beginning of the learning process , as a result of mutual understanding among interlocutors ;"
926	2020_rdsm_1_7	% by using all the features at the training stage . Another study that examines the distinguishing characteristics of Arabic satire is conducted by Al-Ghadhban et al. ( 2017 ) . They study satire as a form of sarcasm in Arabic tweets where the user conveys the opposite of what <<< he/she >>> means . The basic assumption behind the study is that frequency of words would be enough in defining satirical and non-satirical tweets . They train their model on a relatively small number of satirical tweets ( around 340 ) and their model achieves an accuracy of 67.6 % ( Al-Ghadhban
927	W03_2128	"initiations need either confirmation or rejection by the partner who has caused the problem . Thus the pairs of acts are similar to the question-answer pairs . The third type is non-understanding . It can be divided into several sub-types . The partner could not hear the previous turn , <<< he/she >>> finds the information surprising and decides to check it , or he/she did not understand the utterance . There are two linguistic subtypes of this act . The first is open initiation ( formed by some very general words : ah , what ) that do not determine the location"
928	W18_3912	", eSPERTo presents toda a gente as the EP suggestion for the BP phrase todo mundo and the EP suggestion tem a mesma vista for the BP phrase tem vista igual . This adaptation is extremely useful when the user wants to reach an audience that speaks the variety that/IN <<< he/she >>> is less familiar with . The quantity and quality of the resources have been increasing considerably with the integration of tables developed within the lexicon-grammar theoretical and methodological framework ( cf. ( Gross , 1984 ) and ( Gross , 1987 ) ) , based on the transformational operator grammar"
929	2020_ai4hi_1_3	"  an inescapable aspect of image production "" "" ( Chadwick , 2015 , p. 17 ) . In practical terms , this means that/IN a painter in the mainstream is inspired by the work of those who had gone before him/her but the artist is not conscious that/IN <<< he/she >>> is "" "" imitating "" "" another work of art . In contrast , there is the art created outside the boundaries of official culture or "" "" Anti-cultural art "" "" as described by Jean Dubuffet in 1949 . The condition of "" "" non-traditional "" "" or ,"
930	Y00_1011	"obtains the same "" "" and""""-reading as in ( 13 ) and ( 15 ) , though this is the case in which the addressee is a single person . The result of the event is shown in Figure 6 . Of course , for a particular guest "" "" <<< he/she >>> cannot get through the west gate and through the east gate at the same time . However , if the intention of the utterance in ( 16 ) is to offer accessibility from R to P and Q as shown in Figure 3 , then disjunction in ( 16 )"
931	W16_3646	"the user makes an utterance , based on its language understanding result . When there is food or drink in the understanding result , the system needs to know its group so that/IN it can fill the appropriate slot of the frame . For example , when the user says <<< he/she >>> had steak for supper , the system needs to know if it is an okazu ( main or side dish ) so that/IN it can fill the "" "" okazu "" "" slot of the "" "" composition "" "" slot of the "" "" supper "" "" slot ."
932	W06_1629	"each test word , each assessor provided one or more impression keywords in Chinese . We did not restrict the number of impression keywords per test word , which was determined by each assessor . If an assessor provided more than one impression keyword for a single test word , <<< he/she >>> was requested to sort them in order of preference , so that/IN we could investigate the effect of the number of impression keywords on the evaluation results , by changing the number of top keywords used for transliteration purposes . We provided the assessors with the descriptions for the test"
933	2008_tc_1_9	"on editing screenshots might work better in a classroom scenario . What did respondents enjoy most and least about the e-learning ? Exercises , practice , assessment ( quizzes ) and reading came out top when asked what participants enjoyed most about the course . Only one respondent said that/IN <<< he/she >>> enjoyed the online discussions with the other students . When asked what respondents liked least , one respondent mentioned taking part in discussions and one respondent commented that/IN there were not enough quizzes in one unit . Conclusion Creating an e-learning course , even when it can be based on"
934	D12_1043	"It is worth mentioning that/IN Henry ' s formulas have been applied to FFL by Cornaire ( 1988 ) . During the same time , Richaudeau explored a different path , as a representative of the structuro-cognitivist paradigm . He used the number of words recalled by a subject after <<< he/she >>> has just read a sentence as a device to measure understanding and provided an "" "" efficiency formula "" "" of texts ( Richaudeau , 1979 ) . Although more modern in its conception , Richaudeau ' s hard-to-implement formula did not achieve the same recognition in the French speaking"
935	W12_5109	"that/IN the verbs Fr . CÉDER IV.1 lit . ' to give in [ to someone ] ' , OBÉIR 3 lit . ' to obey ' and OBTEMPÉRER lit . ' to comply ' are used as collocates of their complement CHANTAGE I to express ' $2 does what <<< he/she >>> is expected ( by $1 ) to do in respect to $1 ' s blackmail , ' is modeled by the following lexical function application , where Real 2 is the syntagmatic lexical function that/IN returns "" "" verbs of realization "" "" that take the second actant of a"
936	W00_1012	"from the wish of a subject to do D. The scheme also illustrates one of the general principles referred to above . It explains the order the steps are taken by the reasoning agent : if a subject is in a state where he/she wishes to do D , then <<< he/she >>> checks first the harmful/useful aspects of D , and after this proceeds to aspects connected with possible punishments . The prerequisite for triggering this reasoning procedure is w(pleas ) &gt; w(unpleas ) , which is based on the following assumption : if a person wishes to do something , then"
937	W08_1407	"example of an image and Table 2 contains the corresponding related information . Each participant was asked to familiarize himor herself with the location of the image by analyzing the map and going through all 11 URLs . Then each participant decided on up to 5 different pieces of information <<< he/she >>> would like to know if he/she sees the image or information about something he/she relates with the image . The information we collected in this way is similar to ' information nuggets ' ( Voorhees , 2003 ) . Information nuggets are facts which help us assess automatic summaries by"
938	W14_5818	"participant must correctly answer the first two Chinese character identification questions in the section 2s of the questionnaires , and he/she must correctly answer at least one of the last two questions in these section 2s ; ( 2 ) If a participant do not satisfy the above conditions , <<< he/she >>> will not see Section 3s ; ( 3 ) each word stimulus in section 3s has an option which allows the participants to skip it in case he/she does not recognize that word ; ( 4 ) all the questions in the questionnaires must be answered except the ones which"
939	W08_0119	"asked to solve the task via a dialogue with the system . The tasks set could either have one solution , several solutions , or no solution at all in the database . In cases where a subject found that/IN there was no matching venue for the given task , <<< he/she >>> was allowed to try and find an alternative venue by relaxing one or more of the constraints . In addition , subjects had to perform each task at one of three possible noise levels . These levels correspond to signal/noise ratios ( SNRs ) of 35.3 dB ( low noise"
940	Y15_2001	"proposes a method to automatically judge whether the user displays the sympathy in his/her utterance as a fundamental technique in a non task oriented dialog system . In this paper , we define ' sympathetic utterance ' as the utterance where the speaker expresses the sympathy or approval especially when <<< he/she >>> replies to subjective utterance of the other participant . Note that/IN the utterance just showing agreement is not defined as sympathetic . Various kinds of clues could be applicable for identification of the sympathy , such as facial expressions , gesture or the contents of the utterance . Since we"
941	2021_acl_long_314	"improvement : The student suggests one or more improvements that are relevant for the further establishment of the activity and idea from the perspective of the peer . Most suggestions are written concretely and , if applicable , supported by examples . In most cases , the student explains why <<< he/she >>> suggests a change . 3 = slightly weak / equal The student tries to understand the perspective of the peer and adds further elaborations to her statements . However , her elaborations are not completely thought through and her feedback is missing some essential explanations , examples , or questions"
942	W98_0202	"news . Recently developed news readers classify news items using their subjects , however , since the subject often differs from the contents of the article , many unnecessary articles are extracted by such a simple screening method . A keyword method can be useful when one knows what information <<< he/she >>> wants , or when one precisely knows the hierarchy of keywords , e. g. , a thesaurus . When one is in the process of forming a new concept from his/her basic concept , it is not possible to chose a suitable keyword . The human conception process begins from"
943	2003_tc_1_13	"guidance and validation is used to limit the amount of free text offered to the user and also to reduce the grammatical complexity of the input . The web interface is structured in such a way that/IN the user needs to provide basic information about the version of the software <<< he/she >>> is using , the operating system used etc in drop down lists in order to limit the free text input to the relevant text . In addition , style guidelines were developed for solution engineers and system integrators on the user side to avoid complex syntactic and grammatical structures that"
944	W19_8714	"major stages in the translator ' s workflow , in which distinct technical efforts could enhance productivity ( Zaretskaya et al. , 2015 ) . From the Perspective of Translators The translator ' s workflow consists of four major stages . When working with a technical document , even if <<< he/she >>> has excellent command of the languages concerned , it is inevitable that/IN there will be unfamiliar terms outside his/her active vocabulary . A. To cope with these challenges , appropriate lexical resources and other reference materials have to be consulted . D. For self-improvement , the conscientious translator or the"
945	2020_acl_main_567	"model by analyzing the state tracking errors . We noticed two types of errors . First , SAS can not effectively identify value "" "" dontcare "" "" for most slots . For example , when the agent asks the user about his/her requirement on the hotel rating , though <<< he/she >>> answers "" "" that is not really important for me "" "" , the model fails to fill "" "" dontcare "" "" into the slot "" "" hotelstar "" "" . We believe this is due to the fact that/IN the meaning of "" "" dontcare "" "" has"
946	2020_cllrd_1_6	"BG = a ) = 15/194 ≈ 0.07 , and P(RU = я | BG = a ) = 4/194 ≈ 0.02 . In such a case , we can expect a Russian reader to have more difficulties to correctly guess which characters in RU correspond to the BG one <<< he/she >>> is confronted with . As in the case with the LD , we normalized the WAS and calculated the average value of the normalized WAS ( nWAS ) for 190 cognate pairs of the Common Slavic vocabulary ( Carlton , 1991 ) . The nWAS matrix ( Table 3 )"
947	2021_nlp4convai_1_25	"task performance ; the highest correlation was determined between the IOS score and the satisfaction with the dialogue system , reaching .16 ( significance level p &lt; .05 ) . Table 4 shows that : ( 1 ) the higher a person ' s final education level , the lower <<< he/she >>> rates the response appropriateness of the dialogue system ; ( 2 ) the more frequently a person uses the dialogue system , the less likely he/he is to succeed in the task ; ( 3 ) extroverted and sociable people tend to fail the task ; and ( 4 )"
948	W19_6301	"of frequent words occurring in the domain of , for example , sports , it is very probable that/IN he/she knows another high-frequency word from this domain . However , if the learner does not know a lot of lowfrequency words from the domain , it is not probable that/IN <<< he/she >>> knows another low-frequency word from this domain . To operationalize this idea , we need to use a combined measure which would not only reflect the amount of known words but also the frequencies of the known words in a particular domain . The calculation of the learner-specific features is"
949	W16_3646	"base . If the food is not in the food and drink list , the system estimates its food group and requests confirmation from the user as will be explained in Section 4.4 . Slot values can be a set of food and drink . So if the user says <<< he/she >>> had a steak and a salad , the okazu slot value is the set of "" "" steak "" "" and "" "" salad "" "" . The system-utterance selection is done with manually written rules . The system asks what the user ate and drank in order . This"
950	2021_acl_long_314	"They could be relevant for the peer . However , the statements do not include any further elaboration on the mentioned weakness . Suggestions for improvement : The student suggests one or more improvements that could be relevant for the peer . However , the student does not explain why <<< he/she >>> suggests the change or how the suggestions for improvement could be implemented . = absolutely weak The student ' s feedback is very short and does not include the peer ' s perspective . She does not add any further elaboration in her thoughts . Strengths : The student only"
951	P08_2004	"the popularity of a movie such as movie ratings and box office performance . In applications requiring certain level of language-understanding , things can get even more complicated while different dimensions weave together . As in sentence ( 5 ) , the speaker may bias towards the blue team while <<< he/she >>> shows uncertainty towards the red team . Correctly understanding this kind of subjective statements would probably need some investigation in different dimensions of subjectivity . Conclusion In this paper , we demonstrated that subjectivity in natural language is a complex phenomenon that contains multiple dimensions including non-objectivity , uncertainty ,"
952	W06_0303	"over the topic , which gave 95.6 % . Overall , our method performs the binary classification for points at issue with a high accuracy . Errors were mainly due to opinions that included arguments for both standpoints . For example , a person supporting a standpoint might suggest that <<< he/she >>> would support the other side under a specific condition . Points at issue classified incorrectly had usually been extracted from such contradictory opinions . Evaluation of Ranking Opinions To evaluate the effectiveness of our method in ranking opinions on a point-by-point basis , we used a method that sorts the"
953	W14_3104	"tedious . More importantly , it cannot handle polysemes . For example , the word "" "" pound "" "" can refer to either a currency or a unit of mass . If a user adds a must-link between "" "" pound "" "" and another financial term , then <<< he/she >>> cannot add a must-link between "" "" pound "" "" and any measurement terms . Since word must-links are added without context , there is no way to disambiguate them . As a result , word constraints frequently are not as effective as document constraints . Active learning ( Settles"
954	2021_ranlp_1_61	"each node as the feature . • Polarity of node pair Emotional information is also one of the characteristics of conversations . For example , a speaker may emotionally argue while claiming his/her opinion in a discussion . In a similar way , when a speaker may emotionally argue when <<< he/she >>> agrees or disagrees with another speaker ' s question . To capture the information , we use Stanford CoreNLP ( Manning et al. , 2014 ) . We compute the score ( 1 to 5 ) of each utterance by using CoreNLP . Then we compute the average score from"
955	C12_1049	"token ) Description British National Corpus ( BNC ) ( The BNC Consortium , 2007 ) British 100 mil . General corpus This dataset was designed to be quite exhaustive . Every learner was handed a randomly sorted questionnaire comprising 12 , 000 words and asked to answer how well <<< he/she >>> knew the words in the questionnaire based on a five-point scale . We regarded level 5 as only y = 1 ; the learner knows the word . Otherwise we regarded y = 0 ; the learner does not know the word . Out of the 12 , 000 words"
956	2020_acl_main_619	"  une bonne enseignante "" "" for , respectively , a male or female referent . In spoken language data , the human entity that determines gender agreement is either the speaker him/herself ( I am a good teacher ) or another person the speaker is referring to ( <<< he/she >>> is a good teacher ) . We classify our phenomena of interest in two categories based on where the necessary information to disambiguate gender can be recovered , namely ( Category 1 ) from the audio signal , when gender-agreement only depends on the speaker ' s gender , which"
957	W14_4310	"interface since speech commands are less subject to the physical constraints imposed by devices . On the other hand , if the system accepts only a limited expression , the user need to learn how to use the system . If the user is not familiar with the system , <<< he/she >>> cannot even make an input utterance . Not all users are motivated to converse with the system in actual environments , and sometimes a user will abandon the dialog without making any input utterance . When the user has difficulty to make the utterance , conventional systems just repeat the"
958	2000_amta_workshop_3	"program , he/she chooses the synonym deliberately . Then the learner finds a suitable context , fills in the blank and asks the program for translation to make sure that his/ her choice is correct . If the learner has no idea about the meaning of the phrasal verb , <<< he/she >>> has to use the trail-and-error method to make his/her choice . The third stage is meant to help the learner to keep in mind the new information he/she has obtained at the lesson . After the learner has chosen the synonyms to all the phrasal verbs , he/she is supposed"
959	E93_1037	"some difficulty in accounting for the wa-nominal having semantic control over a set of period-marked sentences . cf. [ Mikami , 1960 ] . Ours , however , is free from the problem , as we see below . Because Taro gave him/her a favor of giving a seat , <<< he/she >>> thanked Taro , who was slightly em . barrassed . ( 9 ) 01&lt;i&gt; 02&lt;j&gt; seki-wo uzutte-ageta-node , Taro&lt;i&gt; -wa 01&lt;i&gt; 02&lt;j&gt; orei-wo iwareta . 01&lt;i&gt; chotto terekusak -atta . Because Taro gave him/her a favor of giving a seat , he/she thanked Taro , who was slightly embarrassed ."
960	D19_1197	"2 ) Relevance : if the response is relevant to the given message ; and ( 3 ) Richness : if the response contains informative and interesting content , and thus may keep conversation going . For each aspect , if the annotator cannot tell which response is better , <<< he/she >>> is asked to label a "" "" tie "" "" . Each pair of responses receive 3 labels on each of the three aspects , and agreements among the annotators are measured by Fleiss ' kappa ( Fleiss and Cohen , 1973 ) . Baselines We compare our model with"
961	W11_2301	", a training exercise is composed of several semantic stimuli items . The stimuli may be of several different types : text , audio , image and video . Like in ordinary speech therapy sessions , the patient is asked to respond to the stimuli verbally , describing the imaging <<< he/she >>> sees or completing a popular saying ( which was presented verbally or in text ) . Exercise categories The set of therapeutic exercises integrated in Vithea has been designed by the Language Research Laboratory of the Department of Clinical Neuroscience of the Lisbon Faculty of Medicine ( LEL ) ."
962	W08_1407	"2 contains the corresponding related information . Each participant was asked to familiarize himor herself with the location of the image by analyzing the map and going through all 11 URLs . Then each participant decided on up to 5 different pieces of information he/she would like to know if <<< he/she >>> sees the image or information about something he/she relates with the image . The information we collected in this way is similar to ' information nuggets ' ( Voorhees , 2003 ) . Information nuggets are facts which help us assess automatic summaries by checking whether the summary contains the"
963	P06_3006	"to collect the corpus , ( Haas , 1995 ) created a simulated office building modeled after the actual computer science department at SUNY/Albany . This environment was set up like a popular first person shooter game such as Doom , and the subject saw a demonstration of the route <<< he/she >>> was asked to describe . The subject wrote directions and sent them to the experimenter , who sat at another computer in the next room . The experimenter tried to follow the directions ; if he reaches the right destination , the subject got $1 . This process took place"
964	D13_1122	"discover its hypernyms by leveraging knowledge from multiple sources . Considering the case where a person wants to know the meaning of an unknown entity , he/she may search it in a search engine and then finds out the answer after going through the search results . Furthermore , if <<< he/she >>> finds an entry about the entity in an authentic web site , such as Wikipedia , the information will help him/her under-stand the entity . Also , the morphology of the entity name can provide supplementary information . In this paper , we imitate the process . The evidences from"
965	2021_conll_1_10	"workers to have at least 100 approved assignments , and the approval rate is at least 95 % . To avoid having the same worker working on too many HITs , we ran a custom script at the backend that constantly checked the worker statistics and blocked the worker if <<< he/she >>> had already finished 50 HITs . Figure 6 is a screenshot of the welcome page of our human evaluation experiment on the crowdsourcing platform . Figure 7a shows the instructions and explains to the worker how the tasks work , where the worker can also try an example task by"
966	E17_2116	"understand if the learned user embeddings reflect actual email correspondence , we study the relation between the similarity of users ' embeddings and the frequency they communicate . Specifically , for each target user u i , we first identify all others { u j | j =i } that/IN <<< he/she >>> has had communications with , and then bucket the cosine similarity between their embeddings into intervals . For each interval , we take the average of the numbers of times each u j communicates with u i and convert it into logarithm space . Figure 2 shows that/IN in general"
967	Y01_1015	", when it is produced with a professional and fluent intonation . However , it is not the intention of interlocutors in conversation to impress each other in this way . In contrast , the speaker would rather let the addressee know that/IN he/she made a mistake previously and what <<< he/she >>> is now saying is correct . Thus , it is very likely that/IN discourse particles and speech disfluency are highlighted by prosodic means to emphasise the semantic and syntactic inadequacy . This paper mainly deals with means emphasising particular speech sequences and four possibilities of observing these activities are 1"
968	W10_4339	"order to represent a state that/IN the user has potential preference , we introduce a knowledge parameter K user = ( k 1 , k 2 , . . . , k M ) that shows if the user has the perception that/IN the system is able to handle or <<< he/she >>> is interested in the determinants . k m is set to "" "" 1 "" "" if the user knows ( or is listed by system ' s recommendations ) that/IN the system can handle determinant m and "" "" 0 "" "" when he/she does not . For example"
969	U17_1007	"2000 ) are used for FVC experiments . The recordings are 10-25 minutes long . For this study , it was decided to target fillers . Fillers are sounds or words ( e. g. um , you know , like in English ) uttered by a speaker to signal that <<< he/she >>> is thinking or hesitating . The filler /e : / and the /e : / segment of the filler /e : to : / were chosen because i ) they are two of the most frequently used fillers in Japanese ( many monologues contain at least ten of them )"
970	O04_1013	"By choosing to only use common Web technologies , a problem arises : the user interface of Web services usually changes with the time . For example , many sites have advertisements that/IN by their nature change frequently . For the human user it is not a big problem because <<< he/she >>> can understand their meaning and skip them . But it is difficult for a computer to really "" "" understand "" "" the interface of a Web service . Intelligent solutions are hard to be designed for general purpose . WIDL instead provides a language to describe the position of"
971	W10_4335	"the chances of tagging wrong positions or failing in tagging back-channel feedbacks , realizing coherent tagging . • Discretization of tagging points : Tagging is performed for each segment into which driver ' s utterances are divided . In a normal dialogue , the listener can provide backchannel feedbacks whenever <<< he/she >>> wants to , but the inconsistency in the timings to give such feedbacks becomes larger in exchange • Elaboration using synthesized sound : An annotator checks the validity of the annotation by listening to the sounds . In other words , an annotator elaborates the annotation by revising it many"
972	2020_paclic_1_52	"displaying the details for "" "" renwei "" "" and "" "" yiwei "" "" . Based on "" "" Common Patterns "" "" , although "" "" renwei "" "" and "" "" yiwei "" "" shared the subjects of pronouns like "" "" _ /_ "" "" ( <<< he/she >>> ) , "" "" __ "" "" ( they ) and "" "" _ "" "" ( I ) with relatively approximate salience , "" "" renwei "" "" showed an overwhelmingly frequent distribution of subjects from professional fields , such as experts ( __ ) and personages(__ ) in"
973	2020_emnlp_main_426	"e. g. , ' Iris ' who is mentioned in 4 sentences ) . Then , in step 3 , in each sentence of the story , we identify the protagonist ' s role as Agent or Other using its dependency parse 5 . The protagonist is an Agent if <<< he/she >>> is the subject of the main verb in the sentence and Other otherwise ( e. g. , Iris ' s role is Other in sentence 4 and Agent in all other sentences ) . Next , in step 4 , we obtain the emotional reaction of the protagonist in each"
974	2022_acl_long_287	"and many-to-one ( Xx→En ) translation scenarios separately . Following recent work ( Ma et al. , 2021 ) , we adopt document-specific metrics for evaluation apart from BLEU and support our findings with human evaluations . We also propose a pronoun F1 metric ( targeted at gendered pronouns : <<< he/she >>> ) for Xx→En translation , and employ accuracy on contrastive test sets ( Bawden et al. , 2018 ; Müller et al. , 2018 ) for En→Xx translation . Our main findings are summarized below : • Zero-shot transfer from sentences to documents is feasible through multilingual Doc-NMT modeling ,"
975	Y09_2053	"classification criteria The distinction between Levels B and C may be drawn drastically differently , depending on which of the three following classification criteria may be adopted ( Onoe 1999a PST ' While he/she was studying hard , since the exam given on the following day would be harder , <<< he/she >>> had a call . ' The sentence above gives strong evidence against the Minami hierarchy , since the subordinate clause headed by kara is embedded in the clause introduced by to , while the former is assigned to Level C and the latter to Level B by Minami ( 1974"
976	2020_lrec_1_117	"one used for gaps , with the POS of the elided element in square brackets and with the lemma missingˆtoken . This is typical , for example , of comparative clauses , like s485 : set tibi obedire et servire debeat , sicut filius [ verb ] patri ' but <<< he/she >>> must obey and serve you , like the son [ obeys and serves ] the father ' . While ellipsis is intentional by definition , the same kind of placeholder is also used to introduce unintentionally omitted tokens if their POS can be reliably reconstructed . For example , it"
977	W13_0209	"situation , but ignores q1 . This is evident in ( 11 ) . A and B are playing Monopoly . A asks a question , which is ignored by B. It is not that/IN B does not want to answer A ' s question and that/IN ' s why <<< he/she >>> asks q2 . Rather , B ignores q1 and asks a question related to the situation ( in this case the board game ) . ( 11 ) A : I ' ve got Mayfair &lt;pause&gt; Piccadilly , Fleet Street and Regent Street , but I never got a set"
978	E89_1004	"Rule 1 asserts : Given the mutual knowledge that/IN the user wants a certain action to occur , and the system ' s knowledge ( in form of a unique rule ) about the associated precondition and effect , the system concludes that/IN the user envisions the resulting state and <<< he/she >>> is familiar with the connecting causal relation . If the uniqueness of the rule cannot be established , sufficient evidence derived from the partner model might be an alternative basis to obtain a sufficient categorization of the desired event so that/IN a unique rule is found . Otherwise the user"
979	2022_acl_long_425	"in Figure 1 , the conversation starts without any specific goal in the user ' s mind , and the agent explores the potential task-oriented intents and smoothly transitions to a task-oriented conversation . The focus of this paper is more similar to a salesperson ' s capability , where <<< he/she >>> needs to chat with the user and discovers the implicit task-oriented intents that fit the business purposes and navigates the user to complete a task , such as purchasing a product , reserving a restaurant , or booking a hotel room . Hence , a new pipeline for constructing such"
980	W14_5154	"free to listen to the equation any number of times till they felt comfortable that/IN they could recall the equation . Similarly , the same participants were also made to listen to speech of mathematical equations generated by a TTS system . The participant will have to reproduce the equation <<< he/she >>> listens to . In addition to reproducing the equation , the participant will have to evaluate the spoken equation based on eight other parameters , i. e. , perform objective analysis . We arrived at these parameters partly by following the ( Hinterleitner et al. , 2011 ) and our"
981	W03_2128	"the problem . Thus the pairs of acts are similar to the question-answer pairs . The third type is non-understanding . It can be divided into several sub-types . The partner could not hear the previous turn , he/she finds the information surprising and decides to check it , or <<< he/she >>> did not understand the utterance . There are two linguistic subtypes of this act . The first is open initiation ( formed by some very general words : ah , what ) that do not determine the location of the problem . The typical response is repeating of information ."
982	P87_1005	"sophisticated enough to be a member of the support staff of the underlying system(s ) involved , and is familiar with the way the domain is conceived by the end users of the NLI . More particularly , we assume that/IN the individual can become comfortable with logic so that <<< he/she >>> may recognize the correctness of logical expressions output by the semantic interpreter , but need not be trained in AI techniques . A total environment is provided for that class of user so that/IN the necessary knowledge may be acquired , maintained , and updated over the life cycle of"
983	2020_emnlp_main_716	"Driving on public roads is a right not a privilege "" "" , sentences from PRO side "" "" In addition , in purchasing our vehicles , we have the right to drive said vehicle . "" "" and "" "" I appreciate the insight given by my opponent but <<< he/she >>> has failed to address the issue at hand . "" "" are classified as "" "" Testimony "" "" wrongly , which makes the model prefer PRO as the more convincing side . We believe that/IN incorporating more accurate argument structure generation models can further improve the performance on persuasion"
984	C94_1095	"or noun ) . Cache dictionaries are used as filters : if INTEX finds a word in a cache dictionary , it will not look tip the selected dictionaries and FSTs . If the user knows that/IN in a given corpus , the token par is always a proposition , <<< he/she >>> enters the following entry in a cache dictionary : pat ; par . PREP Hence , the user can avoid unnecessary ambiguities by putting frequent words ( or conversely , specific terms ) in cache dictionarids adapted to each processed text . Most compounds are ambiguous , since they forreally"
985	2022_slpat_1_9	"along with the corresponding responses . We use these in Task 2 to present to the turkers as human responses . Task2 : Overall system interaction and metrics : In the interaction flow , the user reads the conversation context , picks a keyword ( From task 1 ) that <<< he/she >>> wants to respond with -which brings up a human response ( from Task1 ) and a model response ( kw_loss model ) . The user can use a response as is or edit or type a new response altogether . We analyse if the users tend to choose a model"
986	2021_findings_acl_313	"for our experiments . Languages and Gender The extent to which information about the gender of referents is grammatically encoded varies across languages ( Hellinger and Motschenbacher , 2015 ; Gygax et al. , 2019 ) . Unlike English -whose gender distinction is chiefly displayed via pronouns ( e. g. <<< he/she >>> ) -fully grammatical gendered languages like French and Italian systematically articulate such semantic distinction on several parts of speech ( gender agreement ) ( Hockett , 1958 ; Corbett , 1991 ) . Accordingly , many lexical items exist in both feminine and masculine variants , overtly marked through morphology"
987	W10_0403	"next word when reading a partial sentence vs. a full sentence . That said , it needs emphasizing that/IN the key issue is to evaluate the quality of a suggested next word given a partial sentence , not grammaticality in complete isolation . When a user uses word completion , <<< he/she >>> is actively engaged in the writing process . No software can truly predict the intent of the writer ; the full sentence is waiting to be written and cannot be written a priori . Consider someone who is in the process of writing the sentence "" "" The plane carrying"
988	2020_intellang_1_5	". May : The user is interested in Insights related to Weekdays . 2 . June : Weekend insights are interesting to the user . 3 . July : The user prefers to know more about his sleep duration . August : The user is again interested to know if <<< he/she >>> is doing well on weekends . All statistically significant insights per day on a given month that satisfy the corresponding preference criteria were labeled with interestingness score 1 and otherwise labeled 0 . Since neural networks understand only numbers , we encoded each comparison insights into a single dimension binary"
989	W16_3601	"As a result , the agent needs to judiciously select the question , given the context of the game , in order to narrow down the range of valid people . There are 31 questions . Table 1 shows a summary . Attribute Q a Example Question Birthday 3 Was <<< he/she >>> born before 1950 ? Birthplace 9 Was he/she born in USA ? Degree 4 Does he/she have a PhD ? Gender 2 Is this person male ? Profession 8 Is he/she an artist ? Nationality 5 Is he/she a citizen of an Asian country ? Table 1 : Summary of"
990	W09_2105	"tag . The other simplification types refer to the eighteen simplification cases presented in Table 1 . Nested tags indicate multiple operations applied to the same sentence . Revising the automatic simplification Once the automatic simplification is done , a review screen shows the user the simplified text so that <<< he/she >>> can visualize all the modifications applied and approve or reject them , or select alternative simplifications . Figure 1 shows the reviewing screen and a message related to the simplification performed below the text simplified . The user can revise simplified sentences one at a time ; the selected sentence"
991	W07_2429	who produces approximately the same results when repeating a test . We used the following method for generating training examples . Give a subject three documents : a reference document R and two other documents A and B. Thereafter the subject specifies which of the documents A or B that/IN <<< he/she >>> considers to be most similar to R. This method generated reliable data and it was also possible to automatically generate large amounts of training examples by using hypotheses about the similarity between documents . Resemblance and containment Resemblance and containment quantify the similarity between two documents . The degree of
992	2001_mtsummit_papers_20	". As large numbers of people take this test world wide , it is hoped that/IN the scores obtained using this material will given some indication as to the level of English ability . For example , if subject A scores 500 points from the original TOEIC test , while <<< he/she >>> scores 600 points from the E-J MT results , then the chances are the subject finds the MT system useful . For subject B , the score from the original English test may well be higher , indicating that/IN he does not find the MT output useful . Our assumption"
993	W14_4313	"Pickup , Grab , Drop , ClearTop , Stack } Each time , the subject can choose any blocks they think are useful to teach the action . After finishing teaching one action ( either under step-by-step instructions or under one-shot instructions ) , we would survey the subject whether <<< he/she >>> thinks the teaching is completed and the corresponding action is successfully performed by the robot . We record the teaching duration and then re-arrange the table top setting to move to the next action . For the teaching/learning phase , we use two metrics for evaluation : 1 ) Teaching"
994	N19_4012	"in the article will be labeled with red color . If the author would like to use one of the suggestions , he/she can click on the gray button ( step 5 ) to add it to the text-area on the left hand side and edit it . Finally , <<< he/she >>> can click "" "" Post "" "" ( step 6 ) to post the article . The Proposed Model As shown in the Fig. 3 , our system can suggest to the users two headlines ( based on Newsroom headline and Bytecup datasets ) and summaries ( based on Newsroom"
995	C18_1155	"Uncovering a hidden relation or ellipsis from a construct is an important problem in NLP . For instance , when a customer searches for 15 inch laptop , he/she is actually searching for a laptop with 15-inch display . But , when a customer searches for 30 inch tyres , <<< he/she >>> is actually searching for tyres with 60 inch diameter . Noun Compounds are one of the many such constructs where the relation is hidden . For example , "" "" WHO Geneva headquarter "" "" is "" "" ( the ) headquarter of WHO located in Geneva . "" """
996	P10_3007	"syllable box contains a number of menus , and a text grid at the bottom of the box . • Syllable Type 4 • Syllable Frequency 5 • Voiced -Unvoiced consonant 6 • Manner of articulation 7 • Place of articulation 8 Once the user selects a syllable type , <<< he/she >>> can further specify each consonant within that syllable type in terms of voiced/unvoiced segment choice and manner and place of articulation . For the sake of simplicity , syllable frequency ranks have been divided in three rank groups . Alternatively , the user can bypass this criterion by selecting '"
997	D14_1143	"learners likely know most of these words . To more accurately measure a learner ' s vocabulary , we ideally must sample words that are representative of the entire set of words . More specifically , we wish to sample words such that if a learner knows these words , <<< he/she >>> is likely to know the rest of the words in the given vocabulary , and vice versa . To our knowledge , however , all current studies have relied on a simple heuristic method . In this heuristic method , educational experts first somehow create groups of words with the"
998	W00_1206	"system ( T'sou et al. 1998 ) , which also contains the system framework . Improvement 4.1 Problems Many Chinese discourse markers have both discourse senses and alternate sentential senses in different context . For a human tagger , steps $3 and $4 in section 2 are not difficult because <<< he/she >>> can identify an ADM/RDM based on his/her text comprehension . However , for an automatic process , it is quite difficult to distinguish an ADM from an RDM if no syntactic/semantic information is available . Another problem is the location of NULL-Marker described above . Our earlier statistics showed some"
999	R15_1090	"each user name is shared by multiple users . In Figure 1 ( b ) , "" "" David "" "" is the most common and ambiguous user name related to 57 users . In some cases , an off-line person asks people around a difficult question verbally , then <<< he/she >>> may be recommended by word of mouth to visit the CQA homepages of some potential answer providers . However , the links to their homepages are not provided sometimes , then the asker has to search them according to the provided user names . Some user names are unique ,"
1000	2021_wassa_1_11	"et al. , 2021 ) provides an extended dataset to the one compiled by Buechel et al. ( 2018 ) . The dataset has a total of 14 features spanning textual , categorical , and numeric data types . Essays represent the subject ' s empathic reactions to news stories <<< he/she >>> has read . The demographic features of gender , race , education , and the essay ' s gold-standard emotion label cover the categorical input features . The numeric features include the subject ' s age and income , followed by personality traits scores ( conscientiousness , openness , extraversion"
1001	2022_findings_acl_83	"medical keywords and hashtags . Each message was labeled for medical self-disclosure . The assigned labels ranged from 0 ( ' no self-disclosure ' ) to 5 ( ' high self-disclosure ' ) . The label ' 5 ' was given for instances were the post writer specifically mentioned that/IN <<< he/she >>> was diagnosed with a specific illness , was taking specific medication , had undergone surgery or was about to have one , or other cases of disclosing specific medical indicators . OffMyChest data set ( OffChe ) Jaidka et al. ( 2020 ) collected the OffMyChest conversations data by letting"
1002	W08_1605	"( follow-up question ) , it is interpreted by the system in the context of previous queries ; a revised version of q , q ' , is either directly submitted to the QA component or a request for confirmation ( grounding ) is issued to the user ; if <<< he/she >>> does not agree , the system asks the user to reformulate the question until it can be interpreted by the QA component ; 4 . As soon as the QA component results are available , an answer a is provided ; 5 . The system enquires whether the user is"
1003	C98_2158	" They are expressed by vertical and horizontal extensions of the prototype in Table 2 . The movements involved in these situations are locational and the other events must be done volitionally by the same person . Another extension covers situations where  "" someone does something , and then <<< he/she >>> does something else . "" "" This is based on the fact that/IN one person cannot generally engage in two actions at the same time . Of course , any type of events may occur sequentially . However , there exists the constraint on the fitness with te-linkage as mentioned"
1004	Y12_1024	", common words are excluded from the pattern and declared only as exceptions . Using common word exclusion , no true positive nor false positive is detected in the sentence "" "" Unless let us say may mga bisita siya "" "" ( translated as : Unless let us say <<< he/she >>> has visitors ) . &lt;token postag=""""ENG . * "" "" postag_regexp=""""yes""""&gt; &lt;exception postag=""""CW . * "" "" postag_regexp=""""yes""""&gt; &gt; &lt;/token&gt; &lt;token postag=""""TAG . * "" "" postag_regexp=""""yes""""&gt; &lt;exception postag=""""CW . * "" "" postag_regexp=""""yes""""&gt; &gt; &lt;/token&gt; &lt;token postag=""""ENG . * "" "" postag_regexp=""""yes""""&gt;&lt;/token&gt; &lt;token postag=""""TAG . * "" "" postag_regexp=""""yes""""&gt;&lt;/token&gt;"
1005	W09_3915	") . Following the same definition , misunderstandings were also tagged as rejections ( tag : Rej ) when the wizard expressed inability to execute the instruction ( for instance , given the robot ' s current location , as shown in line 2 in the dialogue ) , although <<< he/she >>> was able to interpret it . Secondly , non-understandings ( tag : Non , line 4 ) occurred when the wizards obtained no interpretation at all or too many . Non-understandings also included cases in which wizards were uncertain about their interpretation ( as suggested by Gabsdil , 2003 )"
1006	2020_gebnlp_1_3	"analysis of these words embeddings , we use the measures proposed in previous works ( Bolukbasi et al. , 2016b ; Gonen and Goldberg , 2019a ) . Inspired by these previous studies , we make use of the following lists of words : • Definitional List 8 pairs ( <<< he/she >>> ; boy/girl ; father/mother ; male/female ; his/her ; himself/herself ; man/woman ; son/daughter ) • Biased List , which contains 1000 words , 500 female-biased , and 500 male-biased . ( e. g. , diet for female and hero for male ) • Extended Biased List , extended version"
1007	P11_2085	"Pinyin "" "" shenme "" "" with numeric selection "" "" 1 "" "" at 11:10am in Microsoft Word application . The user made a mistake to type in the third Pinyin ( "" "" shenme "" "" is mistyped as "" "" shenem "" "" ) . Then , <<< he/she >>> pressed the backspace to modify the errors he has made . the word "" "" ___ "" "" is deleted and replaced with the correct word "" "" __ "" "" using Pinyin "" "" shenme "" "" . As a result , we compare the typedin Pinyins before and"
1008	2021_eacl_main_207	"privacy for models trained on transformed data . Given a trained machine learning model and its confidence score on a datapoint , MIA infers whether the datapoint was part of the model ' s training data . In order to conduct MIA , an attacker trains a shadow model that/IN <<< he/she >>> expects to mimic the target model under attack . Once trained , the shadow model ' s confidence scores on the datapoints members of its training set and other non-member datapoints are used to train the binary attack model . Given a datapoint , the attacker then extracts a similar"
1009	W14_0210	"plots . Track C -Building In track C the participant was asked to navigate through the building from the entrance to the yard , see Figure 1 . The navigation instructions were changed so that/IN instead of taking stairs down , the participant was asked to take stairs up and <<< he/she >>> got lost in the small corridor , where the last doors should be located but they were not there . The navigation using the NaviTerier application in this type of environment was easy for the participants and they all get lost at the desired location . At the place ,"
1010	W07_1519	parsing guide which is shown to give the highest accuracy for Turkish and for many other languages . The output of the parser ( pre-trained on the Turkish treebank ) is reflected to the screen by automatically constructing the dependency tree . The annotator may then change the dependencies which <<< he/she >>> finds incorrect . Conclusions and Future Work ITU treebank annotation tool is a semi-automatic annotation tool tailored for the particular morphological structure of Turkish where we need to annotate units smaller than words . It has three annotation levels and uses pluggable analyzers in order to automate these levels .
1011	W09_2109	"to allow a student to effectively communicate with the KSC-PaL . First , all drawing and coding actions of the student are interpreted and passed to the agent as a natural language utterance . Graphical actions are matched to a set of known actions and when a student signals that/IN <<< he/she >>> has finished drawing or coding either by ceding control of the graphical workspace or by starting to communicate through typed text , the interface will attempt to match what the student has drawn or coded with its database of known graphical actions . These graphical actions include not only correct"
1012	1997_mtsummit_papers_17	"statements ( some SQL or Boolean structures ) as input ; these structures must be preserved in order to have them processed correctly , and the terms in them must be translated and re-inserted . Support is needed when the foreign language is not understood by the analyst , so <<< he/she >>> cannot check if a translation is good or not . • In case the search is successful then the retrieval result will consist of a set of hits ( textual and structured ) . These hits may be in foreign language . Again they must be retranslated into the analysts"
1013	W13_4027	". Using these recordings we have introduced a socalled Context Catcher ( CC ) module . The way this module is currently working is as follows : The DM requests information from the user to progress through the task-oriented dialog . The user replies without specifying the type of data <<< he/she >>> is providing , the overall intent of the utterance or the relation to any dialog slot . The CC evaluates the request expressed by the DM and consequently updates various parameters of the SURR component . Consequently the SURR is able to provide a better , more context-specific mapping between"
1014	Y15_1047	"to the ways in which the hearer attempts to link together the sentences/clauses that form a discourse ( Kehler ( 2000 : 539 ) ) . For example , in a discourse , the hearer does not interpret the two sentences in ( 24a ) to be unrelated , but <<< he/she >>> infers that/IN Mary is upset at Bill because Bill forgot her birthday . Because it is more difficult to infer how the two sentences in ( 24b ) could be linked together , the discourse is less coherent . ( 24 ) a. Mary is upset with Bill . Bill"
1015	W19_3823	"programmer attribute . Generalizing , we use the following procedure to compute the association between a target and an attribute : We refer to this normalized measure of association as the increased log probability score and the difference between the increased log probability scores for two targets ( e. g. <<< he/she >>> ) as log probability bias score which we use as measure of bias . Although this approach requires one to construct a template sentence , these templates are merely simple sentences containing attribute words of interest , and can be shared across multiple targets and attributes . Further , the"
1016	W00_0306	"error rate , this becomes an even more important issue . The problem , then , is to find a compromise between the two . We compared two ways to systematically generate system utterances with only selected attributes , such that/IN the user hears repetition of some of the constraints <<< he/she >>> has specified , at appropriate points in the dialogue , without sacrificing naturalness and efficiency . The specific problems , then , are deciding what should be repeated , and when . We first describe a simple heuristic of old versus new information . Then we present a statistical approach"
1017	H94_1077	"the person was sometimes not given . The users were requested to make inquiries based on the information given in each sheet . We used maps for indicating the tasks to avoid controlling the structure of the spoken sentences . When the user could obtain the desired telephone number , <<< he/she >>> wrote down the number on the answer sheet , and proceeded to the next task . Even if the user could not get the telephone number alter all efforts , he/she was requested to proceed to the next task . Questionnaires After testing , each user was requested to answer"
1018	2021_emnlp_main_736	"used by human participants in our study , as described in Section 5 . The participants in this study are English proficient volunteers within our organization . Each participant is instructed on the guessing task by playing some trial games . The participant is admitted to the annotation only if <<< he/she >>> shows a clear understanding of the task . Given an image , a dialogue and a set of candidate objects with colour-matching boxes , participants express their guess by typing the number corresponding to the box of the selected candidate . Dialogues generated by human annotators from the GuessWhat ?"
1019	L16_1332	"aim of getting more user ' s recordings to be analyzed later . During game sessions , the role of the trainer ( a teacher or speech therapist ) is twofold : on the one hand , he/she evaluates the player ' s recordings and on the other hand , <<< he/she >>> helps players if necessary . The trainer has to sit next to the player . To evaluate the player ' s recordings , the trainer uses the keyboard of the same computer that/IN the player is using . Besides , to reduce the ambient noise in the recording process ,"
1020	Y13_1045	"the search engine will recommend the potential phrases ( or patterns ) the user may want to use , in order to : ( a ) save time for users , ( b ) make the convenience of use , and even ( c ) guide the user in case <<< he/she >>> is not sure about what to search for . In such tasks , we need to frequently search for frequent patterns containing a certain keyword ( or phrase ) , hence , we want to have a method that supports quick retrieval of patterns . In information retrieval , one"
1021	2002_tmi_papers_21	"source pattern incorrectly or creates an inadequate source pattern , other source patterns would be negatively affected . Unfortunately , it is virtually impossible to prevent this from occurring when increasing the number of training sentences . If the rule writer wants to make a really correct source pattern , <<< he/she >>> must consider all sentences in the corpus . This incurs much time and labor . Another problem is that/IN many source patterns have more than one target patterns . It is difficult to construct a sufficient variety of target patterns . In the conventional approach discussed above , the writer"
1022	W96_0408	"the set of errors a student makes changes , so too does the set of constructions a student uses ( appropriately ) . For example , generally a beginning student does not attempt to use a sentence that contains a complex sentential compLment or a relative clause , until after <<< he/she >>> has mastered the use of simple subject-verb-object sentences . In this section we introduce a component which attempts to capture aspects of the second language acquisition process that affect the text the student is generating . In acquiring English as a second language , there is considerable linguistic evidence that/IN"
1023	O05_3003	questions are answered by the speakers themselves ( rhetorical_question_answered ) . Unfinished utterances can sometimes be completed by the speaker ( completion_by_self ) or by the listener ( completion_by_other ) . The speaker can express exclamation ( exclamation ) or hesitate while he/she is planning the next utterance or when <<< he/she >>> has doubts about the content of the statement just made ( hesitation ) . To end the conversation contains two annotation tags used to close a conversation . The conversation participants draw conclusions about the topic ( conclude ) or express their readiness to end the conversation in general (
1024	2012_amta_wptp_4	") , he/she sent the source materials to a friend asking for help . The friend was late returning the postedited translation and did not include the original source text and raw machine translation . The post-editor hurriedly returned the finished post-edited translation on March 26 , 2012 , but <<< he/she >>> forgot to delete any of the project documents after the project was finished . Target Text : Company Overview Apple From PC to mobile phone Apple is the U. S. computer maker that sells the Macintosh personal computer , iPod portable music player , and mobile phones such as the"
1025	2022_acl_long_78	"operator is frequently used to retrieve the header cells of superlatives , as shown in Table 1 . To keep sentences as natural as they are , we do not encourage unnecessary sentence modification during the conversion . If an annotator finds multiple ways to question regarding a sentence , <<< he/she >>> only needs to choose one way that/IN best reflects the overall meaning . Regular Inspections and the Final Review We ask the two most experienced annotators to perform regular inspections and the final review . ( 1 ) In the labeling process , they regularly sample annotations ( about 10"
1026	W11_2303	"to generate natural language sentences , which are converted to speech via a speech synthesizer . At the end of the day , the child uses a menu to select sentences that/IN he or she wants the system to utter , and thereby puts together a narrative that describes what <<< he/she >>> did . The system allows for vastly more rapid output than a system where the child constructs each sentence from scratch . Perhaps the closest work to what we are proposing is the study of non-disabled adults in Cornish and Higginbotham ( No Date ) , where one of the"
1027	Y13_1017	" ( Cummins , 1999 , p.2 ) . Another factor proposed by Cummins ( 2001 ) that relates to second language acquisition is Common Underlying Proficiency ( CUP ) . Cummins believes when a child learns one language he/she acquires a set of skills and implicit meta-linguistic knowledge that/IN <<< he/she >>> can draw upon when learning another language . The CUP provides the base for the development of students ' native language ( L1 ) and the second language ( L2 ) . This suggests that/IN it is very important for students to maintain their L1 . In most international schools
1028	R11_1106	texts as candidate titles . An original approach combining statistical criteria and noun phrases positions in the text helps collecting relevant titles and subtitles . So , the user may benefit from an outline of all the subjects evoked in a mass of documents , and easily find the information <<< he/she >>> is looking for . An evaluation on real data shows that/IN the solutions given by this automatic titling approach are relevant . Introduction Web pages contain a multitude of information concerning many domains . Very often , the user has to supply heavy cognitive efforts to find the information he/she
1029	2020_lrec_1_807	see Table 2 . ) ( Keywords are underlined here , but were not underlined on the prints used during the recording . ) language , experience in practicing pronunciation of foreign languages , cities where he/she spent their childhood/went to school/attended a university or college , and cities where <<< he/she >>> had lived for at least one year . The second questionnaire was filled after every recorded dialogue and contained a series of open questions intended to find out whether the speaker felt comfortable during this particular session and whether the task was completed successfully . Annotation The annotation scheme includes
1030	H05_1126	prepared manually , was used as an input . ASR result ( baseline ) : The ASR result was used as an input . 3 . Proposed method ( log data ) : The system generated questions based on the proposed method , and the user replied to them as <<< he/she >>> thought appropriate . We also evaluated the proposed method by simulation in order to confirm its theoretical effect . Various factors of the entire system might influence the performance in real dialogue which is evaluated by the log data . Specifically , the users might not have answered the questions
1031	L16_1389	, which is available from a site administered by the Institute , 7 is distributed as a MySQL dump , consisting of 12 tables : six for recipe data and six for meal data . Any researcher in public institutions such as universities can obtain access to the corpus if <<< he/she >>> wishes to use it for research purposes . In Table 1 , we summarize the statistics of our corpus and others described in Section 2 . . From the table , it is clear that/IN our corpus is the biggest in the world . Between its release in February 2015
1032	F13_2012	liens sémantiques , car le réseau est construit de manière automatique et à partir de textes non-annotés . Introduction Lexical choice is an obligatory step in language production . During this stage , the author ( speaker or writer ) has to select a word expressing the concept or idea <<< he/she >>> has in mind . Of course , before choosing a word , one must have accessed a set of words from which to choose . While writers may use an external resource ( dictionary ) in case of word finding problems , speakers always rely on the internal or mental
1033	C10_1031	that/IN we will not repeat the features used in previous systems , but only focus on the new features . 3 http : //www . cs . waikato . ac . nz/ml/weka/ Sentiment Consistency Intuitively , in a post , if the author starts expressing opinions on an object , <<< he/she >>> will continue to have the same opinion on that object or its attributes unless there are contrary words such as  "" but "" "" and "" "" however "" "" . For example , we have the following blog ( an id is added before each sentence to facilitate"
1034	W04_1407	"to one side of the screen . For collaborative work there is a whiteboard feature that lets all participants draw onto the same space in the presentation window . To train software this way , the trainer can use the "" "" application sharing "" "" feature . Whichever application <<< he/she >>> starts will be visible on the screens of all participants ( with a small delay depending on the speed of the internet connections ) . It is also possible to have some of the participants show their screen to the rest of the group . The voice part of the"
1035	P15_1103	"user ' s sentence . The feature set associated to the user ' s attitude is built according to those assigned to the attitudinal expression found is the agent ' s sentence . Since the user assumes or rejects the attitude expressed by the agent , the system considers that/IN <<< he/she >>> utters an attitudinal expression that/IN he/she is the source . Regarding the polarity , if the user validates the statement expressed by the agent , the polarity of his/her attitude is the same as the agent ' s one . Otherwise , if the user expresses a no answer ,"
1036	D19_1556	"annotations gathered for the Persuasive Opinion Multimedia ( POM ) corpus presented in Garcia et al. ( 2019 ) . The dataset is composed of 1000 videos carrying a strong opinion content : in each video , a single speaker in frontal view makes a critique of a movie that/IN <<< he/she >>> has watched . The corpus contains 372 unique speakers and 600 unique movie titles . The opinion of each speaker has been annotated at 3 levels of granularity as shown in Figure 1 . At the finest ( Token ) level , the annotators indicated for each token whether it"
1037	W11_3105	". The various CEFs are now described . Location Related feature : These features contain the place name where user wants to go/travel/stay etc or the place name from where he/she starts his/her journey or where he/she stays ( Origin ) . Sometimes user also mentions the place name where <<< he/she >>> must want to visit . Location To : Where user wants to go/visit/travel/see . Extraction Rule : Location named entity words are preceded by preposition "" "" to "" "" , "" "" include "" "" , "" "" at "" "" Location From : From where user wants to"
1038	W19_7710	"Fauconnier , 1985 ) is necessary because of auxiliaries such as kell ' must ' , lehet ' may ' and akar ' want ' , which may also appear inside a clausal core along with the infinitival form of a main verb ( e. g. meg akarja venni ' <<< he/she >>> wants to buy it ' ) . Auxiliaries allow speakers to talk about the existence of a process in the world of necessary or possible actions , somebody ' s intentions , etc. rather than the Reality Space ( the world of actual occurrences ) . I assume that/IN the"
1039	W12_1621	"the matcher would know which object has what name . As shown in Figure 1 , those secret names are displayed only on the director ' s screen but not the matcher ' s . Once the matcher believes that he/she correctly acquires the name of an target object , <<< he/she >>> will record the name by mouseclicking on the target and repeating the name . A task is considered complete when the matcher has recorded the names of all the target objects . Examples Consistent with previous findings ( Liu et al. , 2011 ) , our empirical study shows that/IN"
1040	K18_1044	"reader in building or further corroborating his or her prior stance on the discussed topic . To capture the magnitude of the effect of the editorial ' s text , we consider the following labels : • Strongly challenging : The editorial made the reader really rethink whether and why <<< he/she >>> thinks that/IN his/her prior stance is right . • Somewhat challenging : The editorial conveyed at least some information opposite to the reader ' s stance that was new and noteworthy for him/her . • No effect : The reader did not find any new and noteworthy information opposing or"
1041	2002_tmi_papers_21	"yield poor translations . In the new method , on the other hand , the writer can obtain many target phrases for the same source pattern by partially translating source sentences . Since the writer can easily judge whether each of the extracted target phrases are correct or not , <<< he/she >>> finds it much easier to construct various kinds of target patterns . Moreover , the use of source patterns as the retrieval key and partial parsing for extracting target phrases makes it easy to add this approach to an MT system . Procedure of New method Figure 4 outlines the"
1042	W12_4108	", advertising ( Mirizzi et al. , 2010 ) , etc. For the sake of easing the process of user annotation and providing a better effect of humancomputer interaction , researchers expected to build automatic social tagging recommender systems , which could automatically suggest proper tags for a user when <<< he/she >>> wants to annotate an online resource . By observing huge amount of online resources , researchers found out that/IN most of them contain summaries , which could play an important role in briefly introducing the corresponding resources , such as the artist entry about Michael Jackson in Figure 1 ."
1043	W03_2109	". In this study , we implemented new functions into the interpreter as follows : • Processing of Correction Utterance : The system omits the word sequence as restatement and word preceding this sequence . The omitted word sequence is the word or word sequence which the user uses when <<< he/she >>> tells the system to repair the wrong word or word sequence . Figure 2 shows this process . • Removing Recognition Error by Logging Error : The system ignores non-semantic words at the head or the tail of the sentence caused by detection errors of beginning/ending speech and adopts the"
1044	E87_1020	"as the Scandinavian languages , this would probably be the case . REFTEX is the part of the program package that will be used by the translator during the process of translation . Program execution starts by asking the translator to key in names of the pair of reference texts <<< he/she >>> wants to use for solving the problems of the actual translation . The program then asks for the first key word to be searched in the reference text , whose equivalents the translator wants to know . If the reference source text contains that word , the program will print"
1045	W10_4355	"the effectiveness of the window , which indicates that/IN temporal changes in user behaviors should be taken into consideration , and match those of our earlier reports ( Komatani et al. , 2008 ; Komatani and Rudnicky , 2009 ) : the user ' s utterance history becomes effective after <<< he/she >>> uses the system about ten times because the average number of utterances per dialogue is around five . By comparing Conditions ( 2 ) and ( 4 ) , we can see that/IN the classification accuracy improves after adding the estimated ASR accuracy to Condition ( 4 ) . This"
1046	2020_sigdial_1_39	"hidden from the user . The user opened a window to interact with the guide in one display and talked with both guides about his/her trip to the two pre-designated prefectures . The two guides used the same account to talk to the user ; the user did n't realize <<< he/she >>> was talking to two guides . In the 2to1 condition , two guides and one user also participated in the dialogue as in the Mixto1 condition . However , both talked to the user using different accounts . Each guide opened a window to interact with the user without opening"
1047	C16_1083	"depend on the level of subjectivity inherent in the task itself . Data Preprocessing Before extracting features for the satisfaction classifier , we anonymized the text by replacing all first and last names with a placeholder , merged all gendered pronouns ( e. g. , both he and she became <<< he/she >>> ) , replaced all words referring to a particular gender with a gender-neutral equivalent ( e. g. , guy and lady became person ) , downcased , and removed special characters . Another crucial step undertaken during preprocessing was the handling of negation terms . For instance , phrases such"
1048	C12_1185	"it needs large translation rules to take the entire sentence structure into account . This requirement always leads to a severe sparsity problem for translation . Therefore , the global reordering problem is not well addressed in these models . Intuitively , when a human interpreter translates a sentence , <<< he/she >>> segments the sentence according to his/her understanding and translates each part respectively and then he/she translates the entire sentence by combining the partial translation of all parts . From this sense , the translation process of our PAS-based translation framework is similar to human translation to some extent . We"
1049	Y13_1035	"the descriptive words , "" "" Oh ! there ' s water coming out of the smoke alarm . "" "" However , there is not such case . In this case , the speaker seems to be hard to decide whether it is an irony or sarcasm , so <<< he/she >>> tagged them both , which indicates that/IN these two terms are not distinguished in their functions in this example . Evaluating this case with the cases illustrated in 4.2 , it shows that/IN the content of sarcastic tweets are built on what the speaker said , but ironic tweets can"
1050	2017_mtsummit_commercial_13	"MT has been introduced , contradicting quantitative measurements that recorded increased speed , has been seen elsewhere by Plitt and Masselot ( 2010 ) and Gaspari et al. ( 2014 ) . When compared to their actual productivity times , we note that/IN apart from ES1 regarding TD ( where <<< he/she >>> is least productive ) , the other participants perceive it differently from the actual numbers . Table 7 below shows the perceived productivity against the actual productivity , where l/L = least , m/M = most , lowercase letters are for the perceived productivity and capital letters for the actual"
1051	2021_naacl_main_155	"possibility and one aspect of the criminal behaviour , and the chain itself may not be sufficient to initiate such a lawsuit . For example , the chain complete understand → violate → abuse of power of charge set AP&DD shows that/IN the litigant deliberately violated the rules , but <<< he/she >>> will be charged with abuse of power only when his/her action results in major loss of public property . Hold Knife Hold Acknowledgments This work is supported in part by National Hi-Tech R&D Program of China ( 2018YFC0831900 ) . We would like to thank the anonymous reviewers for the"
1052	I05_6009	"typology that covers almost all error types was not established in traditional EA . Another criticism against EA is that/IN errors reflect only one side of learner language . A lot of people point out that/IN if a researcher analyzes only errors and neglects what learners can do correctly , <<< he/she >>> will fail to capture the entire picture of learner language . It is time-consuming to count both correct and incorrect usages in learner data , and this must have been quite difficult to do in the past before computing technology was developed . Furthermore , the real significance of EA"
1053	W15_0622	"definitions . However , if the learner knows the meaning of verify , the circularity involving truth and verify will not exist any more . We can capture this idea by defining a learning blanket for each learner , which encompasses the set of concepts in the concept graph that/IN <<< he/she >>> is familiar with . In Figure 1 , all words in bold are assumed to be below the learning blanket with respect to a learner . We observe that/IN the circularities situated below the learning blanket do not challenge the learner . Thus , content editors do n't need to"
1054	S15_1015	"such as multiple choice or binary responses as true or false can be binned into the following categories : • Background Questions : A person ' s age , gender , educational level , income , marital-status , socialstatus , how often he/she follows the news , what news sources <<< he/she >>> follows , etc. ; • Opinion of Political Parties : Democratic and Republican parties and their respective public figure representatives ; • Opinion on major economic and political problems facing the USA ; Q1 I approve of Obama ' s and the Democrats ' position on abortion and gay marriage"
1055	2009_mtsummit_caasl_8	") availability of linguistic resources such as semantic lexicons , thesauri , parallel or tagged corpora and ontologies ( 2 ) structural and lexical similarity of two languages and ( 3 ) the desired depth and precision of translation . For example if one wants to perform corpus based translation <<< he/she >>> should have appropriate corpora otherwise exploiting data driven methods is not a good decision . When we need a deep level of understanding , knowledge based semantic methods perform better than statistical methods and so on . In other words knowledge based approaches are mostly employed where either we need"
1056	C88_1011	"the same matrix dimellsion then means cox~relating the numbers of two planes . tf a user awetmlally finds dial the labels it~ aw , e dim~ ? : ~ . sion of a sift)matrix , could be inchlded idle a ~evi cower s3 , , . x~ • boi , <<< he/she >>> may spceLfy this directly ~md the : ov ; _ : , aii left , ix together with its mapping wili be tnmsformed iuio ~ , m : , v ~ ; maller one . Different mairJeos may be ~llel'[~ed KN iOt ; ~ iitJ [ iic ; misted ~Iiapi)illgS"
1057	W03_2119	"' s drawing turns is almost equivalent to that of X ' s speech turns . The equivalence of the extent of resistance of speech and drawing turns also suggests that silence during drawing tended to be longer not because the other party could not speak while drawing but because <<< he/she >>> did not want to speak while drawing . In other words , drawing could make an excuse for not speaking while preserving the smoothness of turn-taking interactions . Finally , within the data we analyzed , all the cases in which a speech turn overlaps a preceding drawing turns were"
1058	2015_mtsummit_users_19	"completes the sentence "" "" ____ "" "" ( Operating Condition ) , all the sentences "" "" CPU____ "" "" in the remaining tasks will be automatically replaced with "" "" CPU Operating Condition "" "" . After that , when the other translators face the pushed translation , <<< he/she >>> can accept it or revise it according to the context . If a translator finds that/IN the pushed translation is wrong or problematic , then he/she can also tell its original translator or discuss with him/her to find out the best decision . We prepared a document of 1,000 characters"
1059	Y12_1024	"cause false positives and false negatives . These are ( 1 ) intraword CS and ( 2 ) common words -especially those with different semantic information . Consider the sentence "" "" Unless let us say may mga bisita siya "" "" ( translated as : Unless let us say <<< he/she >>> has visitors ) . The word "" "" may "" "" is a common word . If a basic dictionary-based approach is applied , both "" "" may "" "" and "" "" mga "" "" are detected as CSPs . A combination of all pattern matching refinements yielded the"
1060	2021_starsem_1_4	"with evidence and more to do with characters and their choices/feelings . This is illustrated by the positive associations of Voluntary Powers , Related To Space , and Sentiment and Moral Powers . In other words , it seems readers like it best when a detective solves a mystery because <<< he/she >>> is "" "" the good guy "" "" who makes the right choices , rather than through real detective work . Among all the 24 themes , Intellectual Faculties shows some interesting insights about the success prediction of a book . So we ' ll discuss about the impact of"
1061	W19_3019	"comma-separated values file that includes the post titles , content , timestamps , and anonymized unique user ids . The goal of shared Task A is to predict users ' suicide risk into one of the four classes ( i. e. , ( a)-(d ) ) given the fact that/IN <<< he/she >>> has posted on SuicideWatch . Systems Description This section provides an overview of features extracted from posts , followed by a short system description of our submitted runs . Features TF-IDF features : We used the TF-IDF weighting scheme as text representation . The TF-IDF feature vectors of n-grams were"
1062	W19_5506	"red button ) , labeling it as irrelevant ( blue button ) , or the annotator can click on one of the two grey buttons . In this case , the annotator then chooses to label the data as "" "" I do n't know "" "" , in case <<< he/she >>> is unsure about the correct annotation , or as "" "" Not enough information "" "" , in case the uncertainty clearly derives from the presented data itself . This differentiation provides insights about the information content of the data as it becomes clear whether a text might have been"
1063	D19_1019	"Figure 1 depicts an exemplar dialogue of online customer service , which has a form of multi-turn dialogue between the customer and the customer service staff ( or "" "" the server "" "" for short ) . In this dialogue , the customer is asking for refunding the freight <<< he/she >>> paid for sending back the product . At the end of service dialogue , the E-commerce platform invites the customer to score the service quality ( e. g. , using 1-5 stars denoting the extent of satisfaction from "" "" very unsatisfied "" "" to "" "" very satisfied """
1064	W12_2513	"is aware of the other and of the interaction , e. g. , thinking of or talking about someone . An important aspect of annotating social events is taking into consideration the intention of the author : does the author want us to notice an event between characters or is <<< he/she >>> simply describing a setting of a plot ? Since our definition of social events is based on cognitive states of characters , as described by the author , we do not annotate a social event in Example ( 2 ) below since there is no evidence that/IN either Alice or"
1065	W14_2514	"this paper , we investigate how topic dynamics during the course of an interaction correlate with the power differences between its participants . We perform this study on the US presidential debates and show that/IN a candidate ' s power , modeled after their poll scores , affects how often <<< he/she >>> attempts to shift topics and whether he/she succeeds . We ensure the validity of topic shifts by confirming , through a simple but effective method , that/IN the turns that/IN shift topics provide substantive topical content to the interaction . A Cost Sensitive Part-of-Speech Tagging : Differentiating Serious Errors from"
1066	W05_1616	"the other hand , when we talk to basic skills students , they often want to know what their mistakes were ( it can be frustrating to score twenty-six out of twenty-seven and not know which one was wrong ! ) . Not knowing an individual and how much effort <<< he/she >>> has put into the test is another problem . Evaluative comments in a report such as "" "" this is very good "" "" are meaningless without such knowledge and , indeed they are meaningless without reference to some scale ( but tutors have advised against mentioning the core curriculum"
1067	P15_1103	"feature set associated to the user ' s attitude is built according to those assigned to the attitudinal expression found is the agent ' s sentence . Since the user assumes or rejects the attitude expressed by the agent , the system considers that/IN he/she utters an attitudinal expression that/IN <<< he/she >>> is the source . Regarding the polarity , if the user validates the statement expressed by the agent , the polarity of his/her attitude is the same as the agent ' s one . Otherwise , if the user expresses a no answer , the polarity is the opposite of"
1068	Y18_1028	"at the brighter side of things whereas repeatedly highlighting some negative aspects might leave the voters frustrated and unhappy . A slightly higher percentage of kinship terms is seen in the losing speeches . This can be seen as the lack of confidence on the speaker ' s part where <<< he/she >>> tries to impress the voters just by assuming the superficial roles analogous to family members . The winning speeches contain a relatively lesser number of nouns when compared to the losing ones . We observed the frequently used nouns in all the speeches , which are related to politics ,"
1069	2020_signlang_1_28	"encountered a diagram in an exercise ( 3 ) . Each task was timed and observations/remarks of the participant were noted down . After each task , the participant was asked to rate the difficulty of the task on a Likert scale ( 1932 ) and to explain what changes <<< he/she >>> would make on the interface . At the end of the test , the participant was asked to fill a SUS questionnaire . Ideally , the SUS questionnaire would have been in SL . However , no official translation existed and our participants did not have sufficient English knowledge -which"
1070	W10_4339	"adopts a natural policy gradient method as the policy optimization method . Experiment by dialogue simulation For each simulated dialogue session , a simulated user ( P user , K user , V user ) is sampled . A preference vector P user of the user is generated so that <<< he/she >>> has four preferences . As a result , four parameters in P user are "" "" 1 "" "" and the others are "" "" 0 "" "" . This vector is fixed throughout the dialogue episode . This sampling is conducted based on the rate proportional to the percentage"
1071	I08_3009	"to the first choice of the menu when the user types up to "" "" ayubov "" "" ( Figure 4 ( c ) ) . A user can select the menu at this point by pressing the next required punctuation such as space , comma , period etc. or <<< he/she >>> can type up to "" "" ayubovan "" "" ( Figure 4(d ) ) . The Algorithm Input Sequences Goonetilleke et al. have carried out an experiment to find out how the most frequent Sinhala characters are romanized by Sinhala speakers . We have further divided the roman character sequence"
1072	W19_5301	Document Rating + Document Context ) assessments were combined into a single evaluation set-up to save annotator time . This involved constructing HITs so that/IN each sentence belonging to a given document ( produced by a single MT system ) were displayed to and rated by the human annotator before <<< he/she >>> was shown the same entire document again and asked to rate it . Quality control items for this set-up was carried out as follows with the aim of constructing a HIT with as close to 100 segments in total : 1 . All documents produced by all systems are pooled
1073	W12_4001	"are called "" "" Suggester "" "" and "" "" Guesser "" "" . These roles are initialized randomly and interchanged between the two players after each round of the game . The Suggester , who starts each round will be given the whole text of a review document and <<< he/she >>> is supposed to : 1 . Decide whether the whole text is positive or negative , i. e. the author is praising about a subject or criticising it . 2 . Select a single word ( or a sequence of words , as short as possible ) which best describes"
1074	P08_1051	"assignments open at the same time , or that/IN they were not concentrating fully on working on the task . A high value of Time On Task thus does not necessarily mean that/IN the worker actually spent a long time on it . However , a low value indicates that/IN <<< he/she >>> did only spend a short time on it . • Reward Over the period spent collecting the data , we changed the reward a couple of times to speed up the process . The reward is reported per HIT . • Approval Status Within the collection process we encountered some"
1075	2020_signlang_1_28	"in the original version . Thus , we chose to use the French version detailed in ( Yharrassarry , 2011 ) : even if there is no official French translation yet , this one is the most used of the existing translations . Finally , we asked the participant if <<< he/she >>> had global remarks on the interface or any propositions of change . The experimental set-up we used for the tests can be seen in the Figure 4 . User testing was done on a computer running on Windows 10 on which a stable version of the interface had been set"
1076	W15_5956	"Their duration tends to be longer at the end of larger syntactic units , but have statistical variations . A speaker may choose to insert a pause at a location necessary to disambiguate a syntactic ambiguity , or if the preceding uninterrupted sentence segment is too long , or if <<< he/she >>> is simply out of breath . For instance , if there is no pause or if the pauses in a sentence are wrongly placed , then the meaning of the sentence will change . Control of pause occurrence and duration is an important issue for naturalness and correct meaning of"
1077	P08_2004	"team will win . We could easily imagine a scenario where sentence ( 5 ) is more objective than sentence ( 6 ) and ( 7 ) . For example , the speaker may believe that/IN the red team will lose , but in order to avoid personal bias , <<< he/she >>> may instead say : "" "" It is possible that/IN the red team will win ( but the blue team has a better chance ) . "" "" In general , explicitly showing uncertainty can imply postulation , but it can also convey the intention of being objective by not"
1078	2021_findings_acl_313	"English ) linguistic gender forms are rendered in the gold standard translations . Hence , information about speakers ' preferred linguistic expressions of gender are transparently validated and disclosed . Overall , MuST-C exhibits a gender imbalance : 70 % vs. 30 % of the speakers referred by means of <<< he/she >>> pronoun , respectively . Instead , allowing for a proper cross-gender comparison , they are equally distributed in MuST-SHE . Accordingly , when working on the evaluation of speaker-related gender translation for MuST-SHE category ( 1 ) , we proceed by solely focusing on the rendering of their linguistic gender"
1079	W00_1012	", then add Argument . Procedures of interpretationgeneration ( B ' s possibilities to react to proposal ) are started after B has recognised SA Proposal : -in case of ( 2 ) , ( 4 ) , ( 5 ) : if B does not have Goal G and/or <<< he/she >>> does not haw~ the corresponding beliefs and A has not provided the needed additional information , then add Question ( ask for additional information ) ; -in case of ( 6 ) : if B does not have Resources for D , then Reject + Argument ; -in case of"
1080	W15_5705	"MT ) answer and then to the reference answer . In this way , the subject evaluates the MT answer first on its own and then with respect to the reference . Using a web interface , a question is presented to the evaluator in the target language and then <<< he/she >>> is asked to provide a self-estimation of his/her knowledge level ( high , medium , or low ) on the subject involved in the question . Then the same question is presented , followed by the automatically translated answer ( A ) . In this step the subject assesses on"
1081	L16_1623	"a stopping criterion for online learning process . Acknowledgements This work was supported by the MateCat project , which is funded by the EC under the 7 th Framework Programme . "" A Dataset for Detecting Stance in Tweets We can often detect from a person ' s utterances whether <<< he/she >>> is in favor of or against a given target entity ( a product , topic , another person , etc. ) . Here for the first time we present a dataset of tweets annotated for whether the tweeter is in favor of or against pre-chosen targets of interest-their stance ."
1082	Y99_1014	"In this section , we will discuss some instances of canonical WCO effects and relevant data , trying to show that/IN the WCO effects can be accounted for by general binding conditions of pronominal expressions such as the non-locally bound anaphor caki ' self , the overt pronoun ku ' <<< he/she >>> ' , and the empty pronoun pro . ' We will try to show that/IN even the canonical structure that is believed to induce WCO effects cannot be evidence for hierarchical clause structure in Korean . Let us consider the following data first where a pronominal expression is contained within"
1083	I08_2143	"based shared representation for generating actions to be performed by the agents and utterances to communicate about the steps involved in performing the action . The utterances generated by POLLy are socially appropriate in terms of their politeness level . The user will be given a role play situation and <<< he/she >>> will be able to have a conversation with the agents on a desktop computer , where some dialogic utterances would be allocated to the user . An evaluation of POLLy ( Gupta et al , 2007 ; Gupta et al , 2008 ) showed that/IN ( 1 ) politeness perceptions"
1084	W03_2128	"provide the answer . Consultants typically use this act . Refusal and Missing Information The second problem group are situations where the answerer is not able to give information . Three cases can be differentiated depending on continuation of dialogue : the answerer does not have the needed information , <<< he/she >>> refuses to give it , or he/she cannot give it immediately . If the answerer does not have the information then the questioner must abandon the following attempts . In the case of having information we have two possibilities depending on whether the answerer is the consultant or client ."
1085	2020_readi_1_4	"reading fluency , accuracy and comprehension . If the comprehension test can be simultaneously administered to all students of a class , the fluency and accuracy tests must instead be individually administered , in a quiet room : the student is invited to read aloud the piece as best as <<< he/she >>> can , whereas the examiner times and marks the errors on a specific paper sheet . Although it would be desirable to have several evaluation moments during the scholastic term , since this activity is very time consuming , this aspect prevents to regularly repeat the assessment . Furthermore ,"
1086	Y95_1030	"wanted to take in counseling . Because it ' s her original purpose to study abroad . ' In example like these it would seem that/IN the speaker had at first decided to end his/her statement after the clause . Having produced a clause-final falling pitch at that point , <<< he/she >>> decided it would be better to add some account or elaboration as a separate comment . As has been seen in the above , the most striking pattern that emerges from this last grouping is that/IN causal clauses appear as separated , intonationally disconnected units much more often than do"
1087	P98_2163	"boldfaced and they are extended to the other boxes with some directions and constraints . [ x BE zx]x AND [ x BE z212 For example , the Temporal Sequence relation has a prototype structure , which is roughly read as "" "" someone goes to somewhere , and then <<< he/she >>> goes ( from there ) to elsewhere . "" "" This expresses our common sense that/IN one person cannot move along two different paths at the same time , which implys that/IN the two movements by a person must be sequential . This prototype is extended so as to cover"
1088	Y13_1035	"  the play is amazingly good , "" "" the tag "" "" #sarcasm "" "" indicates what the speaker really intend to mean is the opposite . The sarcastic effect is built based on what is said by the tweeter , and the speaker is aware of what <<< he/she >>> has said . On the other hand , the contents of ironic tweets are more about a general event , such as ( 1-a ) to ( 1-e ) . For example , in ( 1-d ) the ironic effect locates in the nature of the contrast between "" """
1089	W10_1303	"is a slot-filler and that/IN other options for filling that slot are available . To edit that text , the user clicks on the highlighted word in the display window , and a window such as that in Figure 4 is displayed . The user may then select the filler <<< he/she >>> desires , and it will replace "" "" nachos "" "" in the display . The system described is currently being implemented . Yet to be integrated is a facility that will enable more extensive editing of the text in the display window and the specifics of easy access to"
1090	C16_1169	"seen that/IN using both constraints leads to larger improvement in performance , indicating that/IN they are complementary constraints which guide the hypothesis selection from different aspects . These results verify that/IN the user-validated prefixes are effective on multiple levels . In fact , when a user gives a prefix , <<< he/she >>> is making a comprehensive decision after analysing the overall structure and orders of the translation . And the proposed method exploits the syntactic structure information hidden in the prefix . In addition , although there are parsing mistakes , we can still get positive results ; this shows that/IN the"
1091	L16_1037	"variety of topics which can be extended easily from the system . Learners can train their conversational skill in L2 on the topics of their interest ( Wilcock & Yamamoto , 2015 ) . Additionally , it is important to investigate how the learner obtain lexical and syntactic knowledge when <<< he/she >>> hears utterances in the similar syntactic structure from the perspective of pedagogy . We will , therefore , create a corpus of collecting speech data of the learners in a conversational scenario in which the advanced learner repeats the utterances in the similar syntactic structure in a series of answers"
1092	2021_findings_acl_279	"and then make a final decision ( Saeidi et al. , 2018 ) . As an example shown in Figure 1 . The user posts the scenario and asks a question concerning whether the loan meets the needs . Since the user cannot know the rule document , the information <<< he/she >>> provided may not be sufficient for the machine to decide . Therefore , a series of follow-up questions are asked by the machine until it can finally make a conclusion . Figure 1 : An example dialog from ShARC benchmark dataset ( Saeidi et al. , 2018 ) . At"
1093	N06_3001	"document and my future research plan is described . Introduction In human communication , ideas tend to unfold in a structured way . For example , for an individual speaker , he/she organizes his/her utterances into sentences . When a speaker makes errors in the dynamic speech production process , <<< he/she >>> may correct these errors using a speech repair scheme . A group of speakers in a meeting organize their utterances by following a floor control scheme . All these structures are helpful for building better models of human communication but are not explicit in the spontaneous speech or the corresponding"
1094	W15_0912	"lexicalized collocations which are considered fixed MWEs ( Oflazer et al. , 2004 ) . An example for this case is given below : • "" "" Arka arkaya iki operasyon gec ¸irdi . "" "" lit . ( Back to back ) ( two ) ( operations ) ( <<< he/she >>> had ) . ( He/she had two operations consecutively . ) Model #1 : The second model selects the sequences of words whose surface forms except the last word ( which may go under inflection ) are the same as the constituents of a MWE in the referenced list ."
1095	2011_mtsummit_papers_66	"will be accepted . Only those SWPs that have passed the quality checking process will be included in the evaluation of post-editing speed . Results and Analysis Speed and Quality As mentioned above , the daily post-editing speed of each single translator is evaluated by the number of SWPs that/IN <<< he/she >>> successfully accomplishes every day , and his daily post-editing quality is evaluated by the average quality score of all the translated SWPs every day . Figure 3 and Figure 4 show the average daily speed ( number of SWPs per translator per day ) and average daily quality ( quality"
1096	W14_2710	"dynamics during the course of an interaction correlate with the power differences between its participants . We perform this study on the US presidential debates and show that/IN a candidate ' s power , modeled after their poll scores , affects how often he/she attempts to shift topics and whether <<< he/she >>> succeeds . We ensure the validity of topic shifts by confirming , through a simple but effective method , that/IN the turns that/IN shift topics provide substantive topical content to the interaction . "" In this paper , we investigate how topic dynamics during the course of an interaction correlate"
1097	C04_1182	". Similarly , we marked breath placements ( BR ) if they were audible . We hypothesize that/IN words may be inserted during periods of breath if not properly accounted for by the speech recognizer . Mispronunciations ( MP ) tend to occur when a child is faced with word <<< he/she >>> is not familiar with and makes an attempt at either sounding it out ( or speak fluently with an inappropriate phonetic realization ) . The use of wrong words ( WW ) is commonly a result of fast reading . The child may only read the first part of the"
1098	2021_emnlp_main_92	"subj } and { obj } . The developer building the templates was given the task guidelines ( brief description of the relation , including one or two examples and the type of the entities ) and a NLI model ( roberta-large-mnli checkpoint ) . For a given relation , <<< he/she >>> would create a template ( or set of templates ) and check whether the NLI model is able to output a high entailment probability for the template when applied on the guideline example(s ) . He/she could run this process for any new template that/IN he/she could come up with"
1099	W15_0912	"required to match . This model extracts collocations belonging to the semi-lexicalized category as stated in ( Oflazer et al. , 2004 ) . Below is an example for this case : • "" "" Gelecegini haber vermedi . "" "" lit . ( that he/she was coming ) ( <<< he/she >>> did n't give ) ( news ) . ( He/she did n't inform ) Model #2 : The third model checks only the stems of the words and select the sequences of words matching the stems of a MWE in the referenced list . Non-lexicalized collocations ( Oflazer et al."
1100	W13_4043	"participant , as illustrated in Figure 1 ( c-1 ) . Figure 1 ( c-2 ) gives an example of the participants ' speech activities in a certain duration . In this example , participant C ' s activity is relatively smaller than that of the others , and so <<< he/she >>> is likely to get left behind in the current conversational situation for a number of reasons . When a robot steps into the situation to coordinate , there should be proper procedures in place to obtain initiatives to control conversational contexts and to give it back to the others ."
1101	C10_2098	". Note that/IN this paper focuses on the task of species disambiguation and makes the assumption that/IN the named entities are already recognised . Consider the following sentence as an example : if one searches the proteins ( i. e. , the underlined term ) in a protein database , <<< he/she >>> will find they belong to many model organisms . However , in this particular context , CD200R-CD4d3+4 is human and mouse protein , while rCD4d3+4 is a rat one . 2 We call such a task of assigning species identifiers to entities , according to context , as species disambiguation"
1102	R19_1114	"the dialog state to track which attribute values have not been provided by the user yet , W/O-NE- D.2 Extended results for task 4 Detailed results for task 4 are shown in Table 5 . With-NE-Table : In task 4 , the user tells the system the restaurant in which <<< he/she >>> wants to book a table . The restaurant name , which is a NE , is stored in the NE-Table along with it ' s generated key . When the user asks for information about the restaurant such as , phone number , the NE restaurant name stored in the"
1103	P89_1023	"ourselves to the word "" "" contract ' , we get the following semantic interpretations of syntactic patterns : Even with a large number of input sentences , the system createsmany of these specific patterns ; a human user must review the results and provide for case descriptions generalization when <<< he/she >>> feels this being reasonable . A second approach is to generalize on the basis of a single example , and then retract ( split ) the rule if a counterexample is found . Currently , we axe ~a'udying different policies and comparing the results ; one interesting issue is the"
1104	W17_2314	". It should be noted that/IN the characteristics of our reliable expert are different from those proposed in previous work ( Donmez and Carbonell , 2008 , 2010 ) . Specifically , in the conventional proactive learning , the reliable expert is assumed to be perfect , i. e. , <<< he/she >>> always provides correct annotations . However , in practice , such an assumption is too strong , especially for NE annotation . Therefore , we assume that/IN the reliable expert is not perfect , but that/IN he/she has a higher expertise level in the target domain , and has a"
1105	1991_mtsummit_papers_17	( in C under UNIX ) . A Finnish-English Workstation has also been implemented and we are presently testing and tuning the system using real data . The MT Machine The MT Machine is a general tree-manipulation system with several built-in inference strategies . When a user applies the machine <<< he/she >>> writes a rule base to control the execution of the machine and chooses the appropriate inference strategy . The machine takes well-defined linguistic trees as input and produces as output trees which represent meaning-preserving transformations of the input trees ( Fig. 1 ) . We will not discuss either the
1106	W00_1012	", then add Argument . Procedures of interpretationgeneration ( B ' s possibilities to react to proposal ) are started after B has recognised SA Proposal : -in case of ( 2 ) , ( 4 ) , ( 5 ) : if B does not have Goal G and/or <<< he/she >>> does not haw~ the corresponding beliefs and A has not provided the needed additional information , then add Question ( ask for additional information ) ; -in case of ( 6 ) : if B does not have Resources for D , then Reject + Argument ; -in case of"
1107	P86_1034	") in goals and plans ( e. g. , "" "" What is a vector ? "" "" ) . In some cases , the clarification subdialogues arise from the prerequisite on the recta-plan , that is , assure mutual understanding . For example , the user will verify that <<< he/she >>> has identified the correct referent for an anaphor in the adviser ' s utterances . 3 . Acknowledgement subdialogues occur when the user informs the adviser that/IN he/she believes that/IN he/she has understood an explanation . They arise from the prerequisite on the recta-plan , that is , assure mutual"
1108	2022_naacl_main_227	"In order to encourage more diverse and high-quality references , we assign each sentence to three random annotators for independent annotation . Their submissions are then aggregated and sent to a random senior annotator ( reviewer ) for review . An annotator may submit multiple references for one sentence if <<< he/she >>> thinks they are all correct according to the guidelines . The job of the senior annotator includes : 1 ) modifying incorrect references into correct ones ( sometimes just rejecting them ) ; 2 ) adding new correct references according to the guidelines . After review , the accepted references"
1109	2020_coling_main_463	". You will automatically get paired with someone else who will play the other role . User : A user is expected to interact with an assistant to get a restaurant recommendation . The user will already know his/her general restaurant preferences and also the exact name of the restaurant <<< he/she >>> wants to go to . Further , information about restaurants that/IN the user has visited in the past will be available and shown to the user . Assistant : An assistant is expected to interact with the user and work towards recommending a restaurant the user wants to go to"
1110	N13_1123	"set comes from Abu-Jbara et al. ( 2012 ) and Hassan et al. ( 2012 ) . This data set originally was used for finding subgroups of users , so the annotations were done at user level , i. e. for each user there is a label indicating which subgroup <<< he/she >>> belongs to . We use the top-3 mostly discussed threads with two subgroups for our study . In reality , controversial issues are often discussed across threads . We thus constructed another large data set which contains more than one thread for each issue . We chose three hot issues"
1111	O08_5002	"part . In a scenario where a user wants to express the approximate meaning of increasing the capacity of knowledge but is not sure whether to use "" "" extend "" "" or "" "" expand "" "" as a verb before "" "" knowledge "" "" as noun , <<< he/she >>> can specify the query "" "" ex % knowledge "" "" to obtain relevant usage examples for comparison and decision . For users who are not even familiar with both of the two words and just roughly know there should be a proper verb before the noun "" "" knowledge"
1112	Y12_1056	"factors of politeness than as separate factors ( lift : 1.22 ; 1.22 ; 1.12 ; 1.11 ) . In case of the couple pre-sequences =&gt; lis . perspective , the association of direct factors of politeness is shown . This means that/IN when the requester used a pre-sequence , <<< he/she >>> also used the lis . perspective ( to mitigate the directness of a request and its impact and effect on the listener ) . Pre-sequence and lis . perspective were associated with salutations and greetings ( F5 with F1 ) or ( F3 with F1 ) by requesters . They"
1113	Y17_1008	"instructor who requires a class project , and the repetition occurs because he wants to emphasize that/IN there can be variety ( e. g. lamp , wall decoration , electrical project ) . In ( 31 ) , the speaker tries to suggest an arrangement or a mainframe in which <<< he/she >>> used the expression twice . ( 30 ) They have to come up with a lamp or they may have to come up with a wall decoration or they should come up with an electrical project anything that has something to do with reports and this may be the application"
1114	2020_lrec_1_807	"or were replaced-see example on Figure 1 . A person having a complete map was asked to explain the route to his/her interlocutor , and the latter had to draw it on his/her own incomplete map . After the explanation , the other person was instructed to repeat the route <<< he/she >>> had drawn . The speakers took turns to describe their complete map , thus swapping the Leader and the Follower roles 4 times . Each pair of maps contained 5 keywords that were kept the same in all the recordings . All the keywords mostly contained vowels and sonorants ("
1115	E09_1040	"the English source ) . This shows the maximum percentage of answers an evaluator managed to find from either the interpreter ( speaker audio ) or the automatic system output ( TTS ) in Spanish . For instance , information in English could have been missed by the interpreter because <<< he/she >>> felt that/IN this information was meaningless and could be discarded . We consider those results as an objective evaluation . SLT , ASR : Verification of the answers in each component of the end-to-end process . In order to determine where the information for the automatic system is lost ,"
1116	W19_7509	"Framework ( NCF ) 33 devised by NCERT -Government of India , and Common European Framework of Reference ( CEFR ) 34 by the Council of Europe the following levels for Sanskrit Shabdamitra are determined : • Novice ूारि_कः ( prārambhikaḥ ) -Novice is considered as a basic user where <<< he/she >>> is provided with the basics/fundamentals of language , like , varṇamālā ( i. e. , Sanskrit alphabet ) , word formation , etc. • Intermediate मा_िमकः ( mādhyamikaḥ ) -Intermediate is an independent user who has mastered the basics of Sanskrit and can communicate simple and basic needs . Here"
1117	2020_wnut_1_76	"is to develop systems that can automatically extract related events from tweets . The built system should identify different pre-defined slots for each event , in order to answer important questions ( e. g. , Who is tested positive ? What is the age of the person ? Where is <<< he/she >>> ? ) . To tackle these challenges , we propose the Joint Event Multitask Learning ( JOELIN ) model . Through a unified global learning framework , we make use of all the training data across different events to learn and fine-tune the language model . Moreover , we implement"
1118	C12_1185	"requirement always leads to a severe sparsity problem for translation . Therefore , the global reordering problem is not well addressed in these models . Intuitively , when a human interpreter translates a sentence , he/she segments the sentence according to his/her understanding and translates each part respectively and then <<< he/she >>> translates the entire sentence by combining the partial translation of all parts . From this sense , the translation process of our PAS-based translation framework is similar to human translation to some extent . We believe that/IN this work is a big step towards semantics-based machine translation . Remainder of"
1119	I17_1099	"example conversation as in Figure 1 . The words in Italic are speaker B ' s own ideas that are new for the other speaker A. The underlined words in purple explicitly indicate the emotions . In the fourth speaker turn , speaker B first expresses his/her feeling on what <<< he/she >>> has heared from speaker A , which reveals his/her understanding . Then , speaker B suggests by saying Just breathe deeply when you feel yourself getting upset . Following the direct response towards A , B ' s suggestion is original yet context-dependent . It shows that/IN B builds up"
1120	2012_amta_wptp_4	"and innovative design . Ultimately , the company gets a lot of attention for the words and deeds of Mr. Steve Jobs , the ostentatious owner , but he died in October of 2011 . Post-Editor C Scenario : Upon receipt of the source materials , the post-editor confirmed that/IN <<< he/she >>> had received all of the source materials and would follow all of the specifications . The post-editor used Acrobat Reader to view the appleTerms . pdf file and MS Word 2010 to edit the target text . When finished post-editing , the post-editor returned the post-edited text alongside the source"
1121	L18_1444	"the example shows the common trend that/IN a user ' s interests , either extracted from his/her messages or from topical friends , are strongly related , and in same case identical . For example , the user in Table 1 frequently accesses the IMDb and Spotify services , and <<< he/she >>> is also a follower of the IMDb and Spotify Twitter account . Furthermore , his/her interest in the band The Magnetic Field emerges from both source types . Overall , we followed 444,744 English-speaking and 25,135 italian-speaking users ( the set U ) who accessed at least one of the"
1122	C10_1097	"predictive process is challenging since it involves micro dynamics and temporal relationship between cues from different modalities ( Quek , 2003 ) . Figure 1 shows an example of backchannel prediction where a listener head nod is more likely . For example , a temporal sequence from the speaker where <<< he/she >>> reaches the end of segment ( syntactic feature ) with a low pitch and looks at the listener before pausing is a good opportunity for the listener to give nonverbal feedback ( e. g. , head nod ) . These prediction models have broad applicability , including the improvement of"
1123	2022_findings_acl_285	"laptop and restaurant . The colored words in brackets represents ground truth sentiment label of the corresponding aspect . The symbol means the predicting sentiment is correct , and the other symbol means the predicting sentiment is wrong . when a person tries to understand a relatively long sentence , <<< he/she >>> first read the entire sentence . Subsequently , after giving a specific aspect , he/she will dynamically select related words based on the previous memory state until he/she fully understands the sentiment polarity of the given aspect . Interestingly , the above phenomenon is consistent with our dynamic re-weighting adapter"
1124	W14_4724	"a person in the class intersection Belgian ⊓ V iolinist(X ) , and hence we can infer that/IN a "" "" Belgian violinist "" "" is a subclass of a "" "" Belgian "" "" . Furthermore , we could conclude that/IN if the same person were a surgeon , <<< he/she >>> would also be a "" "" Belgian Surgeon "" "" . Subsective ( X is a A N ⇒ X is a N , but X is a A N ̸ ⇒ X is A ) Such adjectives acquire their specific meaning in combination with the noun the modify ."
1125	2007_mtsummit_papers_30	"the adequacy questionnaire . Evaluation Set up for Fluency At the end of the adequacy evaluation , judges are asked to fill the fluency questionnaire for each sample . They have to rate the following standard fluency questions ( presented in Table 5 ) taking into account the audio sample <<< he/she >>> has just listened to ( the questions are in fact in Spanish but are here translated here in English ) : Test Fluency questionnaire Understanding Do you think that/IN you have understood the message ? 1 : Not at all 5 : Yes , absolutely Fluent Speech Is the system"
1126	W11_0708	"innovations , new hashtags are created by individuals when they feel the need to categorize their messages with a term not yet used for this purpose . This reflects the speaker ' s need to create a term , for example , to name an object or an action that/IN <<< he/she >>> was not acquainted with in the offline world . Just like hashtags can fail and be used only once , a linguistic innovation may not exceed the boundaries of its creator ' s language . An innovation can be used in a specific situation and fall into oblivion , like"
1127	W13_3714	"( i. e. the VM , the root auxiliary and the infinitive ) form a grammatical unit , which , however , is subject to word order variation . The link between VM and infinitive The first , rather trivial observation is that/IN in patterns like el fog utazni ' <<< he/she >>> will travel away ' and részt akar venni ' he/she wants to take part ' , there is a syntactic relationship between the first and the third element . This relationship is one of licensing : the so-called verb modifiers ( el ' away ' , részt ' part ."
1128	L18_1461	"answer the feature changes of the arguments presented in the sentences ( e. g. , anger of "" "" my child "" "" in "" "" my wife hits my child "" "" ) or those of the workers themselves ( e. g. , anger of each worker himself/herself when <<< he/she >>> reads the presented sentence "" "" my wife hits my child "" "" ) . In total , 33,683 workers participated in this task . As a result , feature changes of 9,073 event sentences ( types ) were acquired ( including 975 verbs ( types ) and 19,052 arguments"
1129	P18_4011	"useful in this very-low-resource scenario . We could already build glosses for many words and provide a partial translations , so that/IN the native speaker could finish a sentence faster than starting from scratch . The Chinese Room also helped the native speaker to more easily find the English words <<< he/she >>> was looking for , and allowed us to make sure that/IN the translation covered all essential parts of the original text . 5 Related Work Callison-Burch ( 2005 ) ; Albrecht et al. ( 2009 ) ; Koehn ( 2010 ) and Trados 5 have built computeraided translation systems for"
1130	C04_1182	". Similarly , we marked breath placements ( BR ) if they were audible . We hypothesize that/IN words may be inserted during periods of breath if not properly accounted for by the speech recognizer . Mispronunciations ( MP ) tend to occur when a child is faced with word <<< he/she >>> is not familiar with and makes an attempt at either sounding it out ( or speak fluently with an inappropriate phonetic realization ) . The use of wrong words ( WW ) is commonly a result of fast reading . The child may only read the first part of the"
1131	2022_naacl_main_227	"time-consuming . On the other hand , we did not give enough consideration to this issue when designing the salary computation formula . In the future , we plan to optimize ( or simplify ) our annotation workflow so that/IN each annotator is required to give only one reference which <<< he/she >>> thinks is the best , and assign each sentence to more annotators if we need more references . Human annotation performance . In order to assess the annotation ability of our annotators and human performance for CGEC task , we calculate char-based F 0.5 scores by evaluating all annotation submissions"
1132	2004_jeptalnrecital_long_15	"résumés normalisés en trois langues ( anglais , français et espagnol ) à partir d'un texte en anglais . We present an application of oriented multilingual summarization from domain specific texts . These summaries are oriented because the user has to define in a first step the kind of information <<< he/she >>> wants to be present in the final summary . In order to acheive this task , a first step of information extraction is performed . This extracted information which corresponds to the user ' s specification is then the input of a multilingual generator that produces the desired summaries in"
1133	2022_acl_long_290	"pool , i. e. , the MMQA dataset , we identify the entities of the question text and answer text . We then randomly select a question from the question pool as the seed of a conversation . We argue that/IN a user may be interested in the entities that/IN <<< he/she >>> have asked and the new entities occurred in the system ' s responses . We hence randomly select one from the identified entities in previous questions and answers as the user ' s next point of interest . Then we randomly select a question from the question pool that contains"
1134	W15_5928	"by the personal pronouns , it is removed from the possible antecedent lists , we are left with "" "" rAmuki "" "" , "" "" gOpiki "" "" 5 ) Reflexive pronouns will be referring the antecedents within the sentence . Example : "" "" tanu "" "" ( <<< he/she >>> ) , "" "" tAmu "" "" ( they ) . Example 15 : ravi : rAmuki Dabbu evaru iccAru ? ( to_Ramu money who gave ) ( Ravi : Who gave the money to Ramu ? ) rAju : gOpi tana Dabbu ataniki ( Gopi his money him )"
1135	L16_1358	"life ' ) is used in Costa Rica to say hello , say goodbye , describe a person who is very nice and easy going , express how one is doing ( e. g. ' -Hey ! how are you ? -Pura vida ! ' ) , ask someone how <<< he/she >>> is doing ( ' -Pura vida ? -Pura vida ! ' ) , express that/IN a situation is good and exciting , and so on . This work is a pilot study for representing Spanish MWEs in a computational lexicon taking dialect specificities into account , as well as for"
1136	L16_1352	"rules and make modifications . To investigate the cognitive load on the author by using ProphetMT is not a trivial task , as the controlled language provided by ProphetMT will both facilitate and control the authoring . The author might have to fall back to choose a different rule when <<< he/she >>> fails to find a suitable one . Nonetheless , if take into account the fact that/IN ProphetMT does not require the user to be multilingual , even if ProphetMT slows down the author somewhat , this can be compensated by the reduced work in the post-editing stage . "" Relations"
1137	W10_4329	"robot simulators have been used . Koulouri and Lauria ( 2009 ) developed a simulator to collect dialogs between human and simulated robot using a Wizard-of-Oz method . The human can see a map of a town and teaches the robot a route and the operator operates the robot but <<< he/she >>> can see only a small area around the robot in the map . However , the dialog is keyboard-based , and the situation does not dynamically change in this setting , making this approach unsuitable to the study of timing aspects . Byron and Fosler-Lussier ( 2006 ) describe a"
1138	2006_tc_1_2	"do know , how clearly can they express themselves ? Also how can the researcher be sure that/IN he/she interprets what the respondent says in the correct way ? Or vice versa , how can the researcher be sure that/IN the respondent understands the questions asked the same way as <<< he/she >>> does ? In order to minimise any misunderstanding or loss of information due to the issues above , a pilot study was carried out prior to the survey being designed . The pilot study included interviews ( 10 in total ) and a focus group session ( 8 participants in"
1139	W13_1108	"' Prescriptions ( PRESC ) Some of our food-health relations are also mentioned in the context of doctors ' prescriptions ( 5 ) . That is , a doctor may prescribe a patient to consume a particular food item since it is considered suitable for their health condition , or <<< he/she >>> may forbid a food item in case it is considered unsuitable . As already pointed out in §4.1.6 , doctors usually present an authority with regard to food-health relations . That is why , their remarks should be considered reliable . In order to detect doctors ' prescriptions , we"
1140	W17_7555	"do , what they think , and what they feel . Character ' s thoughts in response to the actions or words of others are obviously a key to that Character ' s personality . Like thoughts , Characters emotions can instantly reveal a Character ' s personality and what <<< he/she >>> finds important . If we dive deep in the story we can extract the actions , thoughts , emotions and overall personality of a Character easily . Since the Characters are playing the major role in any story , we can consider automatic identification of Characters from stories is one"
1141	Y12_1056	"the level of foreign language acquisition is not on intermediate level ( B1 or B2 ) , the speaker ( sender ) usually simplifies his/her utterance in foreign language , applies utterances from his/her mother tongue or sometimes translates them ( word by word ) into foreign language , hence <<< he/she >>> cannot be aware of differences in meanings , which one and the same element can acquire in the other language . We therefore believe that/IN it is important to examine the rules of production of politeness speech acts , which the interlocutors use in the production of their spoken and"
1142	W18_5611	"the sentences in the test set . However , it is likely that/IN the same problem of "" "" classification standard confusion "" "" negatively influences this score too . For a use-case where , let us say , the system suggests 10 headings per sentence to the user when <<< he/she >>> is writing the nursing notes , this would mean that/IN there is a very high probability ( ≥ 90 % ) of finding a suitable/correct subject heading among the suggested ones . Based on their observations , the evaluators found the system to sometimes assign subject headings with an artificial"
1143	W00_1012	"checks first the harmful/useful aspects of D , and after this proceeds to aspects connected with possible punishments . The prerequisite for triggering this reasoning procedure is w(pleas ) &gt; w(unpleas ) , which is based on the following assumption : if a person wishes to do something , then <<< he/she >>> assumes that/IN the pleasant aspects of D ( including its consequences ) overweigh its unpleasant aspects . The same kinds of reasoning schemes are constructed for the needed-and must-factors . The reasoning model is connected with the general model of conversation agent in the following way . First , the"
1144	R13_1065	"not risk the failure of supposed communicated expectations of the partnera native speaker . The next pair was requester ' s perspective and the politeness markers ( F2 with F4 ) . In case of interlanguage ( English ) , when requester used more direct utterance through factor F3 , <<< he/she >>> mitigated this directness with expressive factor F4 ( politeness marker ) . When he/she decided to express him/herself more indirectly , he/she used a combination with politeness marker ( F2 with F4 ) reinforcing the likelihood of request fulfilment , which is confirmed by the last couple of factors ."
1145	2021_law_1_12	": "" "" I can get up early anyways "" "" ' nasılsa sabah erken kalkarım ( I can get up early anyways ) is a finite sentence , nasılsa sabah erken kalkarımcı is a person who would say this a lot , procrastinating till midnight and still believing that <<< he/she >>> would get up early anyways . Although this type of usage is rare , in UD we have absolutely no way to deal with the syntax of this sort of expressions . For example , kalkarımcı , the last word in the phrase , would have the lemma kalkarımcı ,"
1146	W09_2105	"click on the "" "" simplify "" "" button . This triggers the syntactic simplification system , which returns an XML file containing the resulting text and tags indicating the performed simplification operations . After that , the simplified version of the text is shown to the user , and <<< he/she >>> can revise the automatic simplification . The XML representation of simplification operations Our simplification system generates an XML file describing all simplification operations applied to a text . This file can be easily parsed using standard XML parsers . Table 5 presents the XML annotation to the "" "" gold"
1147	2020_osact_1_5	"opinion in an indirect way , where the intended meaning is different from the literal one ( Wilson , 2006 ) . Additionally , sarcasm is highly context-dependent , as it al-ways takes part between parties where shared knowledge exist . Usually , a speaker will not use sarcasm unless <<< he/she >>> thinks that/IN it will be understood as so ( Joshi et al. , 2017 ) . Sarcasm detection is a crucial task for SA . The reason for this is that/IN a sarcastic utterance usually carries a negative implicit sentiment , while it is expressed using positive expressions . This"
1148	E93_1037	"him/her a favor of giving a seat , he/she thanked Taro , who was slightly em . barrassed . ( 9 ) 01&lt;i&gt; 02&lt;j&gt; seki-wo uzutte-ageta-node , Taro&lt;i&gt; -wa 01&lt;i&gt; 02&lt;j&gt; orei-wo iwareta . 01&lt;i&gt; chotto terekusak -atta . Because Taro gave him/her a favor of giving a seat , <<< he/she >>> thanked Taro , who was slightly embarrassed . ( 10 ) 01&lt;i&gt; 02&lt;j&gt; seki-wo uzut-te-ageta-node , 01&lt;i&gt; 02&lt;j&gt; orei-wo iwareta . Taro&lt;i&gt; -wa 01&lt;i&gt; chotto terekusak -attn . Because Taro gave him/her a favor o/ giving a seat , he/she thanked Taro , who was slighau embarrassed . 8 ,"
1149	P04_3030	": The patient takes an aspirin . identifiability A patient multiplicity The patients The labels ( identifiability etc. ) could of course be replaced by more familiar words ( e. g. , article , number ) . Assuming that/IN the user is happy with the subject of the sentence , <<< he/she >>> will ignore the reconfiguration options and instead click around the word ' takes ' in the feedback text , so selecting the whole event entity : The patient takes an aspirin . polarity The patient does not take an aspirin . time The patient took an aspirin . The patient"
1150	R13_1065	"of expressive and social factors of politeness , i. e. mitigating device combined with presequences but also with attention getter in a reverse order . It means that/IN , when a requester used an alerter -a form of addressing , a specific greeting etc. , it is more likely that/IN <<< he/she >>> used an expressive factor , which raised the indirectness of utterance and decreased its possible negative effect . Similarly , if he/she used indirect expression of perspective -F2 then he/she combined it with politeness markers , so the most frequently occurred association rules were those indicating the preference of indirect"
1151	E14_1022	"weights the matching of each unigram in an MTBT segment equally , however , it is not the case that/IN the value of assistance to the translator is equal for each unigram of the MTBT segment . The parts that are most valuable to the translator are the parts that/IN <<< he/she >>> does not already know how to translate . Weighted percent match ( WPM ) uses inverse document frequency ( IDF ) as a proxy for trying to weight words based on how much value their translations are expected to provide to translators . The use of IDFbased weighting is motivated"
1152	L16_1060	"correlations show that/IN the faster the usertypes , the more often the user tends to make mistakes . In addition , since there seems to be no correlation between the ratios of corrected and uncorrected spelling errors for each user , the user ' s personality appears to determine whether <<< he/she >>> corrected his/her errors . Phonological Factors vs. Typos We analyzed the substitution spelling errors . Tables 6 and 7 show confusion matrices for corrected and uncorrected spelling errors , respectively . The most frequent value for each spelling error is shown in bold . By looking at the most frequent"
1153	L18_1361	"while the user is going through the consent form . Since parents own the data , they have the option to update , erase , remove them or ask for their portability from the secured cloud , using the interface . In the same way , the child , once <<< he/she >>> turns 13 years old ( based on Children ' s Online Privacy Protection Rule aka "" "" COPPA "" "" ) , will be required to express his/her free consent to continue or stop his/her participation to the project . • Data View : The data view interface helps families"
1154	C14_1172	"anaphora resolution . As it is seen from the results table we have obtained lesser scores for Bengali . In Bengali third person pronouns such as "" "" ami "" "" ( I ) , "" "" túmi/tui/apni "" "" ( you ) , "" "" se/tini "" "" ( <<< he/she >>> ) , "" "" amra "" "" ( we ) , "" "" tara/tnara "" "" ( they ) , do not have masculine , feminine distinction , but there is animacy distinction . And also the verb has no gender agreement . This adds more challenge to anaphora resolution"
1155	D15_1282	"such as reviews , discussion posts , and ( micro ) blogs are becoming increasingly popular . We observed from our collaborations with social science and health science researchers that/IN in a typical application , the researcher first need to obtain a set of posts of a particular topic that/IN <<< he/she >>> wants to study , e. g. , a political issue . Keyword search is often used as the first step . However , that is not sufficient due to low precision and low recall . A post containing the keyword "" "" politics "" "" may not be a political"
1156	C08_1076	"to explain the significance of the models at the level of an individual , primarily in terms of the process of language acquisition , which largely governs the course of language change . In the initial years of language development every child passes through a stage called babbling during which <<< he/she >>> learns to produce non-meaningful sequences of consonants and vowels , some of which are not even used in the language to which they are exposed ( Jakobson , 1968 ; Locke , 1983 ) . Clear preferences can be observed for learning certain sounds such as plosives and nasals ,"
1157	2020_coling_main_350	"( e. g. En : I ' ve never been there -It : Non ci sono mai stata/stato ) . Differently , English is a natural gender language ( Hellinger and Bußman , 2001 ) that mostly conveys gender via its pronoun system , but only for third-person pronouns ( <<< he/she >>> ) , thus to refer to an entity other than the speaker . As the example shows , in absence of contextual information ( e. g As a woman , I have never been there ) correctly translating gender can be prohibitive . This is the case of traditional text-to-text"
1158	W01_1401	"accuracy clearly decreases as the dist increases . This implies two points : ( 1 ) dist can indicate the quality of the produced translation , in contrast with the fact that/IN MT systems usually do not provide any confidence factor on their results . The user is safe if <<< he/she >>> confines himself/herself to using translations with a small dist value ; ( 2 ) The current algorithm has a problem in handling distant examples , which usually relate to the long sentence problem . Error Analysis As shown in the previous two subsections , the most dominant problem is in"
1159	2022_udfestbr_1_6	"  between "" "" negociada "" "" ( dependent ) and "" "" continua "" "" ( head ) . Also , note that/IN each token has its id subscripted next to it . Editing Sentence Annotation If the user double clicks on a sentence in the results , <<< he/she >>> will be redirected to the corresponding CoNLL-U . There , they will be able to edit the sentence ' s annotation data . The editor is organized in a table-like manner , with each line of the sentence ' s CoNLL-U corresponding to one row in the editor . Therefore"
1160	O10_2002	"account when using the definite article . According to Hawkins [ 17 ] , using the definite article enables the hearer to access the NP in the p-set ( a set of knowledge known by the hearer/reader as being definite ) . The speaker/writer should use the definite article when <<< he/she >>> is confident that/IN the other party knows that/IN the NP is definite . A communication breakdown will occur if the speaker/writer uses the definite article erroneously or mistakenly believes that/IN the hearer has such knowledge . The writers in this corpus may not have been falsely assuming that/IN the reader"
1161	2020_wnut_1_76	"is to develop systems that can automatically extract related events from tweets . The built system should identify different pre-defined slots for each event , in order to answer important questions ( e. g. , Who is tested positive ? What is the age of the person ? Where is <<< he/she >>> ? ) . To tackle these challenges , we propose the Joint Event Multitask Learning ( JOELIN ) model . Through a unified global learning framework , we make use of all the training data across different events to learn and fine-tune the language model . Moreover , we implement"
1162	2021_paclic_1_12	"a face threatening act , which would threaten readers ' negative face if they do not take the action as desired by the speaker . Therefore , since a reader ' s negative face may be threatened by the speaker ' s persuasion act , the reader would decide whether <<< he/she >>> accepts the speaker ' s viewpoints or not ( Taillard , 2002 ) . In order to let readers agree with speaker ' s suggestions to the largest scale , the speaker needs to be strategic while expressing his/her intentions on the statements . Hovland et al. ( 1953 )"
1163	W96_0408	"intention is that/IN the user ' s placement in SLALOM will help guide the kind of constructions that/IN the system should use in its generated text . That is , the system should attempt to generate texts which use constructions that are at ( or slightly above ) the level <<< he/she >>> is placed in SLALOM . Our initial investigations lead us to believe that/IN this may be done within FUE a functional unification-based text generation system [ Elh93 ] through a dynamic ordering of altemative realizations ( ALTs ) . l I In other words , at ALT branches in the"
1164	2021_findings_acl_180	"on the detection of enthusiasm in human textbased dialogues , using lexical features and word co-occurrences with conditional random fields in order to distinguish enthusiastic utterances from non-enthusiastic ones . They defined enthusiasm as "" "" the strength of each participant ' s desire to continue the dialogue each time <<< he/she >>> makes an utterance "" "" . In our work , we instead combine different modalities and features to detect enthusiasm and we define an enthusiastic speaker as "" "" stimulating , energetic , and motivating "" "" ( Keller et al. , 2016 ) . Tokuhisa and Terashima ( 2006"
1165	W00_1012	"checks first the harmful/useful aspects of D , and after this proceeds to aspects connected with possible punishments . The prerequisite for triggering this reasoning procedure is w(pleas ) &gt; w(unpleas ) , which is based on the following assumption : if a person wishes to do something , then <<< he/she >>> assumes that/IN the pleasant aspects of D ( including its consequences ) overweigh its unpleasant aspects . The same kinds of reasoning schemes are constructed for the needed-and must-factors . The reasoning model is connected with the general model of conversation agent in the following way . First , the"
1166	2022_nlp4convai_1_3	"whether the buyer ' s needs have been met , thus seeking a mutually optimal solution . To simulate such a real-world vending scenario and provide enough motivation to start a conversation , both buyer and seller are given incomplete information prior to the conversation . The buyer knows what <<< he/she >>> prefers among multiple products but does not know the quality of the product prior to the conversation , and the seller does not know in advance the buyer ' s preferences but is aware of the quality of the product and its profit . The seller seeks a mutually optimal"
1167	W12_1621	"the matcher would know which object has what name . As shown in Figure 1 , those secret names are displayed only on the director ' s screen but not the matcher ' s . Once the matcher believes that he/she correctly acquires the name of an target object , <<< he/she >>> will record the name by mouseclicking on the target and repeating the name . A task is considered complete when the matcher has recorded the names of all the target objects . Examples Consistent with previous findings ( Liu et al. , 2011 ) , our empirical study shows that/IN"
1168	S15_2082	"as implied by the previous sentence . Similarly , in "" "" I was so happy with my new Mac . "" "" ( Next sentences : "" "" For two months ... Then the hard drive failed . "" "" ) , even though the reviewer says how happy <<< he/she >>> was with the laptop , he/she is expressing a negative opinion . For the polarity slot the possible values were : positive , negative , and neutral . Contrary to SE-ABSA14 , the "" "" neutral "" "" label applies only to mildly positive or mildly negative sentiment , thus"
1169	P18_1212	"part of Table 1 is a compact representation of three generic rules ; for instance , Line 1 means that/IN the labels themselves are transitive . Note that/IN during human annotation , if an annotator looks at a pair of events and decides that/IN multiple well-defined relations can exist , <<< he/she >>> labels it vague ; also , when aggregating the labels from multiple annotators , a label will be changed to vague if the annotators disagree with each other . In either case , vague is chosen to be the label when a single well-defined relation cannot be uniquely determined by"
1170	1999_tc_1_6	"a similarity score for each sentence based on the common and contiguous segments as well as the length of the sentences under comparison . The common as well as the different elements of the two sentences that contributed to this score are located and presented to the user so that <<< he/she >>> adapts efficiently the suggested translation . In the simplest case an element corresponds to a wordform . The second approach was based on an "" "" enhanced "" "" string edit distance algorithm . This particular algorithm is based on a dynamic programming framework and on the same sentence representation"
1171	C10_1020	"Magic Johnson is not a member of Magic . The symbol ^ indicates that/IN the person name is neutral ( or irrelevant ) to the teams in the finals . In addition , the symbol + indicates that/IN the person name represents a relative of a member of the team <<< he/she >>> is bipolarized to ; or the name is a misspelling , but it refers to a member of the bipolarized team . This kind of bipolarization is correct under the non-strict evaluation strategy . As shown in Table 1 , the proposed method bipolarizes the important persons in the finals"
1172	W10_4339	"is able to handle or he/she is interested in the determinants . k m is set to "" "" 1 "" "" if the user knows ( or is listed by system ' s recommendations ) that/IN the system can handle determinant m and "" "" 0 "" "" when <<< he/she >>> does not . For example , the state that/IN the determinant m is the potential preference of a user ( but he/she is unaware of that ) is represented by ( k m = 0 , p m = 1 ) . This idea is in contrast to previous research"
1173	W08_1605	"of their interest chosen from the Yahoo ! directory ( dir . yahoo . com ) : examples were "" "" ballet "" "" , "" "" RPGs "" "" and "" "" dog health "" "" . For each user , we created the following 3 questions so that <<< he/she >>> would submit them to the QA system : Q per , related to the user ' s profile , for answering which the personalized version of YourQA would be used ; Q bas , related to the user ' s profile , for which the baseline version of the system"
1174	W14_2514	"dynamics during the course of an interaction correlate with the power differences between its participants . We perform this study on the US presidential debates and show that/IN a candidate ' s power , modeled after their poll scores , affects how often he/she attempts to shift topics and whether <<< he/she >>> succeeds . We ensure the validity of topic shifts by confirming , through a simple but effective method , that/IN the turns that/IN shift topics provide substantive topical content to the interaction . In this paper , we investigate how topic dynamics during the course of an interaction correlate with"
1175	W05_1616	"them ? This is particularly difficult because SkillSum does not know what might have gone wrong during the test : perhaps there was a problem with using the computer or the mouse ; or perhaps the user had difficulties with reading the screen because of poor eyesight ; or perhaps <<< he/she >>> has severe learning difficulties . Knowledge acquisition for SkillSum is difficult because the task of generating adult basic skills summary reports is novel , poorly-understood and complex . See Reiter et al. 2003b ] for a detailed review of KA problems specific to NLG . Like the smoking cessation letters"
1176	2000_amta_workshop_3	"verb , he/she has to use the trail-and-error method to make his/her choice . The third stage is meant to help the learner to keep in mind the new information he/she has obtained at the lesson . After the learner has chosen the synonyms to all the phrasal verbs , <<< he/she >>> is supposed to fill in the table in which his/her work is summarized : Phrasal Verb Synonym Russian equivalent At the fourth stage , the learner is supposed to extend the electronic dictionary by adding to it the phrasal verbs having idiomatic meanings that were absent in the initial dictionary"
1177	2020_emnlp_main_507	"and factuality of the resulting , compressed sentence . Each annotator is paid 50 cents upon completing the HIT ; this pay rate was calibrated to pay roughly $10/hour . After all assignments are completed , we filter low-quality annotators according to two heuristics . An annotator is removed if <<< he/she >>> completes the assignment in under 60 seconds or answers the challenge question incorrectly . We see a substantial increase in agreement for both the grammaticality and factuality studies among the remaining annotators . The absolute agreement scores , as measured by Krippendorff ' s α ( Krippendorff , 1980 )"
1178	2022_findings_acl_285	"the corresponding aspect . The symbol means the predicting sentiment is correct , and the other symbol means the predicting sentiment is wrong . when a person tries to understand a relatively long sentence , he/she first read the entire sentence . Subsequently , after giving a specific aspect , <<< he/she >>> will dynamically select related words based on the previous memory state until he/she fully understands the sentiment polarity of the given aspect . Interestingly , the above phenomenon is consistent with our dynamic re-weighting adapter ' s chosen result . Specifically , as Figure 3 ( b ) shows ,"
1179	W17_5051	"; e. g. *&lt;ien&gt; is assigned both &lt;ihn&gt; ( orthographically correct ) and &lt;ihm&gt; ' him ' ( grammatically correct ) . However , decisions about grammatical and orthographic errors are not consistent . For instance , at one point ( er/sie ) *&lt;seht&gt; ( instead of &lt;sieht&gt; ' ( <<< he/she >>> ) sees ' ) is marked as a grammatical error , at another point as an orthographic one . Two German L2 learner corpora are annotated with more than one target hypothesis : Falko ( Reznicek et al. , 2012 ) and EAGLE ( Boyd , 2010 ) . Falko"
1180	W94_0313	"overall causative situation : that of ( a certain degree of ) control of the situation , and especially over the agent of the underlying caused event , labeled the Causee ( see below ) . In other words , a speaker will use this type of construction only ff <<< he/she >>> believes that/IN the Causee is under control of the Causer . If he/she does not believe this is so , a construction that is neutral to this respect ( in the given language ) will be selected . In SFG , the ( social ) status of the participants involved"
1181	L18_1338	", the users are able to look at the instructions without moving their heads as it would be the case if they had to look at printout versions of the instructions . Additionally , the setup forces the user to direct the Leap Motion at his/her hands to see what <<< he/she >>> is doing . This behavior is necessary for satisfying hand tracking performance . For object tracking , the RGB as well as depth data of the Kinect camera is recorded as a ROS 3 bag on a separate machine running Ubuntu . The models of the objects were created beforehand"
1182	W09_0307	"ODIN allows a variety of search options , including search by language name or code , language family , and by grams and their related concepts ( e. g. , Accusative case ) . Once data is discovered that/IN fits a particular pattern that/IN a user is interested in , <<< he/she >>> can either display the data ( where sufficient citation information exists and where the data is not corrupted by the text-topdf conversion process ) or locate documents from which the data is extracted . Additional search facilities allow users to search across linguistically salient structures ( "" "" constructions """
1183	Y12_1056	"of expressive and social factors of politeness , i. e. mitigating device combined with pre-sequences but also with att . getter in a reverse order . It means that/IN , when a requester used an att . getter ( a specific greeting etc. ) , it is more likely that/IN <<< he/she >>> used an expressive factor , which raised the indirectness of the utterance and decreased its possible negative effect . Similarly , if he/she used indirect expression of perspective -F2 then he/she combined it with politeness features , so the most frequently observed association rules were those indicating the preference of"
1184	W17_5505	"the system prompts the user with a goal , which is a randomly chosen combination of departure place , arrival place and time ( e. g. leave from CMU and go to the airport at 10:30 AM ) . The system also instructs the user to say goodbye if the <<< he/she >>> thinks the goal is achieved or wants to give up . The user begins a conversation with one of the two evaluated systems , with a 50/50 chance of choosing either system ( not visible to the user ) . After the user ' s session is finished , the"
1185	M95_1001	"that pos t ( if an article describes a person leaving and a person starting the same job , there will be two IN_AND_OU T objects ) . The IN_AND_OUT object contains references to the objects for the PERSON and for the ORGANI-ZATION from which the person came ( if <<< he/she >>> is starting a new job ) . The PERSON and ORGANIZATIO N objects are the "" "" template element "" "" objects , which are invariant across scenarios . "" Learning Accurate , Compact , and Interpretable Tree Annotation We present an automatic approach to tree annotation in which basic"
1186	2020_coling_main_91	"a controlling strategy in the form of control questions . For every 6 tweets , we have included one control question with a known answer . Users who have made 3 consecutive mistakes will receive a warning message . If the user still keeps on randomly annotating the tweets , <<< he/she >>> will be blocked after the fourth attempt . Another challenge in the crowdsourcing annotation framework is the preparation of concise annotation instructions that/IN users can read and understand it instantly . However , it is very tough to display long instructions and annotation examples that can fit mobile devices ."
1187	W04_0209	"to the end of the corpus . In this strategy the annotator must read and analyze the sense of each word every time it appears in the corpus . The second annotation method is transversal ( or "" "" lexical "" "" ) ( Kilgarriff , 1998 ) , where <<< he/she >>> annotates wordtype by word-type , all the occurrences of each word in the corpus one by one . With this method , the annotator must read and analyze all the senses of a word only once . We have followed in Cast3LB the transversal process . The main advantage of"
1188	W16_3646	"s low capability of continuously generating appropriate small talk utterances . Introduction Our goal is to build dialogue systems that can obtain information from users . In this paper , we call such systems interview dialogue systems . An example is a dialogue system that interviews a user about what <<< he/she >>> ate and drank . The information obtained by the system is expected to be used for health care . Although interviews have not been as popular as database search and reservations as applications of dialogue systems , they have commercial potential ( Stent et al. , 2006 ) . Interview"
1189	2021_sigdial_1_28	"the current speaker ( Goffman , 1981 ) . In this scenario , the side participants can either be silent while the main speaker talks or can express their reactions towards the main speaker . In the latter case , it is expected that/IN the main speaker will feel that <<< he/she >>> is listened to and understood more and also feel empathy from others . Therefore , in multi-party attentive listening , the system needs to act as a moderator to involve the side participants in the dialogue . To promote the involvement of the side participants , this paper proposes a"
1190	W00_1011	"( i. e. , temporary ) shifting between local expertise levels and accumulated ( i. e. , long term ) shifting between accumulated expertise levels . Local shifting adjusts the expertise level temporarily -by observing the user confirmation ( currently an explicit user confirmation is expected ) which indicates whether <<< he/she >>> understands a certain instruction . The reason for temporary adjustment is because we assume that/IN the user is having trouble understanding only this particular instruction and not the overall solution . The accumulated shifting permauently adjusts the user expertise level depending upon two threshold values : EXPERTLEVEL and NOVICELEVEL ."
1191	W19_7509	"Sanskrit Shabdamitra are : Teachers , Students and Parents . Teachers ' concern is that/IN he/she should be able to convey the entire content to students in all the possible nuances and make them competent in language learning , and prepare them for examinations . Students ' concern is that/IN <<< he/she >>> should learn and understand the content as exhaustively as possible in all nuances and grow in terms of competence and be prepared for examinations . Parents ' concern is that/IN their child should get quality education and obtain competitive results . All these stakeholders and their concerns were considered while"
1192	W14_0618	"Bunescu and Mooney , 2005 ) and parse trees ( Zelenko et al. , 2003 ; Culotta et al. , 2004 ) . In addition , several studies use semisupervised learning . DIPRE ( Brin , 1998 ) tries to find the relationship between the author interest and the book <<< he/she >>> had written . Snowball ( Agichtein and Gravano , 2000 ) uses an architecture that is not very different from DIPRE to determine the relationship between an organization and its location . Meanwhile , Knowitall ( Etzioni at al. , 2005 ) examines relation extraction in heterogeneous domains of text"
1193	W01_1012	" Should I install Netscape 6 ?  "" ) . One can take them on face value or not . In explicitly argumentative , and in loaded topics ( like politics ) it is in the interest of the user to have elements of context in the cognitive modeling <<< he/she >>> is doing of the text contents . Paying due attention to argumentation contributes in two ways : -by giving contexts to answers , helping qualify them for credibility -By answering to questions about opinions and stances : what Levels of Answering : on topic , on question , with justifications"
1194	C88_2097	", they suppress each other , and at last the connection from the most strongly activated B'un : Lt wins . Even if a C unit is not so strongly activated , the C-connector sends these requests . Before a human has read a whole sentence , or even if <<< he/she >>> reads only few words , he/she predicts a complete or fairly large part of parse tree of possible sentence , This is why we adopt this low threshold strategy of requests sending . A--connector : When an A-connector receives a request for connection from the other sub-network ' s Cconnector"
1195	1999_mtsummit_1_86	"creating a user ' s dictionary is not as simple as it may look . First of all , knowledge must be possessed about basic Japanese and English grammar in order to build a useful dictionary . For example , if the user wants to enter a Japanese verb , <<< he/she >>> ought to know the type of verb : There are eight types of verbs in Japanese depending on how they conjugate . Therefore , it is essential for the user to acquire basic Japanese grammar as well as English grammar . It is vital for him/her to know a part"
1196	S15_2082	". Similarly , in "" "" I was so happy with my new Mac . "" "" ( Next sentences : "" "" For two months ... Then the hard drive failed . "" "" ) , even though the reviewer says how happy he/she was with the laptop , <<< he/she >>> is expressing a negative opinion . For the polarity slot the possible values were : positive , negative , and neutral . Contrary to SE-ABSA14 , the "" "" neutral "" "" label applies only to mildly positive or mildly negative sentiment , thus it does not indicate objectivity ("
1197	O04_1013	"by JavaScript . Table 2 gives a list of objects provided by WIS . Data Extraction from HTML Pages WIS adopts WIDL for data elements extraction from HTML pages , but with some enhancements . When a user wants to find something in a HTML page that has changed , <<< he/she >>> first identifies unchanged parts , such as titles , which were associated with the wanted data in past versions . Whenever the unchanged part is found , it is very likely that/IN the desired part of the page is located nearby . The &lt;REGION&gt; element with the SINGLE attribute tells"
1198	L18_1424	"it a bit hard for our system to learn common phrases and utilize patterns for detection . -'I love when I see people using the elevator at the gym . ' The speaker could be mocking the act of people using the elevator at the gym ( by saying that <<< he/she >>> loves to see this act ) , or could me mocking the people , because they use the elevator at a gym ! • Lack of Context : Context may often be necessary to determine a sarcasm target . Consider the sentence : ' Oh , you are such a"
1199	2004_tc_1_13	"a ) Costs of CAT tools -average salaries in developed countries are much higher than in the 10 "" "" new "" "" EU member-countries , therefore prices of CAT tools are seen as very high in Central/Eastern Europe . Even if a translator has heard about CAT tools , <<< he/she >>> cannot afford to buy the licence . b ) Confusion of CAT tools with automatic translating machines . Translators do not believe automatic translation can be of any help and are proud to say that/IN they do everything themselves ( ! ) . II . Why CAT tools cause problems"
1200	W04_1607	"used to distinguish these elements from regular inflectional morphemes since the distinct part of speech information may be needed at a later stage of processing , e. g. , for parsing or machine translation . Each word-like prefix is presented by its stem form : av ) ‫او‬ ( ' <<< he/she >>> ' for the pronominal clitic and bh ) ‫ﺑﻪ‬ ( ' to ' for the baseform of the preposition . This stem form is then followed by the relevant morphosyntactic tags . If the information is not required , as in the case of certain information retrieval applications , the"
1201	Y08_1044	"is one thing and to use it is another . User ' s optional control means that/IN users can control the process of the translation engine as much as they want and can turn off functions which they do n't want . If a user is poor in English , <<< he/she >>> probably wants to focus only on the rewriting of the Korean sentence . If a user knows the translation process well and wants better translation , he/she is going to revise errors from translation engine more deeply . A user can select the level of engine control and the system"
1202	2001_mtsummit_papers_62	"a piece of paper . The Japanese text is announced twice in a minute , and there is a pause in-between . To measure the English capabilities of the Japanese natives , the TOEIC score is used . The examinees must each present an official TOEIC score certificate showing that/IN <<< he/she >>> has officially taken the test within the past six months . The test text is from the SLTA1 test set , which consists of 330 utterances in 23 conversations from a bilingual travel conversation database ( Morimoto et al. , 1994 ) . The SLTA1 test set is open for"
1203	W19_5506	"tend to annotate with rounded numbers ( e. g. -1.0 , -0.5 , 0.0 , 0.5 , 1.0 ) . The Consolidation Mode In consolidation mode , CoSACT is able to smoothly consolidate a previously annotated dataset . At the first time the user tasked with consolidation logs in , <<< he/she >>> is requested to specify the number of required annotations per microblog as well as to set an acceptable deviation . The deviation defines the degree of variation between the annotations of a text . These two values are then used to automatically consolidate all microblogs which fulfill the given criteria"
1204	W12_3626	"2001 ) . Agreement & Disagreement Agreement can act as an affordance to an individual or as a means to establish solidarity between individuals . Likewise disagreement can act as a way of undermining or challenging credibility . However , Agreement Statements that/IN a group member makes to indicate that/IN <<< he/she >>> shares the same view about something another member has said or done . Challenge Credibility Attempts to discredit or raise doubt about another group members qualifications or abilities . Disagreement Statements a group member makes to indicate that he/she does not share the same view about something another member has"
1205	E87_1038	"heuristics for parsing within a particular application . Introduction Computer-based environments for the linguist are conceived as sophisticated workbenches , built on AI workstations around a specific parser , where the linguist can try out his/her ideas about a grammar for a certain natural language . In doing so , <<< he/she >>> can take advantage of rich and easy-to-use graphic interfaces that/IN "" "" know "" "" about linguistics . Of course behind all this lies the idea that/IN cooperation with linguists will provide better results in NLP . To substantiate this assumption it may be recalled that/IN some of the most"
1206	W04_1112	"that/IN the document treats , the writer of the document , we expect , uses N not only many times but in various ways . One of typical way of this kind is that/IN he/she composes quite a few compound words using N and uses these compound words in documents <<< he/she >>> writes . For this reason , we have to focus on the relation among simple words and compound words when pursuing new ATR methods . One of the attempts to make use of this relation has been done by Nakagawa and Mori ( 2003 ) . Their method is based"
1207	O05_3003	". The first contains backchannels and signals for understanding feedback . They are important for keeping a conversation going . The listener has no substantial issues to address , so it is necessary for the listener to acknowledge that/IN the message delivered by the speaker has arrived , and that/IN <<< he/she >>> is listening . The second group contains dialogue acts used to begin a sub-topic or to explain the content of a sub-topic . Both begin_statement and explain make up the essential part of a discussion . They build up the framework of the whole discussion . The third frequent group"
1208	2020_findings_emnlp_224	"conversation . Person A ' s first utterance indicates that/IN he/she is tired of arguing with person B. The tone of the utterance also implies that/IN person B is getting yelled at by person A , which invokes a reaction of irritation in person B. Person B then asks what <<< he/she >>> can do to help and says this while being angry . This again makes person A annoyed and influences him/her to respond with anger . This kind of inferred commonsense knowledge about the reaction , effect , and intent of the speaker and the listener helps in predicting the emotional"
1209	W16_1803	"both the aforementioned approaches , using the generation of lexical variants as the departure point for a distributional semantic analysis . Compositional expressions exhibit systematicity ( Fodor and Lepore , 2002 ) in that if a speaker can comprehend spill the beans as taken literally and drop the peas , <<< he/she >>> will also be able to understand spill the peas and drop the beans , but this does not happen if we read spill the beans as an idiom . The restricted lexical substitutability of a given construction could thus be regarded as a clue of its semantic noncompositionality and idiomatic"
1210	W00_1011	"( i. e. , temporary ) shifting between local expertise levels and accumulated ( i. e. , long term ) shifting between accumulated expertise levels . Local shifting adjusts the expertise level temporarily -by observing the user confirmation ( currently an explicit user confirmation is expected ) which indicates whether <<< he/she >>> understands a certain instruction . The reason for temporary adjustment is because we assume that/IN the user is having trouble understanding only this particular instruction and not the overall solution . The accumulated shifting permauently adjusts the user expertise level depending upon two threshold values : EXPERTLEVEL and NOVICELEVEL ."
1211	W16_3906	"the post , we can judge that/IN a reporter does not mention a post flood in the past . close We can judge from the post that/IN a reporter reports flood in front of him/her . distance far We can judge from the post that/IN a reporter reports flood but <<< he/she >>> is not at the place where he/she experienced flood . misc Except close and far . Table 1 : Labels for the flood disaster events . we focus on the prediction of an event using linguistic features to discuss potential issues in text-based event classification . Vieweg et al. ("
1212	Y18_1016	"synthesize a dataset based on the natural question combination patterns . We exhibit improvement in the performance of the DrQA system when it encounters compound questions which suggests that/IN this approach is vital for real-time human-chatbot interaction . "" When a human interacts with an information retrieval chat bot , <<< he/she >>> can ask multiple questions at the same time . Current question answering systems ca n't handle this scenario effectively . In this paper we propose an approach to identify question spans in a given utterance , by posing this as a sequence labeling problem . The model is trained and"
1213	W11_4610	"also be taken into account . For this , we are planning to use the comparability measure developped by Bo and Gaussier ( 2010 ) . • The joint use of several language resources seems to bias the results as the translators ' behaviour changes in function of the resources <<< he/she >>> has as his/her disposal . It is better to have only one resource per situation of translation , for instance : situation 0 : no resources , situation 1 : assessed terminology only , situation 2 : Internet only . • Translators should be prepared to translate in a situation"
1214	P14_2056	"2013 ) . We modeled the problem of detecting power relationships differently in ( Prabhakaran and Rambow , 2013 ) : we predicted whether a participant in an email thread has a certain type of power or not . However , in that work we did not predict over whom <<< he/she >>> has that power . This may result in noisy features ; consider a thread in which participant X has power over participant Y , who has power over participant Z. By aggregating features over all messages sent by Y , features salient to a subordinate-superior interaction are incorrectly conflated with"
1215	Y12_1056	"-a native speaker . The next pair was spe . perspective and politeness feature ( F2 with F4 ) . In case when the author of English request used more direct utterance through factor F3 , he/she mitigated this directness with expressive factor F4 ( politeness feature ) . When <<< he/she >>> decided to express him/herself in a more indirect way , he/she used a combination with politeness feature ( F2 with F4 ) reinforcing the likelihood of request fulfilment , which is confirmed by the last couple of factors . The analysis results for Slovak requests were partially different . The"
1216	2001_mtsummit_papers_20	"asked to answer another set of TOEIC reading comprehension questions , this time in original English text , in order to measure his command of English . Having answered these two sets of questions , the subject is asked to give his/her impression as to which of the two sets <<< he/she >>> found more comfortable to answer . The scores obtained in the sets are calculated for all the subjects , and together with their impression judgments , the data is processed with respect to their English ability Overview of TOEIC test set The original TOEIC test consists of two main sections"
1217	W19_5506	"red button ) , labeling it as irrelevant ( blue button ) , or the annotator can click on one of the two grey buttons . In this case , the annotator then chooses to label the data as "" "" I do n't know "" "" , in case <<< he/she >>> is unsure about the correct annotation , or as "" "" Not enough information "" "" , in case the uncertainty clearly derives from the presented data itself . This differentiation provides insights about the information content of the data as it becomes clear whether a text might have been"
1218	L16_1249	") was used . This application also supports users , groups and task management and has a multilingual help system . The administrator can assign users to tasks based on their background knowledge ( such as assigning only translation tasks etc. ) . If the user is assigned all tasks <<< he/she >>> can continuously and efficiently work through all processes for given sentence . For word alignment , POS tagging and tree building user input can be performed using only the mouse . Figure 1 shows the user interface for word alignment annotation between an English sentence and the corresponding translated Myanmar"
1219	L16_1032	"to define lexical curriculum for L2 learners . One possible way to address this problem consists in creating vocabulary lists in which each word is located on a proficiency scale . Given the level of a target reader , it is therefore possible to have an estimate of the words <<< he/she >>> is supposed to know . With this in mind , we present a lexical resource , SVALex , aimed not only at learners and teachers of L2 Swedish , but also at lexicographers , L2 test and curriculum developers , as well as researchers within Intelligent Computer-Assisted Language Learning ("
1220	Y15_1007	"desks first if they agreed to participate in our experiment . After they signed the consent forms , they could then read the introduction on the screen and press "" "" I Agree "" "" to start to fill in the questionnaire . Once a subject finished the experiment , <<< he/she >>> would get an allowance of 100 Hong Kong dollars . All the 78 subjects finished the experiment , so we collected 78 responses . Data Cleansing and Result Calculation We firstly checked the responses one by one and filtered out invalid ones . A response is considered invalid if 1"
1221	C88_2097	"and at last the connection from the most strongly activated B'un : Lt wins . Even if a C unit is not so strongly activated , the C-connector sends these requests . Before a human has read a whole sentence , or even if he/she reads only few words , <<< he/she >>> predicts a complete or fairly large part of parse tree of possible sentence , This is why we adopt this low threshold strategy of requests sending . A--connector : When an A-connector receives a request for connection from the other sub-network ' s Cconnector , if the A-connector has not"
1222	C92_2110	"the language , lie/she also defines a reply gem eration procedure . The procedure is called when the corresponding linguistic pattern is matched with an input qucry ( See Figure -3 ) . Repair-4 is tile most dilficult of all repair types for an apl)tieation designer . In Repair-d , <<< he/she >>> must dctine not only a new semantic concept , but al. qo the definitions of slots in the semantic cnncept , the procedures which fill the slots , the relations between the new semantic concept with existing other sentantic coucepts~ various constraiuts anlong concepts , etc. lIowever , relnember that/IN"
1223	2022_bea_1_23	"walk -yaw- : andar to go -ke- : habitualmente usually -la- : negación a modo "" "" normal "" "" indicativo negation -i : el / ella he/she Given this , 5 the goal is that/IN the learner deduces "" "" el/ella no anda caminando habitualmente "" "" "" "" <<< he/she >>> does not usually go for walks "" "" . The challenges of this informal analyzer are many . Among them : how to give enough meaningful translations so that/IN they can match the initial experience of learners , but as well , do not confuse them ; how to deal"
1224	L16_1224	"not know the task . In this study , the focus is on the information transmitted by the teacher . Although we are aware that ' knowing ' learners react differently than naive learners , we argue that/IN for our research questions it is sufficient that/IN the teacher assumes that/IN <<< he/she >>> is explaining the task to a naive learner . In the following , the tasks , the reasons for construing the specific tasks and the setups for collecting the respective data are described . The focus in all tasks was on gathering multimodal information transmitted by the teacher , because"
1225	1994_bcs_1_18	"in text generation . It explained how a variety of languages , a variety of sentence lengths and structures , and a variety of more or less concise wording can be achieved . In a computer assisted MT environment , the user can be given the choice of which realisation <<< he/she >>> considers best . On the other hand , in a fully automatic MT system , more meta-rules should be included that can measure the "" "" degree of expressiveness "" "" of a realisation or also that can give a "" "" measure of distance "" "" between the wanted"
1226	C92_2110	". Suppose that/IN KBP could not interpret a NL query which included an expression , "" "" price is more than $100 , and less than $200 "" "" . The aPl)lieation designer judges that/IN the part of the query mnst be defined as a pattern-concept pair . Then , <<< he/she >>> defines a new pattern-concept pair : [ Definition-1 ] If a pattern sequence is : [ "" "" fiekl-nanm(Field ) , 1 { Field i~typc-of numerical } , ~ more than , number(N1 ) , le~s thmt , number(N2 ) "" "" 1 , do the followings : ( 1"
1227	W07_2301	"the other hand , is determined by the perceptions of the system users . It "" "" results from a perception and a judgment process , in which the perceiving subject ( e. g. a test user of the system ) establishes a relationship between the perceptive event and what <<< he/she >>> expects or desires from the service "" "" . Quality is thus everything that is perceived by the user with respect to what she expects from the system . User factors like attitude , emotions , experience , task/domain knowledge , etc. , will influence the perception of quality ."
1228	2022_udfestbr_1_6	"highlighted in purple ( Figure 2 ) shows some options about how the search results should be displayed . Clicking on it exposes three checkboxes with the following options : POS Tags , Dependency relations , and Features . These options enable the user to choose a few extra data <<< he/she >>> might want to be displayed on the results page . For example , if he/she checked the box "" "" POS tags "" "" , the part-of-speech tags of every token would be displayed in the search results after a "" "" / "" "" character . Visualization Options :"
1229	Y18_1016	"d like to look at varying the attention mechanism in the model , and evaluating how it performs with a larger training set . "" Too Many Questions ? What Can We Do ? : Multiple Question Span Detection When a human interacts with an information retrieval chat bot , <<< he/she >>> can ask multiple questions at the same time . Current question answering systems ca n't handle this scenario effectively . In this paper we propose an approach to identify question spans in a given utterance , by posing this as a sequence labeling problem . The model is trained and"
1230	2021_mmsr_1_2	"al. ( 2007 ) , claiming that/IN annotators are expected to select gestures to be annotated only if they have a communicative function . Following this principle , each annotator looked at the portion of the video in which the hand movements were occurring and depending on the meaning that/IN <<< he/she >>> thought the gesture had in that particular context of utterance , attributed the corresponding semantic function . However , as Yoshioka ( 2008 ) points out gestures can be functionally ambiguous and thus have multiple semantic functions simultaneously . According to Tsui ( 1994 ) , the source of these"
1231	L18_1444	"  topical "" "" friends We denote as topical friends those Twitter accounts in a user ' s followees list representing popular entities ( celebrities , products , locations , events . . . ) . For example , if a user follows @David Lynch , this means that/IN <<< he/she >>> likes his movies , rather than being a genuine friend of the director . There are several clues to identify topical friends in a friendship list : first , topical relationships are mostly not reciprocated , second , popular users have a high in-degree . However , these two clues"
1232	W08_1407	"example of an image and Table 2 contains the corresponding related information . Each participant was asked to familiarize himor herself with the location of the image by analyzing the map and going through all 11 URLs . Then each participant decided on up to 5 different pieces of information <<< he/she >>> would like to know if he/she sees the image or information about something he/she relates with the image . The information we collected in this way is similar to ' information nuggets ' ( Voorhees , 2003 ) . Information nuggets are facts which help us assess automatic summaries by"
1233	W08_2205	"bomb attack → bomb explode "" "" are not adequate , as we do not want H to follow from "" "" The police destroyed the bomb . "" "" or "" "" The bomb attack was thwarted "" "" ) . Rather , when a person reads T , <<< he/she >>> recognizes a complete scenario from multiple bits of evidence ( possibly in multiple sentences ) , and integrates what is read with that scenario . This kind of top-down , expectation-driven process seems essential for creating an overall , coherent representation of text . Although scripts are an old idea"
1234	2009_mtsummit_posters_19	"The following examples illustrate the importance of the back translation , since in these cases only checking the recognition results would not have been enough to detect some errors . The first example of error prone utterances in Table 4 presents the answer of a patient to the question whether <<< he/she >>> has a cough ( "" "" no , I do n't have a cough "" "" ) that is translated as "" "" no , I cough "" "" ; this type of error is easily detectable when comparing the recognition and back-translation outputs ( rows in bold of Table"
1235	Q19_1013	"weight at each level of the model : 1 . Customize on the bias vector : At this level of customization , we look at the general biases the categories have towards the problem . As a concrete example , when classifying the type of message a politician wrote , <<< he/she >>> can be biased towards writing personal messages than policy messages . Instead of using a single bias vector b ( c ) in the logistic regression classifier ( Equation 8 ) , we use additional multiple bias vectors for each category , as shown below . In fact , this"
1236	L18_1691	"physician "" "" user is an interface that offers in the translation point of view the opportunity for the physician to consult the technical term in his or her mother tongue . This user has the opportunity as well to select the source language and the target language in which <<< he/she >>> wants to examine the word and its related definition . For this user category , a direct link with related MeSH 12 terms has also been provided . By clicking on the term , the physician can access to the various information provided directly by the National Library of Medicine"
1237	E91_1033	" office plan expert  "" ( who is assumed to know I-Rule 1 ( 1 ) only ) . Fact ( 5 ) is known to anybody , as it is presupposed by the question . The process is simple for the "" "" local employee ' : Since <<< he/she >>> also knows facts ( 2 ) to ( 4 ) , the first hypothesis ( I-Rule 1 ) provides the missing information . The first hypothesis is identical for the "" "" novice ' , but a series of inferences is needed to prove its adequacy . First , a"
1238	J89_3002	"well as contentious , ag-gressive , and ambitious . Inherently lawyers are adults , have gone to law school , and have passed the bar . They practice law , argue cases , advise clients , and represent them in court . Conversely , if someone has these features , <<< he/she >>> probably is a lawyer . In the classical approach to word meaning , the aim is to find a set of primitives that is much smaller than the set of words in a language and whose elements can be conjoined in representations that are truth-conditionally adequate . In such theories"
1239	2022_udfestbr_1_6	"defined in the UD specifications ) to search for in the uploaded treebank : forms , lemmas , part-of-speech tags ( POS tags ) , dependency relations ( deprels ) and features ( feats ) . In addition , the selector highlighted in green allows the user to choose if <<< he/she >>> wants their search to be made in a case-sensitive or insensitive way . On the other hand , the input field highlighted in orange is the one where the user must enter the values that should be searched in the treebank . The button highlighted in purple shows some options"
1240	W12_5102	incoming words over time . Figure 4 : Evolution of AKI success over time . The x-axis is the number of games ( by segment of 157 games ) . The curve shows the success rate at guessing the proper term that/IN a user has in mind from the clues <<< he/she >>> giving to the system . Performances for WSD The purpose of the evaluation on WSD was to access the impact of the network in the case of WSD when viewing this task as a guessing problem almost identical to the guessing game presented above . A full presentation of various
1241	W15_2118	") , it is the negative particle nem ' not ' which prevents the verbal predicate from determining the clause ' s speech function . As suggested above , the predicate functions by default as a schematic positive declarative clause expressing the occurrence of an event ( meghívta meaning ' <<< he/she >>> invited him/her ' ) . This interpretation cannot be "" "" projected "" "" to the clause level in the context of negation , as the negative particle overrides the default positive polarity associated with the predicate . I assume that nem ' not ' only participates in the D2"
1242	W11_3706	"music selection and how long images and video will stay , among other settings . In Moodstream , however , songs are not played entirely but blended into one another every 30 seconds and , even if the user has control on the multimedia flow through the mood presets , <<< he/she >>> cannot actually set a specific mood and/or activity as a core theme for the audio-visual ambient mix . Sentic Corner , on the contrary , uses sentic computing ( Cambria et al. , 2010b ) , a new paradigm for the affective analysis of text , to automatically extract semantics"
1243	2020_lrec_1_532	"false starts , repetitions and truncated words . Since they are marked in the TEI Guidelines as ' editorially deleted ' , the corresponding tag is del . ( e ) overlap : this phenomenon is present when the speaker conveys ( in a verbal or non-verbal manner ) that/IN <<< he/she >>> is about to finish his/her turn and the co-locutor starts speaking so that/IN there is a slight overlap of utterances . New annotation layer The goal of the novel annotation layer added on top of the PoliModal corpus was to enrich it with an additional mode and therefore a new"
1244	2020_lrec_1_55	"many cases the student did not ask about the specified section , but they asked general questions like "" "" when did he born ? "" "" or "" "" where did she born ? "" "" . Question Types The Zenbat seme-alaba ditu ? / How many children does <<< he/she >>> have ? Table 2 : The most frequent initial words and phrases of the questions of ElkarHizketak . During a manual inspection of the dialogues of the dataset we found that/IN some of the questions are dependent on the dialogue history , that is , it is required coreference resolution"
1245	W14_2710	topics in the en tire debate ( TS IntroImpTurns ) and the time spent on those topics in the entire debate ( TS IntroImpTime ) . Analysis and Results We performed a correlation analysis on the features described in the previous section with respect to each candidate against the power <<< he/she >>> had at the time of the debate ( based on recent poll scores ) . Figure 2 shows the Pearson ' s product correlation between each topical feature and candidate ' s power . Dark bars denote statistically significant ( p &lt; 0.05 ) features . We obtained significant strong
1246	E85_1020	"to the absence of a clear surface indicator for grammatical function assignment , even though , as a rule , it is the Object NP that is questioned , as in 14 . ii Who did the chief say that/IN he would have engaged ? 21 . i What did <<< he/she >>> say that/IN John would have bought at the market ? ii What did John say that/IN he would have bought at the market ? 22 . i Who did Mario intend to upset ? ii Who intended to upset Mario ? 23 . i Which secretary knew the director ?"
1247	W07_1409	"introduced in H are valid . A first example is : 358 . T "" "" Kiesbauer was target of a letter bomb ... "" "" 358 . H "" "" A letter bomb was sent to Kiesbauer . "" "" A person recognizes H as entailed by T because <<< he/she >>> knows the "" "" script "" "" for letter bombing , which includes sending the bomb in the mail . Thus a person could also recognize alternative verbs in 358 . H as valid ( e. g. , "" "" mailed "" "" , "" "" delivered "" "" )"
1248	W10_0723	"asked : 1 . Whether the participant is a resident of the United States ; 2 . Who the participant voted for in the 2008 U. S. presidential election ( Barack Obama , John McCain , other , decline to answer ) ; 3 . Which side of political spectrum <<< he/she >>> identified with for social issues ( liberal , conservative , decline to answer ) ; and 4 . Which side of political spectrum he/she identified with for fiscal/economic issues ( liberal , conservative , decline to answer ) . This information was gathered to allow us to measure variation in"
1249	Y13_1035	"the descriptive words , "" "" Oh ! there ' s water coming out of the smoke alarm . "" "" However , there is not such case . In this case , the speaker seems to be hard to decide whether it is an irony or sarcasm , so <<< he/she >>> tagged them both , which indicates that/IN these two terms are not distinguished in their functions in this example . Evaluating this case with the cases illustrated in 4.2 , it shows that/IN the content of sarcastic tweets are built on what the speaker said , but ironic tweets can"
1250	W14_0210	"uncertainty of information provided by lost blind person , possibility that/IN the blind person got lost much earlier and the navigation instructions for next several segments were corresponding with the reality by coincidence . The fact that/IN the blind person gets lost is little bit stressy for him/her . Therefor <<< he/she >>> may provide illogical answers to some questions , e. g. Q : "" "" Could you provide me with the description of your current position ? "" "" and A : "" "" I would rather go to the start of the track and describe the track from the beginning"
1251	2010_amta_workshop_4	"the second step . The Wikipedia editor could also be used for any additions or final edits on the article ( such as , resolving any unresolved red-links or fixing references ) before submission . The user can preview and submit the contribution to the target language Wikipedia , if <<< he/she >>> is satisfied , and the submissions are executed via the standard Wikipedia API ' s . While the current user interface is tailored for Wikipedia users , it may be re-configured for the requirements of different wiki-communities , as well as for different user exposure to Wikipedia . Linguistic and"
1252	W08_1407	"2 contains the corresponding related information . Each participant was asked to familiarize himor herself with the location of the image by analyzing the map and going through all 11 URLs . Then each participant decided on up to 5 different pieces of information he/she would like to know if <<< he/she >>> sees the image or information about something he/she relates with the image . The information we collected in this way is similar to ' information nuggets ' ( Voorhees , 2003 ) . Information nuggets are facts which help us assess automatic summaries by checking whether the summary contains the"
1253	W00_0703	", it is possible that/IN a patient can perform the first of these steps , but not the second . This is the difference between our ' unconscious ' and ' conscious ' segmentations ( see below ) so-called because , in the latter , the patient is aware that/IN <<< he/she >>> has to find a hidden word . This particular implementation of PbA does not guarantee an output pronunciation . A complete path through the lattice requires that/IN all nodes on that path ( except the first and last ) are linked by at least one arc . Clearly , each"
1254	W13_3306	"že akcie bude stabilizovat , jak se zdá , v příštích několika dní , než/DC opět klesat/V , zablokování více investorů . A further difficult case in CZ is the binding of conditionals with personal pronouns , e. g. if I = kdybych , if you = kdybys , if <<< he/she >>> = kdyby etc. In the following example ( WSJ section 2386 ) , the BASELINE system completely missed to render the personal pronoun ( but still generated the correct conditional connective if-pokud ) , whereas SYSTEM2 outputs the much better if I-kdybych . However , apart from the better connective"
1255	W98_0202	"intuition , but the relevant article itself . In other words , this system allows information retrieval through the use of ambiguous keys . It is not necessary for the user to enter any concrete keywords or titles of articles . He/she simply needs to point to the article which <<< he/she >>> is interested in . The system will find ( almost ) all related articles . We are developing the system in JAVA language which is one of the most popular languages capable of handling visual images on the screen . The system works as follows : 1 . A user"
1256	2020_lrec_1_27	"and increase the chance of the right answer being selected . Each set of options had "" "" Not in candidate "" "" and "" "" Not an entity "" "" in addition to the abstracts of the individual entity candidates ; the worker was to choose the former if <<< he/she >>> could not find any adequate abstract and the latter for an erroneously tagged entity . En-Figure 4 : Annotation interface for coreference resolution tity candidates were provided as a result of an automatic search among the entities in a knowledge base . Besides the main reason for providing "" """
1257	D19_3042	"internet and media . Underneath the news flow , key roles including people and organizations interact with each other and involve in various events over time . With the overwhelmed information , extracting relations between key roles allows users to better understand what a key person is doing and how <<< he/she >>> is related to different news topics . To understand the action of key roles , we provide a semantic level analysis using semantic role labeling ( SRL ) . To measure the trend of news topics , a word vector level analysis is supported using dynamic word embeddings . In"
1258	2020_emnlp_main_279	". The two responses are top one results from greedy search , and are randomly shuffled to hide their sources . The annotators judge which response is better based on informativeness , consistency , and fluency of the responses . If an annotator cannot tell which response is better , <<< he/she >>> is required to label a "" "" tie "" "" . Each annotator individually judges 500 pairs for all combinations of our model and baseline models . In total , each one labels 2 , 500 pairs for one dataset . Fleiss ' kappa ( Fleiss and Cohen , 1973"
1259	C90_3072	"the stem and assigns the set of endings and prompts the user to confirm the resulting set of forms , For example , when classifying the form radionuklidy ( radionuclides ) , first the user deletes the ending -y ( which is one of the plural endings ) . Then <<< he/she >>> selects "" "" noun "" "" as the basic class ; then "" "" masculine inanimate "" "" is the right choice . Then , he/she should select radionuklidu as the right form which can follow the preposition bez ( without ) , and state that/IN radionuklida is not correct"
1260	Y07_1019	"4 : Refining the output texts The system finds a full name is repeated at the second sentence of both output texts . This situation is not preferred by the system . Therefore , the system replaces the repeated name by a reference string , which is this student , <<< he/she >>> , or by the last name of the student . After being refined by Step 4 , the two outputs now becomes : ( 1c ) Pham Thanh ( male ) was born on 24/10/1984 in Ha Bac . He is a student of the class BK20 . ( 1d"
1261	L16_1100	"g. "" "" qui "" "" , "" "" que "" "" , "" "" dont "" "" and "" "" quoi "" "" ) , are unambiguous as they are in English . • First-person ( i. e. speaker reference ) pronouns , and the third-person pronouns "" "" <<< he/she >>> "" "" which are all unambiguous in English . • Possessive adjectives ( "" "" your/their "" "" etc. ) , which in French agree with the noun that follows ( and not the antecedent ) . One could argue for the inclusion of other pronoun forms within some of"
1262	2005_sigdial_1_17	". Task success may best be determined in a laboratory situation where explicit tasks are given to the test subjects , see Möller ( 2005 ) . However , realistic measures of task success have to take into account potential deviations from the scenario by the user , either because <<< he/she >>> did not pay attention to the instructions given in the scenario , because of his/her inattentiveness to the system utterances , or because the task was unresolvable and had to be modified in the course of the dialogue . Modification of the experimental task is considered in most definitions of"
1263	W06_1908	"tokens generated by the query analyzer . If the tokens are presented in the current query , it uses them . Otherwise it gets the token information from the dialogue history . For example , in the arrival time queries user has to specify Train name/no and station/city name where <<< he/she >>> needs to go . If he/she did not mention that information , SQL generation procedure gets the information from the dialogue history . Figure 2 depicts the conversion of natural language query to its SQL query . For the fare related query , SQL generation procedure would be called depending"
1264	Y15_1007	"the last two questions in these section 2s ; ( 2 ) If a participant do not satisfy the above conditions , he/she will not see Section 3s ; ( 3 ) each word stimulus in section 3s has an option which allows the participants to skip it in case <<< he/she >>> does not recognize that word ; ( 4 ) all the questions in the questionnaires must be answered except the ones which allow to be skipped and are explicitly claimed to be skipped ; ( 5 ) we wrote a monitor program to detect and resist spammers automatically ; ("
1265	W19_8102	"few images to a complete story . However , extracting such background knowledge is very difficult , especially with limited data . To alleviate such drawback , it is important to take previous experience of story-writing into account . Imagining when a person starts to tell stories from images , <<< he/she >>> may not understand the implications in those images and fail to write a proper story . However , if he/she had heard others telling stories , he/she may be able to tell a story from the stories of similar image sequences he/she previously heard . Motivated by such process ,"
1266	1991_mtsummit_papers_17	"facts are not within the reach of any rule system . The Finnish-English system features a dictionary of translation equivalents : Finnish words with sets of possible translations ( in some contexts ) . If the user is not satisfied with a given lexical choice in the target text , <<< he/she >>> can point at the word and a window with a list of alternative translations will appear on the screen . If an alternative is pointed at , it will automatically replace the wrong word in the text -even in the right form . The current Finnish-English system has approximately 5000"
1267	E89_1004	"( ( EXIST Y ( STATE Y ) ) ( HAS-EXPERIENCER Y USER ) ) ) NOW ) NOW ) They express that/IN the user knows something that ' has to do ' ( expressed by the meta-predicate RELATED ) with states ( STATE Y ) concerning him/herself and that <<< he/she >>> wants to achieve a state ( STATE X ) . In assumption 1 , ( STATE X ) is in fact specialized for a consultation system as a real world state ( instead of a mental state which is the general assumption in any dialog system ) . This state"
1268	W15_0912	"additional module which detects these repetitions on top of the previous model . Below is an example showing a MWE formed by word repetition handled by this model : • "" "" Onu yavas ¸yavas ¸sakinles ¸tirdi . "" "" lit . ( him/her ) ( slow slow ) ( <<< he/she >>> calmed down ) . ( He/she slowly calmed him/her down ) Experimental Results and Discussions Table 2 gives the precision , recall and F-scores ( based on the number of MWEs ) for the evaluation of the presented models on the introduced datasets . As stated previously , IMST ,"
1269	Y13_1035	"  the play is amazingly good , "" "" the tag "" "" #sarcasm "" "" indicates what the speaker really intend to mean is the opposite . The sarcastic effect is built based on what is said by the tweeter , and the speaker is aware of what <<< he/she >>> has said . On the other hand , the contents of ironic tweets are more about a general event , such as ( 1-a ) to ( 1-e ) . For example , in ( 1-d ) the ironic effect locates in the nature of the contrast between "" """
1270	1995_mtsummit_1_27	"are marketed today leaves any potential user in a state of uncertainty . There never seems to be the right MT system for his/her needs and after the first few hours of using the system , any MT system , the only certainty there is , is the feeling that/IN <<< he/she >>> bought the wrong MT system and spent far too much money for it . This kind of experience made by a large number of real users of MT systems reveals a weakness in the current NLP marketing strategies on the side of the few vendors and points at a misguided"
1271	N13_1088	"annotation is a complex cognitive process . From the videos of the scan paths obtained from the eye-tracking device and from detailed discussion with lexicographers it can be inferred that/IN this cognitive process can be broken down into 3 stages : 1 . When a lexicographer sees a word , <<< he/she >>> makes a hypothesis about the domain and consequently about the correct sense of the word , mentally . In cases of highly polysemous words , the hypothesis may narrow down to multiple senses . We denote the time required for this phase as T hypo . 2 . Next the"
1272	Y13_2005	"online collocation exploration tool allows users to choose from the six mediumsized domain-specific corpora : MWC , EWC , LWC , MAC , EAC , and LAC , and the two largescale general-purpose corpora : BNC and Wikipedia . A user accessing the website can key in a keyword that/IN <<< he/she >>> intends to study and the system will automatically search for words which tend to co-occur with the keyword in the selected databases . The current released version of TechCollo ( i. e. TechCollo 1.0 ) provides searches of verb-noun collocations . The measures of frequency and tradMI , as specified"
1273	2020_coling_main_11	". Then , the annotators were instructed to read an event description , without having access to the emotion label , and to answer the following questions : Most probably , at the time when the event happened , the writer . . . • . . . found that/IN <<< he/she >>> was in control of the situation . ( Control ) • . . . found that/IN the event could not have been changed or influenced by anyone . ( Circumstance ) Each event description from enISEAR was judged by three annotators between the age of 26 and 29 . One"
1274	K19_1001	", for singular sentences this is not the case . create 4 different conditions , based on the gender of the subject and object ( FF , FM , MF , and MM ) . An example of an MF sentence would be The father likes the woman , because <<< he/she >>> . We sample from the set of entity descriptions to create 500 sentences per condition , for both corpus types . Experiment types Phrase contributions In the first type of experiment , we consider the contributions of different words in the input to a later prediction of the model ."
1275	P81_1018	", the student , the writers of the exam , the graders , etc. Each role has some required preconditions . For example , any writer must be a professor at this university . There are also postconditions , such as the fact that/IN if the student passes the qual <<< he/she >>> has fulfilled that requirement for the Ph. D. and will be pleased . This post-condition is an example of a domain-dependent inference rule , which is stored in the semantic network when a situation from the domain is discussed . Finally , we have the rule memory . This is"
1276	W11_4610	"evaluated on the basis of texts translated by several translators . In turn , one has to be cautious that/IN translators do not translate texts from the same domain in different situations of translation . Indeed , if a translator translates a text from domain A in situation 1 , <<< he/she >>> must not translate a text from domain A in situation 2 : there is a risk that/IN the translator re-uses some terms'translations he/she has learnt in the previous situation . A critical point when judging the translation of technical texts is that/IN the judges often lack domain expertise and that/IN"
1277	2022_udfestbr_1_6	"should be displayed . Clicking on it exposes three checkboxes with the following options : POS Tags , Dependency relations , and Features . These options enable the user to choose a few extra data he/she might want to be displayed on the results page . For example , if <<< he/she >>> checked the box "" "" POS tags "" "" , the part-of-speech tags of every token would be displayed in the search results after a "" "" / "" "" character . Visualization Options : Displaying Dependency Relations Note that/IN users can also choose to display dependency relations on the"
1278	W03_2128	"initiations need either confirmation or rejection by the partner who has caused the problem . Thus the pairs of acts are similar to the question-answer pairs . The third type is non-understanding . It can be divided into several sub-types . The partner could not hear the previous turn , <<< he/she >>> finds the information surprising and decides to check it , or he/she did not understand the utterance . There are two linguistic subtypes of this act . The first is open initiation ( formed by some very general words : ah , what ) that do not determine the location"
1279	R13_1065	"a requester used an alerter -a form of addressing , a specific greeting etc. , it is more likely that/IN he/she used an expressive factor , which raised the indirectness of utterance and decreased its possible negative effect . Similarly , if he/she used indirect expression of perspective -F2 then <<< he/she >>> combined it with politeness markers , so the most frequently occurred association rules were those indicating the preference of indirect expression is Slovak language . The results are interesting mainly in terms of differences in the use of politeness factors in English and Slovak language . We consider these findings"
1280	W15_5928	"by the personal pronouns , it is removed from the possible antecedent lists , we are left with "" "" rAmuki "" "" , "" "" gOpiki "" "" 5 ) Reflexive pronouns will be referring the antecedents within the sentence . Example : "" "" tanu "" "" ( <<< he/she >>> ) , "" "" tAmu "" "" ( they ) . Example 15 : ravi : rAmuki Dabbu evaru iccAru ? ( to_Ramu money who gave ) ( Ravi : Who gave the money to Ramu ? ) rAju : gOpi tana Dabbu ataniki ( Gopi his money him )"
1281	1987_tc_1_5	"of AITC ( International Association of Conference Translators ) , stated that/IN there seemed to be a difference of opinion where Mr Hayes had said desktop publishing was not for the translator and Mr Jones said it was . He wished to know how the translator would be compensated if <<< he/she >>> took over the typesetting function . Might there not be a tendency for the publisher to offload the editorial function onto the translator , making him/her responsible for translation over a wide area ? Mr Reisenberger , of Arrow Translations , said the translator should go towards electronic mail and"
1282	P17_4003	"Fu and Liu , 2013 ) to recognize the intention of users . User intention can be either used as clues for response generation or features for domain selection . For example , if a user says : "" "" I want to go to Beijing . "" "" , <<< he/she >>> may want to book an airplane or train ticket or further reserve a hotel room in Beijing . We also design a scheme to filter out the sentences that contain vulgar , obscene or sensitive words . A classifier is trained to automatically identify these sentences with manually collated lexicons"
1283	2020_ecnlp_1_8	"et al. , 2018 ) . The encoder of BERT base contains 12 Transformer layers , with 768 hidden units , and 12 self-attention heads . Next Purchase Prediction The goal of this task is to predict the next item a user is going to purchase given the seed item <<< he/she >>> has just bought . We start with a pre-trained BERT base model , and fine-tune it for our next purchase prediction task . We feed seed item as sentence A , and target item as sentence B. Both item titles are concatenated and truncated to have at most 128 tokens"
1284	E14_3001	"database . Association rules are traditionally used for market basket analysis , in which rules of the type 7 http : //ibmi3 . mf . uni-lj . si/bitola/ { pizza , steak } → { coca cola } are inferred , stating that/IN if somebody buys pizza and steak , <<< he/she >>> is likely to buy coca cola as well . In Bitola ' s discovery step , basic associations are first mined from the co-occurrence patterns of MeSH terms . Subsequently , indirect associations a → c are inferred by combining association rules on the form a → b i and"
1285	W12_1601	"other hand , the backchannel features get the lowest performance , and its combination with the other features is not effective , resulting in degradation of the performance . Next , we conduct the second sub-task of speaker prediction . Predicting the next speaker in a multiparty conversation ( before <<< he/she >>> actually speaks ) is also challenging , and has not been addressed in the previous work ( K. Jokinen et al. , 2011 ) . For this subtask , the prosodic features of the current speaker are not usable because it does not have information suggesting who the turn will"
1286	D19_3030	"Label 1 in Fig. 6 depicts one such answer group , whereas the generated question set is depicted by Label 2 in Fig. 6 . Editing questions with history of edits and Download generated questions and answers : If users are not satisfied with the generated ques- tion answer pairs <<< he/she >>> may edit it . The system stores all version of questions and answers . Users can download the final generated set of questions and answers in JSON or text format at the end . Implementation Details ParaQG 1 comprises the frontend user interface , the backend question generator and a"
1287	2020_lrec_1_701	"is to determine the contextual meaning of the sentences , especially the core constructions of them . In a given context , the first sentence is an ordinary "" "" special question "" "" . The speaker tries to draw listeners ' attention to let them imagine the situation when <<< he/she >>> cannot take care of "" "" her(the people who may be mentioned in the context ) "" "" and consider the accompanying consequence . The second sentence contains a construction "" "" _ ( wait ) + X(replaceable event ) + noun/pronoun + _ ( should be ) + _"
1288	W04_0106	"' ba-6 Furthermore the algorithm cannot deduce that/IN the illative is actually realized as a vowel lengthening + ' n ' : ' kammioon ' vs. ' koskeen ' . hama+saari+en ' the genitive is marked as ' en ' , and in ' edes+autta+ko+on ' ( "" "" may <<< he/she >>> help "" "" ) ' on ' marks the third person singular . Similar examples can be found for English , e. g. , ' ed ' and ' d ' are allomorphs in ' invit+ed ' vs. ' phrase+d ' , and so are ' es ' and '"
1289	W11_4610	"translate texts from the same domain in different situations of translation . Indeed , if a translator translates a text from domain A in situation 1 , he/she must not translate a text from domain A in situation 2 : there is a risk that/IN the translator re-uses some terms'translations <<< he/she >>> has learnt in the previous situation . A critical point when judging the translation of technical texts is that/IN the judges often lack domain expertise and that/IN domain experts are rarely available . One can get round this trouble by choosing specialized texts which already have an existing translation ,"
1290	W17_7552	". Related Work The research paradigm called information diffusion seeks to answer how information spreads in a social network and model how a given piece of information will propagate through a social network -more precisely what a user will do with a particular tweet ( lets say ) , will <<< he/she >>> either retweet it , atmention somebody or broadcast it again to spread it over to a wider audience within his/her reachability in the network . Essentially researchers seek to answer to the following questions : ( i ) which pieces of information or topics are popular and diffuse the most"
1291	J86_1002	"A sample schema can be seen in Figure 7 . In test II , the user had much more freedom , since its purpose was to demonstrate a partiallyordered schema . Here the subject had to solve six sets of simultaneous linear equations with two equations and two unknowns and <<< he/she >>> spoke whatever sentences that seemed appropriate . A sample schema is shown in Figure 8 . Notice that/IN in one case an argument was created . The third test was done to show how well error correction works when the dialogue seems random , creating a totally-unordered schema . To"
1292	W06_1908	". If the tokens are presented in the current query , it uses them . Otherwise it gets the token information from the dialogue history . For example , in the arrival time queries user has to specify Train name/no and station/city name where he/she needs to go . If <<< he/she >>> did not mention that information , SQL generation procedure gets the information from the dialogue history . Figure 2 depicts the conversion of natural language query to its SQL query . For the fare related query , SQL generation procedure would be called depending on the type of train ."
1293	P13_2144	"text written in the discussion by each participant as a vector of 100 dimensions . The vector of each participant contains the topic distribution of the participant , as produced by the LDA model . Subgroup Detection At this point , we have for every discussant the targets towards which <<< he/she >>> expressed explicit opinion and a 100-dimensions vector representing the LDA distribution of the text written by him/her . We use this information to represent the discussion in two representations . In the first representation , each discussant is represented by a vector . For every target identified in steps 3"
1294	2012_amta_wptp_4	"and innovative design . Well known for their words and deeds of Mr. Steve Jobs , the charismatic owner is always attention throughout the world . He died in October 2011 , however . Post-Edited Texts and Scenarios Post-Editor A Scenario : When the post-editor received the source materials , <<< he/she >>> sent them to an acquaintance who converted them to MS Word 2003 format because the post-editor did not own MS Word 2007 or greater . After finished post-editing , the post-editor sent the post-edited target text to the acquaintance to have it converted to . docx format , but this"
1295	W10_1604	"guessed by a topic spotting mechanism , and use them to generate phrases that can be chosen by the end-user to follow the conversation . Since they are interactive tools , the phrases are first displayed on the screen in the end-user ' s native language and , then , <<< he/she >>> selects a phrase to be translated ( by a text-to-speech engine ) in the language in which the conversation is taking place . In our work , the main goal is also investigating new ways to improve MT performance , but instead of greater BLEU or NIST values we are"
1296	Y15_2009	"case of first sentence example , the French sentence "" "" Je ne comprends pas cette phrase , désolé "" "" means "" "" I cannot understand that phrase , I ' m sorry … "" "" . We guess that/IN a crowdsourcing participant translated the French sentence so because <<< he/she >>> did not understand the meaning of a medical term ' temporomandibular dislocation ' . In the second example , French sentence that means "" "" the bank only gives away "" "" was not completed unlike Korean and English sentence . In the third example , Korean sentence means """
1297	W16_4406	"of the test dataset acquired from QALD question dataset . Introduction In this research we focus on generating a sentence which formulates the answer as a natural language sentence and presents it in a more natural form . In particular , if we ask a question to a person , <<< he/she >>> has the ability to answer with a sentence or sentences which has the answer embedded in a context . This form of answering a question is more natural compared to the bare factoid answer delivered by most QA systems . The rest of the paper is structured as follows ."
1298	2007_mtsummit_papers_55	"choosing control level . User ' s optional control means that/IN users can control the process of the translation engine as much as they want to do . If a user is relatively poor in English , he/she may put emphasis on the rewriting of the Korean sentence . If <<< he/she >>> wants to get professional translation quality , he/she is going to revise all the errors from the engine . The level of engine control can be set by the user . For provision of sufficient information to fix the errors generated by the engine , the MT system provides the"
1299	2020_emnlp_main_252	"whether a social media user updates his/her account or not , but with specific context like the one in the document , Wu had already gained much attention and hence people cared about his life . As for the document with a non-conditional pair , one shall feel frightened whenever <<< he/she >>> witnesses a bloody murder , which is unlikely to change with different contexts . Definition 1 indicates that/IN the conditional pairs should not be judged to have causal relationship when an irrelevant context or no context is given . Considering such a property , our task is formulated as follows"
1300	P12_1092	"al. ( 2008 ) found that/IN 10 non-expert annotators can achieve very close inter-annotator agreement with expert raters . To ensure worker quality , we only allowed workers with over 95 % approval rate to work on our task . Furthermore , we discarded all ratings by a worker if <<< he/she >>> entered scores out of the accepted range or missed a rating , signaling lowquality work . We obtained a total of 2,003 word pairs and their sentential contexts . The word pairs consist of 1,712 unique words . Of the 2,003 word pairs , 1328 are noun-noun pairs , 399"
1301	2020_acl_main_72	"analysis , which forces an ad hoc construction of the term dictionary . This situation is rather severe in the real-world tasks because the vocabulary size for an exhaustive search of the texts is vast , and the analyst will go through re-peated trial and error of creating dictionaries until <<< he/she >>> reaches findings . At present , there is a demand for a machine that decreases the cost of the ad hoc dictionary construction . As the dictionary construction can be considered as a type of collecting terms , there is a related research field -set expansion that expands a small"
1302	W97_0110	"requirement for a strong estimate of precision . 0 = 0.8 is the best choice when the training corpus is small . GT Threshold Some problems were also detected which prevent better performance of the system . The cu~ent do-main is a newsgroup , where anyone can post anything which <<< he/she >>> believes is relevant to the newsgroup . It is inevitable that/IN some typographical errors and some abbreviations occur in the articles . And the format of the article sometimes is unpredictable . If we can incorporate into the system a spo]llng checker , and build a database for the commonly"
1303	W19_6301	"known words in each keyword list should represent the knowledge of the learner across different genres and domains . The idea behind this is that/IN if the learner knows a lot of frequent words occurring in the domain of , for example , sports , it is very probable that/IN <<< he/she >>> knows another high-frequency word from this domain . However , if the learner does not know a lot of lowfrequency words from the domain , it is not probable that/IN he/she knows another low-frequency word from this domain . To operationalize this idea , we need to use a combined"
1304	2020_bionlp_1_1	"at-risk patients . Furthermore , with the use of contextual word embeddings ( Scheuerman et al. , 2019 ) , implicit bias measurement techniques can be used as part of the writing process to avoid gendered language when it is not necessary ( e. g. , using singular they vs <<< he/she >>> ) . A Note About Gender . Similar to prior work measuring gender bias ( Chaloner and Maldonado , 2019 ) , we focus on binary gender . However , it is important to note that/IN the results for binary gender do not necessarily generalize to other genders , including"
1305	W14_0210	"the navigator to find the position and orientation of the lost blind person , until he/she gets to the location from which he/she can continue with the track . The dialog system should take into account following findings about the dialog structure . When the blind person get lost , <<< he/she >>> uses information , provided by navigation application for sections that seemed to him/her correct and corresponding with reality , for description of his/her current position , e. g. "" "" I am in the Vaclavska street . "" "" The dialog system should take into account uncertainty of information provided"
1306	W19_5903	"CILK can store these predicted triples in the KB as well after checking their correctness through cross-verification while conversing with other users in some future related conversations by smartly asking them . Note that/IN CILK may not verify its prediction with the same user who asked the question/query q because <<< he/she >>> may not know the answer(s ) for q. However , there is no problem that/IN it acquires the correct answer(s ) of q when it asks q to some other user u in a future related conversation and u answers q. At this point , CILK can incorporate q into"
1307	W10_4339	"retrieval system , the user ' s goal may not be the extraction of price information but to make a decision on candidate restaurants based on the retrieved information . This work focuses on how to assist a user who is using the system for his/her decision making , when <<< he/she >>> does not have enough knowledge about the target domain . In such a situation , users are often unaware of not only what kind of information the system can provide but also their own preference or factors that/IN they should emphasize . The system , too , has little knowledge"
1308	Y07_1056	NO TWO LANGUAGES ) ( SOME AND NOT EVERY STUDENT ) nom KNOW What ( 7 ) basically means is that/IN there are no ( two ) languages which are known by some but not by all students and not that/IN for every student there are two languages such that <<< he/she >>> knows them . Thus in this representation the use of the nominative case extension is essential . Analysis In this paper I want to apply the SCT basically to some reflexive pronouns in Japanese and discuss some of these applications in the context of similar pronouns in Polish . It
1309	2022_udfestbr_1_6	"be displayed on the results page or not . Note that/IN the whole search input is organized in a way that/IN it forms a sentence ( from left to right ) . This was done this way to improve usability and to decrease the user ' s learning curve while <<< he/she >>> is learning how to use the tool . Complex Searches Users can also build complex search patterns with the use of the logical conditions AND , OR , and NOT . The logical AND and the logical OR are represented by new rows in the search input , while the"
1310	N18_1115	"provides a significant boost to the performance of the CARNN models . Upon comparison with the baseline systems , CARNN models tend to perform better on instances which require the system to remember specific information through a long dialog history . In Figure 5 , the user already mentioned that/IN <<< he/she >>> wants to find a "" "" cheap "" "" restaurant , but the GMN and QRN seem to "" "" forget "" "" this information . We speculate that/IN due Figure 5 : Sample dialog from our system compared to the baselines . Only CARNN ' s predicted action takes"
1311	Y08_1044	"much as they want and can turn off functions which they do n't want . If a user is poor in English , he/she probably wants to focus only on the rewriting of the Korean sentence . If a user knows the translation process well and wants better translation , <<< he/she >>> is going to revise errors from translation engine more deeply . A user can select the level of engine control and the system provides only such items that/IN a user has selected . Provision of full information means that/IN our MT system provides full information that is related to the"
1312	D19_3022	", Czech , Danish , Dutch , English , Estonian , Finnish , French , German , Greek , Hungarian , Italian , Macedonian , Polish , Portuguese , Quechuan , Romanian , Russian , Serbian , Serbo-Crotian , Spanish , Swedish , Turkish and Vietnamese word gelemeyenlerden "" "" <<< he/she >>> is one of the folks who can not come "" "" encodes sentence-level information ) . 3 Features : Models , Layers and Epochs We support the following classifier architectures implemented by AllenNLP : BiaffineDependen-cyParser ( Dozat and Manning , 2016 ) , CrfTagger ( Sutton et al. , 2007"
1313	W11_3405	"correct the errors in a focused way . For example , a validator can check and correct all the error in "" "" less fre-quent "" "" category first and then start correcting "" "" ambiguous cases "" "" . It also helps validator to decide the amount of energy <<< he/she >>> needs to spend . For example , correcting "" "" ambiguous cases "" "" would require more time compared to other categories . This could be because the validator might look for sentence or sometimes discourse level information to resolve the ambiguity . He/she could also contact peers or an"
1314	W14_2623	"Consider a situation where a human reader needs to annotate two documents with sentiment . Assume that/IN the first document is linear subjective -with ten sentences , all of them positive . In case of this document , when he/she reads a couple of sentences with the same polarity , <<< he/she >>> begins to assume that/IN the next sentence will have the same sentiment and hence , skips through it . We refer to this behavior as anticipation . Now , let the second document be an oscillating subjective document with ten sentences , the first three positive , the next four"
1315	2021_law_1_12	"in such a case , we separate it just like in Figure 3 . Person Singular Plural 1 ögrenci-∅-yim ögrenci-∅-yiz ' I am a student ' ' we are students ' 2 ögrenci-∅-sin ögrenci-∅-siniz ' you are a student ' ' you are students ' 3 ögrenci-∅-∅ ögrenci-∅-(ler ) ' <<< he/she >>> is a student ' ' they are students ' Table 1 : Turkish present tense copular paradigm One solution to solve this issue might be introducing empty nodes and categories into our UD representation . However , our team judged that/IN it would be too unorthodox for the current form"
1316	Y09_1026	"as the input for the summarization for general purpose , a statement such as "" "" Are diesel engines harmful to the environment ? "" "" is given for the summarization for the information credibility . In other words , we assume that/IN a user enters a statement , and <<< he/she >>> would like to verify its credibility , such as a query in information retrieval . Therefore , finding a set of documents relevant to the given statement is involved in the process of the summarization for the information credibility . In general , there are roughly two types of techniques"
1317	2022_udfestbr_1_6	"experienced . UDConcord does not suffer from this , because it is a web application accessible through the web . To make queries with Interrogatório , the user must learn a query language that is similar to Python code . Again , if the user is unfamiliar with Python , <<< he/she >>> might experience some confusion in the process of learning the language . To avoid this possibility during the usage of UDConcord , we implemented the query feature with the use of a form . That is , to make queries with UDConcord , users do not need to learn a"
1318	W15_1812	"in Iceland ) and discuss the linguistic properties and cross-language portability of Talebob . We conclude in section 7 with some remarks on Talebob ( and interactive language learning tools in general ) as an approach to screening large populations of pupils . A note for the reader : Pronouns <<< he/she >>> are used randomly for the generic pupil and teacher . Example phrases are quoted in Danish and ( being highly idiomatic ) translated only when strictly necessary . Talebob as a CALL tool Talebob is a tool for computer-assisted language learning ( CALL ) , and it can be seen"
1319	I17_2054	"source of the corpus is very crucial to determine the quality of corpus . The dialogue data in a specific domain in real life is often combined with commercial secrets as well as with peoples ' private information . For example , when a person books ticket through phone , <<< he/she >>> has to offer private information . So it is hard to obtain such data from a website or by some free methods . That is why there is a little corresponding corpus of dialogue in particular domains . Audio data Audio to text Processing Annotation Analysis Dataset Raw data While"
1320	N04_1028	"to learn to speak a language and mod-ern approaches to foreign language teaching try to mimic its characteristics . If the student cannot be present in the country the language is spoken in , then the student should be put into a series of situations imitating the linguistic experience that/IN <<< he/she >>> would have in the target country . Thus , most current language teaching methods , following the Communicative Approach ( Littlewood , 1981 ) have focused on creating exercises where the student is forced to use language quickly in realistic situations and thus to learn from the situation itself as"
1321	W19_7805	"from somebody ) , anticipate -předpokládat and predict -předpovídat , which share the verbs expect , suppose , believe , očekávat , čekat and others . While these verbs share valency frames across usages and interpretations , they are used in non-synonymous contexts -expecting ( that someone does something which <<< he/she >>> should do or is planned to do ) is not the same as predicting/forecasting ( that something happens ) and that is in turn not the same as anticipating ( that something I believe happens actually happens ) . However , in this case no hierarchy could be determined among"
1322	2022_eamt_1_20	"translations of the offensive language in this shows the impact a missing punctuation mark has on the translation . The three systems translated the first part as ' I gave up thanking ' . They , therefore , do not deliver the original meaning where the writer intended to say <<< he/she >>> is giving up trying to keep the pages , and that/IN the word ' thanks ' is used in a sarcastic way to express his/her frustration . Negation Negation can lead to critical errors when reversed from negative to positive or vice versa ; through e. g. dropping or reversing"
1323	W19_4447	"into one of hard , difficult , and tough as opposed to the source word hard in hard luck . One example translation made by a participant is "" "" The reason why a person ' s life is tough might because he/she was lazy when he/she was young or <<< he/she >>> had a bad luck "" "" . In such cases , the learning effect cannot be correctly evaluated . We seek to find the best example sentences for word sets where the words are confusing for learners . Hence regarding the suggested example sentences , the example sentences were extracted"
1324	2020_coling_main_350	", 2020 ) . We therefore make explicit that/IN throughout the paper , when talking about speakers ' gender , we refer to their accepted linguistic expression of gender rather than their gender identity . Focusing on the two language pairs of our interest , 2,294 different speakers described via <<< he/she >>> pronouns 3 are represented in both en-it and en-fr . Their male/female 4 distribution is unbalanced , as shown in Table 1 , which presents the number of talks , as well as the total number of segments and the corresponding hours of speech . ST Systems For our experiments"
1325	W12_4805	"The second sentence , with the original intention "" "" It usually takes four business days to deliver the goods , "" "" does not follow any basic English structures . The author is assumed to have completely failed to put the words in the right order , even though <<< he/she >>> was successful in choosing the right words "" "" delivery of goods "" "" and "" "" four business days . "" "" These types of errors are extremely difficult to detect or correct by conventional ESL error correction systems . It is because they involve global structures of the"
1326	W09_3929	"the instructions and take your time to plan the directions you want to give to your partner . Phase 2 : Directing the follower In this phase your partner will be placed into the world in the start position . Your monitor will show his/her view of the world as <<< he/she >>> moves around . He/she has no knowledge of the tasks , and has not received a map . You have to direct him/her through speech in order to complete the tasks . The objective is to complete all 5 tasks , but the order does not matter . The tasks"
1327	P97_1072	") holding between the descriptions and their anchors ( Clark , 1977 ; Sidner , 1979 ; Heim , 1982 ; Carter , 1987 ; Fraurud , 1990 ; Chinchor and Sundheim , 1995 ; Strand , 1997 ) . A speaker is licensed in using a bridging DD when <<< he/she >>> can assume that/IN the commonsense knowledge required to identify the relation is shared by the listener ( Hawkins , 1978 ; Clark and Marshall , 1981 ; Prince , 1981 ) . This reliance on shared knowledge means that/IN , in general , a system could only resolve bridging references"
1328	W02_0112	"will replace them ( e. g. Methods of logical programming , Methods of functional programming , Systems modelling , Formal languages ) . Therefore , a person who has completed this curriculum is an information scientist who has additionally studied linguistic and computational linguistic subjects to such an extent that/IN <<< he/she >>> will have a systematic picture of the tasks of natural language processing and will be able to solve these tasks in co-operation with linguists . Problems The modules of CL and LT contain a number of common subjects that have also to be taught jointly to the students majoring in"
1329	P18_1140	"might be helpful to separate them . Start over is active when the user chooses to restart the task in the middile of the conversation . The system is designed to give the user an option to start over after several turns . If the user takes this offer , <<< he/she >>> might have negative sentiment . Textual features We also noticed that/IN the semantic content of the utterance was relevant to sentiment . So we used the entire dataset as a corpus and created a tf-idf vector for each utterance as textual features . Classification results The sentiment classifier was trained"
1330	L18_1450	"recording , we grouped the chunks derived from a particular phrase together , and presented them in relation with their source phrase . That way the speaker has the chance to read the phrase as a whole , and then to read the individual chunks in the same style as <<< he/she >>> read the chunk within the whole phrase . The first aPP voice was recorded by a non-professional Taiwanese male speaker with a very typical and strong Mandarin accent in English . In order to test the "" "" worst-case scenario "" "" , we deliberately did not use a professional"
1331	W12_0515	"by that condition and how many of these sentences are relevant ( similar enough to at least one catchphrase , as defined in Section 4 ) . At the same time the user can inspect manually other sentences matched by the condition , and refine the condition accordingly . When <<< he/she >>> is satisfied with one condition , they can add and test more conditions for the rule , and see other examples , to narrow down the number of cases matched by the rule and improve the precision while at the same time trying to include as many cases as possible"
1332	W97_1301	"finding the relation ( LINK ) holding between the bridging description and its anchor ( Clark , 1977 ; Sidner , 1979 ; Helm , 1982 ; Carter , 1987 ; Fraurud , 1990 ; Strand , 1997 ) . A speaker is licensed to use a bridging DD when <<< he/she >>> can assume that/IN the common-sense knowledge required to identify the relation is shared by the listener ( Hawkins , 1978 ; Clark and Marshall , 1981 ; Prince , 1981 ) . This reliance on commonsense knowledge means that/IN , in general , a system could only resolve bridging references"
1333	W03_2128	"the problem . Thus the pairs of acts are similar to the question-answer pairs . The third type is non-understanding . It can be divided into several sub-types . The partner could not hear the previous turn , he/she finds the information surprising and decides to check it , or <<< he/she >>> did not understand the utterance . There are two linguistic subtypes of this act . The first is open initiation ( formed by some very general words : ah , what ) that do not determine the location of the problem . The typical response is repeating of information ."
1334	W17_7558	"' competence refers to various kinds of competence . Automated essay scoring , for instance , assesses an author ' s writing competence or capabilities by analyzing the author ' s text . An author ' s competence can also refer to competence or expertise in a specific topic that/IN <<< he/she >>> demonstrates by , for example , his/her written argumentation in a chat discussing the topic . An author ' s competence can also be related to the author ' s competence in performing a specific task ( e. g. classifying galaxy images ) and the author ' s written text"
1335	W14_0210	"In order to put the participant into the "" "" recovery from lost "" "" situation , the navigation instructions were intentionally modified to represent a mistake in the track description ( a realistic mistake ) , which caused that/IN the participant get lost . When the participant realized that/IN <<< he/she >>> is lost , a navigator from assistance center was called and they tried to find out the location of blind person and navigate him/her to the end of the track . Navigator was seated in an office without visual contact to lost blind person . He knew all three routes"
1336	C04_1182	"repeating the misread word or by beginning the sentence over again . In some cases the child catches his/her error before finishing the word and thus creating a partial word , however , since it is a conscious act by the child the word is marked as a repetition assuming <<< he/she >>> did repeat it to self correct . Other important factors to be tracked by the recognizer are over-articulations ( OA ) , hesitations ( HS ) , non-speech segments ( NS ) and background noises ( BN ) . An over-articulation is considered to be a deliberate sounding out of"
1337	W17_6504	"contain any component that could justify quantifiablity of accent . What do we want to convey when we say that/IN somebody has a slight Essex accent ? Ob-viously , not that/IN the pronunciation of this person s l i g h t l y s h o w s that/IN <<< he/she >>> is from Essex . Rather , we mean that/IN , first , his/her pronunciation of English words ( a ) is typical for people from Essex , and second , is s l i g h t l y d i f f e r e n t from the"
1338	2022_naacl_main_227	"defined as final golden references . For the sake of self-improvement , we employ a self-study mechanism that allows annotators to learn from their mistakes if they submit an incorrect reference . Concretely , if an annotator submits a reference that is not included in the final golden references , <<< he/she >>> has to modify his/her submission into a correct one . Moreover , the annotator can also make complaints if he/she insists that/IN his/her submission is correct . We find that/IN the self-study and making-complaints mechanisms can trigger very helpful discussions . To improve annotation efficiency , we have developed a"
1339	2021_findings_acl_110	", most contents ( A ) in WIKIBIO usually cannot be directly extracted as substrings from the document ( D ) . Besides , the contents usually has some related information that should be modified at the same time . For example , if somebody is a pianist , then <<< he/she >>> may have received a piano award instead of a guitar award . Therefore , WIKIBIO satisfies the goal of our proposed task : making minimal changes to the original document to make it fit the changed answer ( A ) . 4 Select-Mask-Generate ( SMG ) Method for Controllable Text"
1340	1994_tc_1_4	"so , the tool considers either wordforms only or surface linguistic data ( lemmas and tags ) in order to search for similar sentences and identify their common parts . The parts of the database and input sentences that are different are computed and displayed to the user so that <<< he/she >>> knows where to intervene in the proposed translation . In addition , the system computes a similarity score between the compared sentences , based on the importance of the differences between them . The similarity score is externally configurable in that/IN it can accept a minimum value for the similarity"
1341	W19_7509	"wherein Sanskrit teacher uses this digital aid . Here , the data is presented in the interface , lesson by lesson . In this interface , the teacher chooses a school curriculum board ( CBSE , ICSE , State Board , etc. ) ; followed by a class to which <<< he/she >>> wants to teach ; followed by a lesson/chapter . Once he/she clicks on a chapter , all the words from that chapter appear in the order in which they appeared in the textbook . While teaching , teacher can simply click on any of the word from the list and"
1342	W02_1407	", expresses the key concept of a domain that/IN the document treats , the writer of the document must be using N not only frequently but also in various ways . For instance , he/she composes quite a few compound nouns using N and uses these compound nouns in documents <<< he/she >>> writes . Thus , we focus on the relation among single-nouns and compound nouns in pursuing new ATR methods . The first attempt to make use of this relation has been done by ( Nakagawa & Mori 98 ) through the number of distinct single-nouns that come to the left"
1343	2007_mtsummit_papers_55	"internet protocol packet from the input side link to the output end link . Korean-English Translator Korean-English Translator Too long sentence . Please make it short . Target Sentence Correction The user can get more improved English sentences through the source sentence modification and engine error correction . However , <<< he/she >>> still could not satisfy the translation quality . One of the main reasons is that/IN our paper MT system is pattern-based system . The system generates target sentences mainly based on pattern resources such as sentence patterns , verbal patterns , noun patterns and etc. When the wrong patterns are"
1344	L16_1077	"strong eye-mind hypothesis by Just and Carpenter ( 1980 ) , according to which , "" "" there is no appreciable lag between what is fixated and what is processed "" "" ( Just and Carpenter , 1980 ) . That is , when a subject looks at something , <<< he/she >>> also processes it cognitively . The hypothesis also states that/IN the amount of time the subject spends on processing the particular object is equal to the amount of time his/her gaze stays fixated on this object . A series of studies on eye tracking during reading were conducted by Rayner"
1345	P15_2056	"Subtopic Candidates from Query Log In web search , users usually add additional words to clarify the underlying intents of a query ( Hu et al. , 2012 ) . For example , if the ambiguous query ' jaguar ' does not satisfy a user ' s information need , <<< he/she >>> may submit ' jaguar sport car ' as an expanded query to specify the subtopic . Therefore , for a given query q , we collect its reformulations with additional words from query log as query subtopic candidates , e. g. , we collect { ' jaguar sports car '"
1346	1999_mtsummit_1_86	"but we must make sure that/IN we use it as a part of our work . The author recommends that/IN MME should appoint one person who is responsible for MT and updates the system constantly . He/she must report regularly how they are utilised within the company . Also , <<< he/she >>> should give an induction for employees who wish to use the MT system . The induction includes training them to master the writing rules . In this way , MT systems can find their place in a company . Otherwise , the novelty will soon wear off and only few"
1347	W17_3808	"' paths . This index file is what we use to display the correction to the player . The final result is displayed to the player as a correction to his/her mistakes . Experimentation The player explores the terrain searching for a sound source , once he/she finds it ; <<< he/she >>> will be able to control the listening with a keyboard key . When the player finishes listening to the French dictation , a new panel appears , giving him a place to write the sentence heard ( Figure 2 ) . After writing the sentence heard and by clicking on"
1348	W10_0403	"Take our current focus-grammaticality of word completion . If the form of the content produced is ungrammatical or difficult to read from the perspective of a reader , you risk having the reader misunderstand the writer ' s intent . However , from the writer ' s perspective , unless <<< he/she >>> is perceptive of the interpretation problems with his/her potential readers , there is no incentive to produce content as such ; the writer can only produce content based on his/her previous linguistic experience . One may argue that/IN corpus statistics may best capture human linguistic behaviour . For example ,"
1349	2022_lnls_1_5	"these beneficial effects on model quality , supervision in the form of explanations is in line with E-SNLI Premise A 2-3 year old blond child is kneeling on a couch . Hypothesis The child has brown hair . Gold label Contradiction Free-text The child would not have brown hair if <<< he/she >>> was blond . COS-E Questions What would not be true about a basketball if it had a hole in it but it did not lose its general shape ? Answer options a ) punctured , b ) full of air , c ) round Gold label b ) Free-text Air"
1350	W10_0723	"2008 U. S. presidential election ( Barack Obama , John McCain , other , decline to answer ) ; 3 . Which side of political spectrum he/she identified with for social issues ( liberal , conservative , decline to answer ) ; and 4 . Which side of political spectrum <<< he/she >>> identified with for fiscal/economic issues ( liberal , conservative , decline to answer ) . This information was gathered to allow us to measure variation in bias perception as it relates to the stance of the annotator , e. g. , whether people who view themselves as liberal perceive more"
1351	S17_2047	"comment length . If the question is long and the answer is short , it may be less relevant . The comment is written by the author of the question If the answer is posted by the same user who posted the question and it is relevant , why has <<< he/she >>> asked the question in the first place ? Answer rank in the thread . Earlier answers could be posted by users who visit the forum more often , and they may have read more similar questions and answers . Moreover , discussion in the forum tends to diverge from the"
1352	D13_1104	"and preposition "" "" to "" "" are "" "" hidden "" "" in the affixes of case and person , i. e. : Mektep(NN = a school ) + ke ( dative case = to school ) bar(VB , imperative = go ) + dy ( past tense = <<< he/she >>> went ) + m ( 1st person = I went ) As the example shows , inflected affix chains contain important information that is not always present in the context , hence a tagset should be designed in a way to capture this information to the extent possible . For"
1353	P98_2163	"our common sense that/IN one person cannot move along two different paths at the same time , which implys that/IN the two movements by a person must be sequential . This prototype is extended so as to cover such situations as "" "" someone goes to somewhere , and then <<< he/she >>> does something/becomes something/stays there "" "" or "" "" someone does something/become something/stays somewhere , and then he/she goes to elsewhere . "" "" They are expressed by vertical and horizontal extensions of the prototype in Table 2 . The Cause Circum Contrast Circum movements involved in these situations are"
1354	1999_mtsummit_1_32	"  , "" "" proof "" "" ) , ( ' ' personal computer "" "" , ' ' instrument "" "" ) , ( ' ' plan "" "" , ' ' communication system "" "" ) When the appropriate pattern in the transfer knowledge is missing , <<< he/she >>> writes new patterns and examples . Example of new pattern and examples : ( X "" "" in accordance with "" "" Y ) = &gt; Y ' "" "" ni taiou suru "" "" X ' ( ( ' ' sensor "" "" , "" "" purpose "" """
1355	D17_2013	". Messages containing at least one same word would be candidates which is then ranked by BM25 ( Robertson et al. , 2009 ) . When the user received a message and is composing a response , the user manually specifies an emotion ( e. g. , Anger ) that/IN <<< he/she >>> wants to convey in the message , and the following two settings for generating responses . [ Baseline ] : Given the message that/IN the user received , MoodSwipe first retrieves its most similar message ( by Lucene ) from the database , and then returns the response of that"
1356	2020_acl_main_116	") . PowerDensity , Resistance , WorkingTemperature : These slots are generally filled by mentions of type VALUE , i. e. , a numerical value plus a unit . Our annotation guidelines give examples for relevant units and describe special cases . This enables any materials scientist , even if <<< he/she >>> is not an expert on SOFCs , to easily understand and apply our annotation guidelines . Difficult cases . We also found sentences that include enumerations of experimental settings such as in the following example : "" "" It can be seen that/IN the electrode polarization resistances in air are"
1357	Y07_1009	"of the sentence . The type of the verb may change depending on the order of the complements . 1 In the context such as where the causer is a film director and the causee an actor , we can imagine that/IN the film director makes the actor/actress act as <<< he/she >>> directs . In this case , we could consider the verb ' to drop ' as a self-controllable action and the causative verb otisaseru would also take the type c 6 r c 3 r c 1 r s 1 . However , to keep our analysis within the scope"
1358	P18_4013	"size=10 in Figure 1 ) . Extension Users can write their own custom modules on all three layers , and user-defined layers can be integrated into the system easily . For example , if a user wants to define a custom character sequence layer with a specific neural structure , <<< he/she >>> only needs to implement the part between input character sequence indexes to sequence representations . All the other networks structures can be used and controlled through the configuration file . A README file is given on this . Evaluation 3.1 Settings To evaluate the performance of our toolkit , we"
1359	W15_2118	". As proposed above , this dimension is concerned with the clause ' s illocutionary force and polarity . The neutral positive declarative clause in ( 19 ) has the function of stating the occurrence of an invitational event , and the same meaning is construed schematically by meghívta ' <<< he/she >>> invited him/her ' . Hence , the verbal predicate makes a key contribution to the clause not only in D1 ( by evoking an invitational event ) but also in D2 ( by being crucial to the clause ' s speech function as a positive statement expressing that event '"
1360	I08_3009	", we can expect a very high level of user-friendliness . However , if there is any lack of user-friendliness in SriShell Primo , when the user tries to input a Sinhala word by entering the character sequence that/IN he/she thinks most appropriate to represent a specific Sinhala word , <<< he/she >>> will not get that Sinhala word as a candidate in the SriShell Primo menu . At that point the user will have to correct the input character sequence in order to get the correct Sinhala word . As there may be other reasons for not having the userintended Sinhala word"
1361	W18_0310	"because the voiced obstruent is adjacent to the left high tone . In ( 12b ) , the voiced obstruent is further away , so the high tone spreads , but only across one syllable before it is blocked . ( 11 ) a. /á-na-tsukur-a/ → [ ànàtsùkǔrâ ] ' <<< he/she >>> is taking ' b. /á-na-á-tsukur-a/ → [ ànàátsúkúrâ ] ' he/she is taking them ' c. /á-na-á-demurir-a/ → [ ànàádèmùrǐrâ ] ' he/she is scolding them ' ( 12 ) a. /a-ká-ézeker-a/ → [ àkàézèkěrâ ] ' he/she has thatched with/for ' b. /a-ká-súrubik-a/ → [ àkàsúrúbǐk-â ] ' he/she"
1362	W19_5506	"tend to annotate with rounded numbers ( e. g. -1.0 , -0.5 , 0.0 , 0.5 , 1.0 ) . The Consolidation Mode In consolidation mode , CoSACT is able to smoothly consolidate a previously annotated dataset . At the first time the user tasked with consolidation logs in , <<< he/she >>> is requested to specify the number of required annotations per microblog as well as to set an acceptable deviation . The deviation defines the degree of variation between the annotations of a text . These two values are then used to automatically consolidate all microblogs which fulfill the given criteria"
1363	W01_1202	"e. g. http : //www . altavista . com ) in World Wide Web ( WWW ) . However , in a real sense of information retrieval rather than document retrieval , a user still needs to find an answer phrase within the vast amount of the retrieved documents although <<< he/she >>> can promptly find the relevant documents by using these engines . Recently , several QA systems are proposed to avoid the unnecessary answer finding efforts ( Ferret et al. , 1999 ; Hull , 1999 ; Moldovan et al. 1999 ; Prager et al. , 1999 ; Srihari and Li"
1364	W98_1009	"of the input word . This is most often needed by information retrieval systems . The main menu of the system is shown in Figure 2 . From the main menu the user can select one of the four options . In case the user selects the first option , <<< he/she >>> will get all the information about the input word as seen in Figure 3 . When the user selects the second option , the menus in Figures 4 , 5 , 6 , and 7 appear in sequence to select the appropriate codes . Examples &the output in these cases"
1365	L18_1361	"online consent form must be signed when parents log in for the first time onto the Baby Explorer . Unlike traditional terms of agreement clauses , this one is aimed at protecting the user ' s rights and privacy and making sure that/IN the user understands the terms of contract <<< he/she >>> is agreeing on . This last step is verified by an online quiz while the user is going through the consent form . Since parents own the data , they have the option to update , erase , remove them or ask for their portability from the secured cloud ,"
1366	2021_naacl_main_49	") to one ( dialogue ) , multiple ( conversation ) , or massive ( broadcast ) . Receivers may be known or unknown . For instance , in any given dialogue or conversation , the speaker knows the identity of the specific and fixed target or group to whom <<< he/she >>> is talking . However , when it comes to broadcasting or highly public spaces , receivers are often "" "" imagined "" "" by the speaker ( Litt , 2012 ) and are potentially numerous and invisible . This imagined audience is a speaker ' s mental conceptualization of the"
1367	N19_4012	"( Luong et al. , 2015 ) . When placing the mouse tracker ( step 4 ) on any token in the headlines or highlights , related content in the article will be labeled with red color . If the author would like to use one of the suggestions , <<< he/she >>> can click on the gray button ( step 5 ) to add it to the text-area on the left hand side and edit it . Finally , he/she can click "" "" Post "" "" ( step 6 ) to post the article . The Proposed Model As shown in"
1368	N15_1102	of transport should agree with the translations of someone and the preceding 1 you need to tell the locals to evacuate the area so we can secure the area to make sure no one gets hurt auxiliary verb can ( yqdr ) . The correct form would be yqlk ( <<< he/she >>> transports you ) instead of nqlk ( we transport you ) . Such translation errors are confusing to users as they affect the understanding of basic semantic roles . They tend to occur when translating English infinitival constructions ( to+verb ) or other syntactic constructions where English base verb forms
1369	W14_5119	"test is conducted by creating a small parse in combination of noun and verb . Learner uses their knowledge of already learnt nouns and verbs Figure 5 shows the test in small phrase-level . This section which is an evaluation to test the memory of the learner on how much <<< he/she >>> remembers the experiment 1 and 2 . A set of 10 combinations of verbs and nouns are displayed for the learner , where he/she is required to listen to the four options of the audio and select the right audio combination of noun and verb . Retention after 2 days"
1370	2021_acl_long_384	" ) . Method R-1 R-2 R-L R-1 R-2 R- Occasionally , the abstractive module produces new inferred information that is not mentioned explicitly in the conversation . In one instance , the model generated that/IN the patient has a history of heart disease conditioned on a cluster that/IN men-tioned <<< he/she >>> takes digoxin , a popular medicine for heart disease . Similarly , the model can infer past medical history of  "" high cholesterol "" "" upon seeing pravastatin usage . Such inferences can also lead to incorrect summaries , e. g. , when a doctor explained that/IN a patient"
1371	L16_1626	"evaluated scores , we performed an experiment with 8 participants . Each participant was asked to rate each pair by assigning a score of similarity and a score of relatedness , both ranging from 1 to 4 . In particular , for each pair , the participant was asked if <<< he/she >>> agreed with the following statements ( 1 = totally disagree , 4 = totally agree ) : • I consider the two emojis equivalent ( similarity ) • I can imagine a situation in which I would use the two emojis together ( relatedness ) All the participants were familiar"
1372	J86_2002	"  Canadian "" "" , the student may be referred to as a "" "" FOREIGN "" "" student . Similarly , if the value stored for a student under the attribute NATIONALITY is a member of the set ( U. K. U. S. A. Australia ... ) , <<< he/she >>> may be designated as coming from an English-speaking country . Finally , if the student has value U. K. , France , etc. for NATIONALITY , he/she may be considered to be from Europe . Distinguishing values correspond to key values that naturally divide the values in a domain into"
1373	W11_0610	" , ADOS :  "" unusual "" "" ) and sometimes contradictory ( ADOS : "" "" appropriate "" "" vs. ADI-R : "" "" inappropriate "" "" ; ADOS : "" "" phrases ... they could not have heard "" "" vs. SCQ : "" "" phrases that/IN <<< he/she >>> has heard other people use "" "" ) . In what is one of the only studies focused specifically on unusual word use in ASD , Volden and Lord ( 1991 ) transcribed two 10-minute speech samples from the ADOS for 20 school-aged , highfunctioning children with autism and 20"
1374	Y12_1024	". Approach Accuracy Dictionary CSP Detection The system has been plugged into OpenOffice and it highlights CSPs in an OpenOffice document . Figure 1 shows a sample screenshot of the system detecting CSP in the sentence "" "" And then kinuha niya "" "" ( translated as : And then <<< he/she >>> took it ) . Figure 1 : Sample screenshot of the system showing English to Tagalog CSP After studying the Philippine component of the International Corpus of English ( Bautista et al. , 2004 ) , we experimented on a dictionary-based approach to detect CSPs using LanguageTool ( Naber ,"
1375	L18_1361	"their favorite recordings or pictures , share them with relatives or friends and set privacy settings on their data with regards to their use for research . The pictures taken from the child ' s device will inform parents and researchers on his/her perception of his local environment ( people <<< he/she >>> is looking at , location , activities such as playing , eating , napping ... ) . • Dashboard : The dashboard displays an overview of the metrics about the child ' s linguistic development . It allows parents to follow his/her cognitive development on a daily basis through analytics"
1376	2020_readi_1_4	"start the audio recording . When the system has acquired the entire file ( case ( a ) ) or the student has finished to read the text ( case ( b ) ) , the teacher listens to the recorded audio by clicking on the play button . If <<< he/she >>> is satisfied with it , he/she lets start the audio processing by clicking on the button "" "" TRASCRIVI "" "" ( "" "" Transcribe "" "" ) to launch the ASR algorithms and perform the automatic assessment . Otherwise , the reading can be recorded again . Visualization of"
1377	2020_acl_main_652	"introduces the topic . Having this information , he must ask free text questions . The first question of every dialogue must be the title of the topic that appears in the title of the Stack Exchange thread . The domain expert has access to the whole answer passage and <<< he/she >>> answers the query by selecting a span of text from it . In order to make the dialogue look more natural , the domain expert has the opportunity to edit the answer , but note that/IN if he does so the answer will not match the content of the text"
1378	2021_eacl_main_227	"user to assign a label to a test user . Unsupervised Classification For unsupervised classification , we used the same unsupervised classification method described earlier , which we used to prepare the training set . Specifically , we constructed a feature vector for each test user based on the accounts <<< he/she >>> retweeted , computed its similarity to all users in the training set , projected all the users in the training along with the test user into a lower dimensional space using UMAP , and lastly clustered the users using mean shift . We then labeled the test user using the"
1379	C14_1172	"to a feminine pronoun . This possibility of referring to both the gender introduces more errors . In Hindi , most of the pronouns such as "" "" vaha "" "" ( he/she/it ) , "" "" usa "" "" ( he/she/it ) , "" "" unhone "" "" ( <<< he/she >>> honorofic ) and "" "" khuda "" "" ( himself ) etc. , do not have gender distinction and can be used to refer to antecedents of both feminine and masculine . PNG agreement adds more challenges in anaphora resolution , due to which the system gives more false positives"
1380	2007_mtsummit_papers_55	"all possible combination among target words and searches the each expression from our own English paper database . Finally it displays the search result with frequency information as in Figure 7 . From this information , the user gets a hint on how to correct the awkward expression , so <<< he/she >>> can change the wrong expression ' a necessity is occurring ' into the right expression ' necessity has been raised . ' Sometimes natural expressions may look unnatural to a user . In this case , for the user ' s confidence , the system can provide example sentences with"
1381	R19_1079	"feature provides functionality for requesting a "" "" hint "" "" . The hint provides the user with a correct related word , which is taken from the knowledge base . After reading the hint , the learner is free to input the hint word or any other word that/IN <<< he/she >>> deems fitting . Whenever a learner uses that feature , there is an underlying mechanism that stores the presented hint in the database . Within both interfaces , learners can see their points and badges gained and for the Telegram chatbot , they can also access a leaderboard . Chatbot"
1382	W12_3626	", Agreement Statements that/IN a group member makes to indicate that/IN he/she shares the same view about something another member has said or done . Challenge Credibility Attempts to discredit or raise doubt about another group members qualifications or abilities . Disagreement Statements a group member makes to indicate that <<< he/she >>> does not share the same view about something another member has said or done . Disrespect Inappropriate statements that/IN a group member makes to insult another member of the group . Offer Gratitude A sincere expression of thanks that/IN one group member makes to another . Relationship Conflict Personal ,"
1383	W00_1012	"1 presents the reasoning scheme that departs from the wish of a subject to do D. The scheme also illustrates one of the general principles referred to above . It explains the order the steps are taken by the reasoning agent : if a subject is in a state where <<< he/she >>> wishes to do D , then he/she checks first the harmful/useful aspects of D , and after this proceeds to aspects connected with possible punishments . The prerequisite for triggering this reasoning procedure is w(pleas ) &gt; w(unpleas ) , which is based on the following assumption : if a"
1384	W16_5404	"character formatting of these objects may reflect the intuition of the lecturer about his/her talk , because these objects are selected Place license statement here for the camera-ready version , see Section ? ? of the instructions for preparing a manuscript . and located by him/herself . For example , <<< he/she >>> will use either a larger point font or a bold style font , to represent an important part of his/her talk . The second is that/IN this approach naturally introduces multi-level granularity of conceptual units because our using method proposed by ( Hayama et al. , 2008 ) extracts relationship"
1385	P15_4001	"annotator should also select a hint from the drop down list in hint column to indicate how the error phoneme can be corrected . Annotations As depicted in Figure 2 , annotations can be conducted easily and directly with this tool . If an annotator finds a pronunciation error , <<< he/she >>> can simply check the checkbox at line : phoneme and column : error type from the table , and provide extra information of the actually spoken phoneme and also hints of how to pronounce correctly . To make the annotation more convenient and efficient , several functions are built in"
1386	W19_8714	". They have helped to meet some of the translator ' s needs , though the technical specialists have not kept pace with the practical and expanding requirements in language mediation . One major technical and linguistic hurdle involves words outside the vocabulary of the translator or the lexical database <<< he/she >>> consults , especially Multi-Word Expressions ( Compound Words ) in technical subjects . A further problem lies in the multiplicity of renditions of a term in the target language . This paper discusses a proactive approach following the successful extraction and application of sizable bilingual Multi-Word Expressions ( Compound Words"
1387	C98_2158	"each row to the second . The prototypes are boldfaced and they are extended to the other boxes with some directions and constraints . For example , the Temporal Sequence relation has a prototype structure , which is roughly read as "" "" someone goes to somewhere , and then <<< he/she >>> goes ( from there ) to elsewhere . "" "" This expresses our common sense that/IN one person cannot move along two different paths at the same time , which implys that/IN the two movements by a person must be sequential . This prototype is extended so as to cover"
1388	C04_1182	"repeating the misread word or by beginning the sentence over again . In some cases the child catches his/her error before finishing the word and thus creating a partial word , however , since it is a conscious act by the child the word is marked as a repetition assuming <<< he/she >>> did repeat it to self correct . Other important factors to be tracked by the recognizer are over-articulations ( OA ) , hesitations ( HS ) , non-speech segments ( NS ) and background noises ( BN ) . An over-articulation is considered to be a deliberate sounding out of"
1389	J86_2002	"which evidence is lacking ; ( iii ) the maxim of relation -be relevant ; ( iv ) the maxim of manner -avoid obscurity , avoid ambiguity , be brief , be orderly . In the case of query Q2 above , the responder would only enumerate positive instances if <<< he/she >>> could not say the more informative All of them . Thus , $2-1 might mislead a user , who would expect the system to respond with $2-2 if it were true . Of course , the Gricean maxims must be viewed as being phrased relative to the responder ' s"
1390	W11_3105	"Related Information : Some features are dependent on the type of question . Accommodation Related These features specify the choice of accommodation of the user . Sometime user specifies the special range of accommodation like government guesthouse , holiday home etc. Hotel Type : User specifies the type of hotel <<< he/she >>> wants to stay . Extraction Rule : Noun Phrase contains keyword like "" "" Private Hotels "" "" , "" "" Government Hotel "" "" , and "" "" Guest House "" "" , "" "" Hostel "" "" etc Hotel Specification : User specifies the criteria that should be"
1391	2019_gwc_1_30	"The validator either confirms each element or rejects elements one by one with feedback . In the case of a lexical gap , she can accept as it is or suggest word(s ) for the synset where she denies it as a gap . When the translator receives feedback , <<< he/she >>> accommodates comments if she agrees with the validator . Alternatively , she can reject the evaluation with comments . Upon reaching an agreement between the translator and the validator , we believe this process produce target language synset with high-quality at the end . Tasks for translators and validators are"
1392	2020_rocling_1_25	"French NSs would filter out the other superfluous frequencies . However , when it comes to a L2 learner learning French , the learner would perceive a sound through hearing all the frequencies that are contained in a sound . When it comes to perceiving a sound in L2 , <<< he/she >>> is likely not to recognize the sound /i/ at the frequency recognized by a French person but is likely to recognize the sound /i/ at a frequency dictated by his/her mother tongue such as between 300-600 Hz because his/her perception is likely to be mediated through his/her mother tongue ,"
1393	1999_mtsummit_1_32	"he/she writes the knowledge about it . He/She checks the source language structure , the target language structure , and the translated target sentence . If the source language structure is wrong , he/she checks the current pattern in transfer knowledge . When the selection of transfer knowledge fails , <<< he/she >>> adds an example into the appropriate pattern . Example of adding examples : ( X "" "" as "" "" Y ) =&gt; Y ' "" "" tosite no "" "" X ' ( ( "" "" RS6000 "" "" , "" "" ews "" "" ) , ( """
1394	C92_1051	"a piece of bread-OBJ give-PAST ' Because Bill was hungry , I gave him a piece of bread . ' This sentence is unacceptable or at most marginal because of discrepancy of the agent of action and the experiencer . In Japanese , even if we consider an observer , <<< he/she >>> could not be the agent of action when the experience , for instances being hungry or being sad , is not observable from outsiders [ 6 ] . However if we replace verb "" "" sui-ta "" "" with ira-suffixed one , "" "" suite-its "" "" , shown in"
1395	P11_4009	technology relative polarity scoring has been assigned to each n-n word pair combination . Randomly n ( presently 2-4 ) words have been chosen from the source SentiWordNet synsets along with their images as retrieved by Google API . Each player is then asked to select one of them that <<< he/she >>> likes most . The relative score is calculated and stored in the corresponding log table . Word Positivity Negativity Q3 The player is asked for any positive word in his/her mind . This technique helps to increase the coverage of existing SentiWordNet . The word is then added to the
1396	D17_1055	"are inspired by several observations . First , people are interested in not only the overall sentiment or topic distribution of the documents but also the sentiments towards specific topics . For example , a person may be happy with that/IN the disaster passed away , but at the meanwhile <<< he/she >>> may be unsatisfied with the post-disaster relief . Second , most existing sentiment-topic models ignore the temporal evolution of topics and sentiment in a time-variant data corpus such as the Twitter stream . There are strong evidences which indicate that/IN people ' s attitudes toward a disaster will gradually change"
1397	E99_1002	"than a matter of degree , and ( b ) that/IN at most one referent can be in focus at any time . Actually the ICONOCLAST system refines the second limitation by grouping the referents according to whether they are competitors for the same pronoun : people compete for ' <<< he/she >>> ' ( or ' him/her ' etc. ) , and physical objects for ' it ' . With this refinement , the relevant constraint is that/IN at most one referent in each group can be in focus at any time . However , in the example , the three referents"
1398	C18_1155	"set . We also adapt their system to our problem setting for a comparison . Why Prepositional Paraphrasing of Noun Compounds ? Uncovering a hidden relation or ellipsis from a construct is an important problem in NLP . For instance , when a customer searches for 15 inch laptop , <<< he/she >>> is actually searching for a laptop with 15-inch display . But , when a customer searches for 30 inch tyres , he/she is actually searching for tyres with 60 inch diameter . Noun Compounds are one of the many such constructs where the relation is hidden . For example ,"
1399	L18_1044	", the sentiment annotation is saved in the database . • Type 2 : The abstract does not contain a conclusion section , as is the case for the abstract shown in Figure 5 . In this case , we asked the annotators to click on the first sentence where <<< he/she >>> thinks that/IN the conclusion starts . This clicked sentence and all subsequent ones were then listed and a sentiment could be selected for each one . With the developed interface , it was possible to achieve an inter-annotator agreement of 80 % . Note : Before computation of the agreement"
1400	D14_1211	"TokenRato ) and tokens per message ( TokenPerMsg ) , all calculated over M . THR META : This feature set includes the average number of recipients ( AvgRecipients ) and To recipients ( AvgToRecipients ) in emails sent by p , the percentage of emails p received in which <<< he/she >>> was in the To list ( InToList % ) , boolean features denoting whether p added or removed people when responding to a message ( AddPerson and RemovePerson ) , average number of replies received per message sent by p ( ReplyRate ) and average number of replies received from"
1401	W10_0306	"the process scattering . ( capability Breaking experiencer Lamp ) ( capability Breaking experiencer Glass ) ( capability Scattering experiencer Toy ) Reaction to events is expressed using the if-else axiom of SUMO , for example , if a child character causes an accident ( a damage ) , then <<< he/she >>> will feel anxiety . Emotions are represented using the attribute relation . Swartjes ( 2006 ) noted that/IN organizing actions and events , and causally relating them , is an essential step in story generation . Independent of the story plot , the causes and effects of character actions can"
1402	2022_findings_naacl_126	"IAC-V1 and IAC-V2 ) and Twitter datasets show that/IN our proposed DC-Net achieves state-of-the-art performance on sarcasm recognition . Our code is released to support research 1 . Introduction Sarcasm is a complicated linguistic phenomenon . Intuitively , it means that/IN one says something positive on surface form , while <<< he/she >>> actually expresses negative , vice versa ( Liu , 2012 ; Merrison , 2008 ) . Take the sentence "" "" Final exam is the best gift on my birthday "" "" as an example , the literal sentiment on surface is positive , which is reflected by the explicit"
1403	D18_1145	"  , reflects the extent to which people ascribe the cause or control of events in their lives to themselves or the external factors ( Rotter , 1966 ) . The language indicating internal control in a given situation signals intentionality ( the author is describing an action that/IN <<< he/she >>> intended ) and awareness ( the author is aware of the effect of the action ) . Internal control is often associated with causing a given event or doing something that is clearly a choice . The external control language , on the other hand , is characterized by lack"
1404	W11_3706	"the sentics detected belong to the lower part of the Hourglass , the multimedia contents searched will have an affective valence opposite to the emotional charge detected , as Sentic Corner aims to restore the positive emotional equilibrium of the user , e. g. , if the user is angry <<< he/she >>> might want to calm down . The Exhibit IUI module , eventually , visualizes the contents of the Sesame database exploiting the multi-faceted categorization paradigm . Faceted classification allows the assignment of multiple categories to an object , enabling classifications to be ordered in multiple ways , rather than in"
1405	W19_8102	"it is important to take previous experience of story-writing into account . Imagining when a person starts to tell stories from images , he/she may not understand the implications in those images and fail to write a proper story . However , if he/she had heard others telling stories , <<< he/she >>> may be able to tell a story from the stories of similar image sequences he/she previously heard . Motivated by such process , we propose to utilize the large corpus as an inventory and improve the visual storytelling model by including stories from similar image sequences in corpus as input"
1406	W98_0202	"by using natural language processing technology , and it utilizes heuristics on the features of the network news assuming it to be a kind of conversational text . Typical usage of this system would be : the user is very busy and cannot keep up with the recent news , <<< he/she >>> gets some free time and takes a look at today ' s news articles which are extracted from a huge set of unread articles . He/she finds one very interesting article and wants to read all the articles pertaining to that topic , enough to understand whole discussion . So"
1407	2021_eacl_main_207	"privacy for models trained on transformed data . Given a trained machine learning model and its confidence score on a datapoint , MIA infers whether the datapoint was part of the model ' s training data . In order to conduct MIA , an attacker trains a shadow model that/IN <<< he/she >>> expects to mimic the target model under attack . Once trained , the shadow model ' s confidence scores on the datapoints members of its training set and other non-member datapoints are used to train the binary attack model . Given a datapoint , the attacker then extracts a similar"
1408	2020_readi_1_4	"the system has acquired the entire file ( case ( a ) ) or the student has finished to read the text ( case ( b ) ) , the teacher listens to the recorded audio by clicking on the play button . If he/she is satisfied with it , <<< he/she >>> lets start the audio processing by clicking on the button "" "" TRASCRIVI "" "" ( "" "" Transcribe "" "" ) to launch the ASR algorithms and perform the automatic assessment . Otherwise , the reading can be recorded again . Visualization of a student ' s assessment At"
1409	W00_1012	"1 presents the reasoning scheme that departs from the wish of a subject to do D. The scheme also illustrates one of the general principles referred to above . It explains the order the steps are taken by the reasoning agent : if a subject is in a state where <<< he/she >>> wishes to do D , then he/she checks first the harmful/useful aspects of D , and after this proceeds to aspects connected with possible punishments . The prerequisite for triggering this reasoning procedure is w(pleas ) &gt; w(unpleas ) , which is based on the following assumption : if a"
1410	W12_0515	"the knowledge base . In this way the creation , testing and integration of the rule in the system is done at the same time . During knowledge acquisition this same interaction is repeated : the user looks at examples , creates conditions , tests them on the dataset until <<< he/she >>> is satisfied , and then commits the rule to the knowledge base , following the RDR approach . When creating a rule the user is guided both by particular examples shown by the system , and by statistics computed on the large dataset . Some rules of our KB are"
1411	C18_1234	"but rise slightly , as the z-score cutoff goes up to 2.5 . This is because a larger z-score cutoff means that/IN the winning author must have a significantly higher plausibility value compared to all the other authors . Therefore , an author is announced for a document only if <<< he/she >>> is the clear winner compared to all the others . The recall values reduce somewhat with increasing zscore cutoff and this is because the authors who do not stand out very strongly compared to the other authors do not get attributed to the documents . Conclusion In the above discussion"
1412	2020_cl_2_4	"the possession by third person singular for feminine and masculine , Turkish uses only one marker for the possession by the third person singular . ( 6 ) Ayakkabı-(s)ı-(n)ı shoe-POSS.3SG-ACC giy-ecek wear-3SG . FUT ' He/she will wear his/her shoes . ' An example sentence in Turkish with "" "" <<< he/she >>> will wear his/her shoes "" "" is given above . As can be seen , possession implicitly acts as an agreement feature ( i. e. , possession of the object and person of the verb must match ) . Tense . We use the simplified universal definition of tense ,"
1413	W09_4203	"titles , lists , tables , etc. BwanaNet offers this filter . The CQP edition of the BNC allows the user to search in titles and keywords . Query outcome When an electronic corpus is queried , the user can select different types of query outcomes depending on the result <<< he/she >>> desires . These query outcomes may be a list of monolingual or aligned concordances , a list of words , a list of synonyms , a list of collocates or a list of clusters . List of concordances Concordances are the contexts in which the query probe appears . Most"
1414	2009_eamt_1_17	"tense and past tense forms of the verb . North Sámi , on the other hand only has one form to express both present and past tense . The tense distinction is made by means of the main verb following the negation verb as in ii boa de ( ' <<< he/she >>> does not come ' ) and ii boahtán ( ' he/she did not come ' ) . ii ii+V+IV+Neg+Ind+Sg3 ij ij+V+Neg+Prs+Sg3 ittjij ij+V+Neg+Prt+Sg3 Both for generation and analysis that means that/IN one has to find a possibility to account for the ' missing ' tag in North Sámi . '"
1415	W15_0813	"if-then relation . Furthermore , if there are some cases that do not meet an if-then relation , we do not believe that/IN its former negation or latter negation is contradictory . For example , we can easily think of counterexamples for "" "" if going to a spa , <<< he/she >>> wears a summer kimono , "" "" and thus we do not believe that/IN the event pair ⟨going to a spa , not wearing a summer kimono⟩ is contradictory . Multistage Inference Contradictions There are contradictory event pairs based on multistage inferences . For example , ⟨I made a supper"
1416	P83_1005	"this one parameter ~ retty much covers the contextual features ontague-Kaplan had in mind . Suppose also that/IN a dog t otherwise unknown to our speaker and hls/her audience , just walked by the front porch , on which our protagonists are sitting . When the speaker utters the sentence <<< he/she >>> is exploiting a situation in which bo{h speaker and audience saw a lone dog stroll by ; he/she is not describing either that/IN particular recent situation or such a sltuation-type -there may have been many such ; the two of them often sit out on that porch , the neighborhood"
1417	2020_emnlp_main_209	"dataset ( Webster et al. , 2018 ) is a coreference resolution dataset of human-annotated ambiguous pronoun-name examples from English Wikipedia . Prates et al. ( 2018 ) constructed a translation challenge dataset of simple sentences in gender-neutral languages such as Hungarian and Yoruba and English target sentences such as <<< he/she >>> is an engineer to estimate gender biases in machine translation . Both these challenge datasets focus on gender hallucinations , not unambiguous errors induced by gender bias . Some of our examples share similarities with the English WinoGender schema ( Rudinger et al. , 2018 ) . Consider the following"
1418	2020_cl_2_4	"beneficial in a multilingual setup for several reasons . The first reason is that/IN the information encoded by the word order and function words in English is encoded at the morphological , subword level information in many other languages . Consider the Turkish word katılamayanlardan , which means "" "" <<< he/she >>> is one of the folks who can not participate . "" "" In morphologically complex languages like Turkish , single tokens might already communicate a lot of information such as event , its participants , tense , person , number , polarity . In analytic languages , this information would"
1419	Y10_1021	". In our approach , a total of five final suffixes such as -__ -lako , -__ -tako , -ㄴ___ -ntanunkwun are used as Quotative to weaken the value of terms which are the attitude of other people , not the author . Such suffixes can be translated as ' <<< he/she >>> said that~ ' in English . ( 8 The negative term ___ mipongchayk ' temporary expedient ' gets the base value -1 by matching with the polarity dictionary and the value is changed to -0.5 affected by the Quotative ending -__ -lako . In our approach , we equally reduce"
1420	2020_gamnlp_1_12	". class of task 3-2 ( ∈ { human , werewolf } ) human Table 7 : Examples of Reference Dataset of Task 2 , Task 3-1 and Task 3-2 ( Underlined part of the utterance is quoted by the player who utters , indicating exactly in that part that/IN <<< he/she >>> declares the results of divination / medium , or just his/her guesses . ) one detects that/IN the utterance does not include any of those vocabularies . Classifier As the classifier , this paper applies CNN and SVM to all of the four tasks : task 1 , task 2"
1421	W18_0701	"addition to using proper names , speakers can refer to one another using pronouns , and several early systems implemented simple rules for resolving I and you ( e. g. , ( Jain et al. , 2004 ) ) . In multilogue , it is also possible that/IN third-person pronouns <<< he/she >>> refer to conversation participants ; we are not aware of systems addressing this . Other exophoric reference This phenomenon was already prominent in TRAINS ( see above ) , but largely handled by using semantic type constraints . It also occurs in Maptask dialogue and similar task-solving interactions like the"
1422	2022_acl_long_78	"operator is frequently used to retrieve the header cells of superlatives , as shown in Table 1 . To keep sentences as natural as they are , we do not encourage unnecessary sentence modification during the conversion . If an annotator finds multiple ways to question regarding a sentence , <<< he/she >>> only needs to choose one way that/IN best reflects the overall meaning . Regular Inspections and the Final Review We ask the two most experienced annotators to perform regular inspections and the final review . ( 1 ) In the labeling process , they regularly sample annotations ( about 10"
1423	D14_1143	"states that/IN weights of edges and labels of nodes should be consistent . We explain how the cluster assumption relates to our task . In our application , each node corresponds to a word . Labels of the nodes in a graph denote the vocabulary of a learner . If <<< he/she >>> knows a word , the label of the node corresponding to the word is +1 ; if not , the label is −1 . The cluster assumption in our application is that/IN the heavier the edge , the higher the similarity between users familiar with the two words . In"
1424	C14_1117	"the guessers guess the right phrase exactly , the game is closed automatically . In addition , if the drawer judges the guess as having the same meaning as the assigned concept ( for example , "" "" Cabbie "" "" for "" "" Taxi Driver "" "" ) , <<< he/she >>> can end the round by marking the guess as correct , rewarding the guesser with game points . If the timer runs out before a correct guess happens , then the game times out . Figure 1 shows the UI during the progress of a game ( the given text"
1425	Y18_1085	"s knowledge . That is , alethic modality does not have to be a type of epistemic modality . Given above , I argue that/IN yuánlái2 is the most likely candidate of alethic modality expression in natural language for three reasons . First , when the speaker uses yuánlái2 , <<< he/she >>> expresses his/her attitude toward a proposition , that is , the proposition is a new finding . Hence , yuánlái2 can be considered as expressing a type of modality . Second , yuánlái2 is evidential in that it indicates the existence of evidence although it does not specify what type"
1426	W14_0208	"interest ( PoI ) on the route based on two factors : proximity and visibility . The dialogue policy is to introduce the PoI , query the QA server for snippets and push the first snippet to the user . The user is encouraged to ask for more information if <<< he/she >>> is interested . Sys : In front of you , about 200 meters away is Old College . It has a grey dome on top . Sys : Situated on South Bridge , Old College is . . . Sys : Ask for more information if interested . Priority assignment"
1427	2012_amta_wptp_4	"for the words and deeds of Mr. Steve Jobs , the charismatic CEO , who was always earning the attention of the world . However , he passed away in October of 2011 . Post-Editor B Scenario : After getting the source materials , the post-editor verified via email that/IN <<< he/she >>> had received all of the source materials and would follow all of the specifications . The post-editor owns and uses MS Word 2007 and Acrobat Reader . The post-editor completed and returned the post-edited text on March , 24 2012 . He/she also included the source text and machine translation"
1428	W15_0120	", if distributional semantics is to claim psycholinguistic validity , it should account for the fact that/IN many of the words/phrases we use repeatedly ( and therefore might build a distribution for ) refer to individuals . Consider the name of the city a speaker lives in , the company <<< he/she >>> works for , phrases such as my boss , Kim ' s dog , etc. Second , having access to distributional individuals may help us solve problems that/IN DS has been struggling with . For instance , we may make progress on the topic of antonymy , as ( static"
1429	C14_1172	"anaphora resolution . As it is seen from the results table we have obtained lesser scores for Bengali . In Bengali third person pronouns such as "" "" ami "" "" ( I ) , "" "" túmi/tui/apni "" "" ( you ) , "" "" se/tini "" "" ( <<< he/she >>> ) , "" "" amra "" "" ( we ) , "" "" tara/tnara "" "" ( they ) , do not have masculine , feminine distinction , but there is animacy distinction . And also the verb has no gender agreement . This adds more challenge to anaphora resolution"
1430	J86_2002	"final examination fail the course , then a summary response describing this fact would be inappropriate , and a list of the students ' names is likely what is desired . This wo n't be foolproof , of course . The user could be asking for a re-iteration of something <<< he/she >>> already knows ( for confirmation purposes , perhaps ) or could be asking for another summary pattern besides the one the user already knows . Another subtlety that arises is the distinction between implicit and explicit knowledge -the user may know something but not realize it , or may not"
1431	W13_4043	"constraints for both Engaged and Unengaged participants when they address and shift current topics : 1 . Constraint of addressing : An unengaged participant must not address the other unengaged participants directly . 2 . Constraint of topic shifting : An engaged participant must not shift the current topic when <<< he/she >>> addresses the other unengaged participants . The relationship between subjective and objective participants that are permitted to approach in the two constraints are shown in Tables 1 and 2 . In the following sections , we describe a computational model that has the group maintenance functions discussed above . 3"
1432	L18_1279	"guiding principle followed during the whole annotation process provides that/IN what is understandable by a human should be annotated accordingly : this means that/IN even in the presence of non-canonical tokens or structures , whenever the annotator is able to grasp their meaning with a certain degree of confidence , <<< he/she >>> is expected to encode it properly , according to such interpretation . On the other hand , while this served as a general guideline , more peculiar issues have also been encountered , the treatment of which required specific solving strategies . We grouped such issues into the following categories"
1433	W04_3256	"combine it , and present it in the most concise form to the user . When we look at the different attributes in a person ' s life reported in news articles , a person is described by the job positions that/IN he/she has held , by education institutions that/IN <<< he/she >>> has attended , and etc. Those data are confirmed biographical information and do not bear the necessary contradiction associated with evolving news stories . However , we do feel the need to address and resolve discrepancies if we were to create comprehensive and detailed biographies on people-in-news since miscellaneous personal"
1434	E17_1042	"scaled to much larger and wider domains remains an open question which we hope to pursue in our further work . Wizard-of-Oz data collection websites Figure 4 : The user webpage . The worker who plays a user is given a task to follow . For each mturk HIT , <<< he/she >>> needs to type in an appropriate sentence to carry on the dialogue by looking at both the task description and the dialogue history . Figure 5 : The wizard page . The wizard ' s job is slightly more complex : the worker needs to go through the dialogue history"
1435	L18_1161	"as illustrated in ( 3 ) . ( 3 ) E acrescenta que não existe nenhuma lei que permita à Portugal Telecom cortar o servic ¸o telefónico por os utentes não pagarem , por exemplo , as chamadas de valor acrescentado , tipo telefonemas eróticos , etc. ' And [ <<< he/she >>> ] adds that/IN there is no law that allows Portugal Telecom to cut the phone service when users do n't pay , for instance , value added calls , such as erotic phone calls . ' We keep the same set of attributes in this experiment . Besides a baseline"
1436	2020_emnlp_main_601	"questions . Provide 5 questions you might ask about books that can be answered "" "" Yes "" "" or "" "" No "" "" . ( 7 ) Your friend has arrived from out of town to visit you . Provide 5 questions you might ask your friend when <<< he/she >>> arrives and during your time together . You are only allowed yes/no questions . ( 4 ) Suppose that/IN you are meeting your new neighbour for the first time . You want to find out more about him/her , but you are only allowed to ask yes/no questions . Provide"
1437	W97_1208	"in this paper , and more settings can easily be developed . The questions the subject has to answer can be very simple , aimed directly at the linguistic function in question . There is no need to instruct the subject to listen only to the prosody . ` as <<< he/she >>> will hear nothing else . Results The reliability of the test results does not depend on the listener ' s ability to concentrate solely on the prosody as is the case when evaluating original utterantes ; nonsense sentences or utterances consisting of nonsense words . The results can be based"
1438	L16_1235	"IQ relative to emotional abilities . 22 subjects with a high education level in computer science or robotics were selected ( see Table 1 ) between 18 and 45 years old . They are mainly French , but some are from different cultural origins . The subject is explained that/IN <<< he/she >>> will be left alone in the apartment with the task to solve a reversed rebus , that is they have to find successive objects in each room of the smart home , each object giving points to evaluate their global IQ . He/she is warned that/IN some strange noises ,"
1439	W15_2129	: ( 3 ) a. Tā zǒu-de hěn màn . Descriptive de S/he walk-de very slow . ' S/he walks very slowly . ' b. Wǒmen shuì de hěn hǎo . We sleep de very good ' We sleep very nicely . ' c. Tā chuān de hěn piàoliang . <<< he/she >>> dress de very beautiful ' S/he dresses very beautifully . ' ( 4 ) a. Tā jiāo de lèi le . Resultative de s/he teach de tired le ' S/he taught herself tired . ' b. Wǒ kū de yǎnjing dōu hóng le . I cry de eye all red
1440	N09_1006	"one instance per language for each child . An interesting aspect of the bilingual data is that/IN the children mix languages in their narratives . This phenomenon is called code-switching . At the beginning of a retelling session , the interviewer encourages the child to speak the target language if <<< he/she >>> is not doing so . Once the child begins speaking the correct language , any code-switching thereafter is not corrected by the interviewer . Due to this , the English transcripts contain Spanish utterances and vice versa . We believe that/IN words in the non-target language help contribute to a"
1441	2021_naacl_main_305	". Limitations . While the core idea about the double perturbation framework is general , in §4 , we consider only binary gender in the analysis of counterfactual fairness due to the restriction of the English corpus we used , which only have words associated with binary gender such as <<< he/she >>> , waiter/waitress , etc. A Supplemental Material A.1 Random Baseline To validate the effectiveness of minimizing Eq. ( 4 ) , we also experiment on a second-order baseline that constructs vulnerable examples by randomly replacing up to 6 words . We use the same masked language model and threshold as"
1442	2022_udfestbr_1_6	"buttons labeled AND and OR highlighted in pink in Figure 3 . The logical condition is added below the row that contains the clicked button . To delete a logical AND or logical OR , the user must click on the red button that is on the same row that/IN <<< he/she >>> wants to remove . Like we mentioned before , the logical NOT is represented by a value in the selectors highlighted in black in Figure 3 . This selector has the following two possible values : -""""want "" "" : the row will be evaluated without a logical NOT ;"
1443	Y01_1015	"just sound like a perfectly correct sentence , when it is produced with a professional and fluent intonation . However , it is not the intention of interlocutors in conversation to impress each other in this way . In contrast , the speaker would rather let the addressee know that/IN <<< he/she >>> made a mistake previously and what he/she is now saying is correct . Thus , it is very likely that/IN discourse particles and speech disfluency are highlighted by prosodic means to emphasise the semantic and syntactic inadequacy . This paper mainly deals with means emphasising particular speech sequences and four"
1444	P98_2163	"implys that/IN the two movements by a person must be sequential . This prototype is extended so as to cover such situations as "" "" someone goes to somewhere , and then he/she does something/becomes something/stays there "" "" or "" "" someone does something/become something/stays somewhere , and then <<< he/she >>> goes to elsewhere . "" "" They are expressed by vertical and horizontal extensions of the prototype in Table 2 . The Cause Circum Contrast Circum movements involved in these situations are locational and the other events must be done volitionally by the same person . Another extension covers situations"
1445	Y00_1011	". This airport has three gates from the passport control area to the arrival lobby , the west gate , the east gate and the north gate . Here is a marketing researcher who is surveying behavioral patterns of passengers in this airport . After conducting a satisfactory survey , <<< he/she >>> summarizes his/her findings as the following sentence in the report : P1 simume ©nO 4110•••n P2 West Gate East Gate V 1 P3 Q1 Q2 ( 19 ) Touchaku-bin-no kyaku-no 92%-wa arrival-flight-ANP passenger-ANP 92%-TOP nishi-gate-ka higashi-gate-wo toot-te touchaku-lobby-ni de-te-ki-ta . west-gate-KA east-gate-ACC pass-through arrival-lobby-to come-up-PAST "" "" 92 % of"
1446	W14_3502	"Conclusion This paper focused on a very often overlooked issue in the modern readability literature based on complex machine learning algorithm and trained on texts from educational resources : the coherence of the annotations . Indeed , when one collects a large corpus of texts previously annotated -which means that/IN <<< he/she >>> cannot control the annotation process - , it is very likely that/IN the various experts involved in the educational material creation apply incoherent criteria . This issue was confirmed by the results of van Oosten et al. ( 2011 ) ' s experiment with real judges . Interestingly , when"
1447	E89_1004	"( which will be explained later ) . The remainder part of the conclusion matches almost completely the precondition of Rule 2 . This rule states : If the user wants to achieve a goal state ( G ) and is informed about the way this can be done ( <<< he/she >>> knows the specific RULE R and is capable of performing the relevant action ) , the system is right to assume that/IN the user is lacking some information which inhibits him/her from actually doing it . Therefore , a want of the user indicating the intention to know more about"
1448	1999_mtsummit_1_16	"works in order to identify a topic scope and in this case the effect introduced by the topicalization is very weak so that/IN the main intention can be expressed by the last two phrases . Those phrases express the speaker ' s attitude , and in Japanese speech the information <<< he/she >>> wants to convey to a hearer is presented in the last part of the phrases of the utterance as a main verb or a head noun . The first one meets neither a main predicate , nor an obligatory case role in the utter-ance . The word stream of the"
1449	C08_1033	"needs background knowledge to understand the underlying relation between the entities mentioned in the text in order to understand the text . For instance , in Example 2 the reader is expected to know that/IN a gene encodes a protein ( which usually carries its name ) , so that <<< he/she >>> can capture the anaphoric relation and understand the sentence . This aspect emphasises the need for semantic information as part of the anaphora resolution process . Another aspect affecting the anaphoric relations in biomedical texts are the writing conventions adopted in the biomedical domain to distinguish between the mention of"
1450	C16_1270	"girls are outside "" "" . These entailment cases certainly cannot be solved by word-by-word alignment based methods since "" "" outside "" "" cannot be aligned to any of the words in the premise . Intuitively , when a human is judging the relationship of the two sentences , <<< he/she >>> would first read the premise , and then read the hypothesis while considering whether it can be entailed by the premise . Therefore , we intend to make the model more like human , namely , we require the model be capable of reading and thinking . In this paper"
1451	W17_7511	"According to a work by ( Hidayat , 2012 ) , There are the following major reasons for Code-Mixing : - • 45 % : Real lexical needs : For instance someone is thinking of some object but is not able to recall the word in the language , then <<< he/she >>> will tend to switch to a language where he knows the appropriate word . • 40 % : Talking about a particular topic people : tend to talk about some topics in their mother tongue ( like food ) and generally while discussing science people tend to switch to English"
1452	C92_2110	"must dctine not only a new semantic concept , but al. qo the definitions of slots in the semantic cnncept , the procedures which fill the slots , the relations between the new semantic concept with existing other sentantic coucepts~ various constraiuts anlong concepts , etc. lIowever , relnember that/IN <<< he/she >>> must carry out such eoml)licated tasks to all possible linguistic patterns in his/her target domain , if he/she uses the case-based parsing approach alone . Dialogue Example between PDI and an Application Designer PDI ( Pattern Definition interviewer ) is CAPIT ' s interface to all application designer . A"
1453	2007_mtsummit_papers_55	"translation ( Kim , 2007 ) . Even though the system reports awkward English expression candidates to the user by computing the probability of the translated English word sequence , the user may not know how to modify them into natural expressions . If the user knows English well , <<< he/she >>> can correct the awkward part based on one ' s own linguistic knowledge . But , if not , he/she should depend on a Korean-English dictionary and search example expressions . When the exactly matched example expression is found in the dictionary or in the example corpus , the translation"
1454	W17_7554	"' negative ' event such as a trauma can evoke intense fear and sadness and subsequent sobbing ( Miner et al. , 2016 ; Althoff et al. , 2016 ) . The person suffering from distress actually using a model of world which is very limited and in this world <<< he/she >>> find no appropriate choice from the options available to their model of world ( Bandler and Grinder , 1975 ; Bandler and Grinder , 1979 ; Bandler and An-dreas , 1985 ) . Therefore , there is a requirement of expanding the model of world i. e. improvise the model"
1455	W04_1012	"them in system performance comparison . Van Halteren ( 2002 ) argued that/IN only two manually created extracts could not be used to form a sufficient basis for a good benchmark . To explore this issue , we obtained a ranking order for each human judge based on the extracts <<< he/she >>> generated . The results showed that/IN the ranking orders obtained from 9 different judges are actually similar to each other , with the average Spearman correlation efficient to be 0.901 . From this point of view , if the ranking orders obtained by sentence precision and recall based on the"
1456	C00_1013	"form a Language Server residing in the Internet . All language servers will be connected in the UNL network . They will allow any Internet user to deconvert a UNL document found on the web into his/her native language , as well as to produce UNL representations of the texts <<< he/she >>> wishes to make available to multiethnic public . UNL language We cannot describe the UNL language here in all details : this topic deserves a special paper which will hopefully be written by the author of the language design -Dr . Hiroshi Uchida . We will only characterize it to"
1457	W01_1202	"gives high scores to content words that focus a user ' s intention . For example , when a user inputs the query "" "" Ö × Ø Ù Ú Û Ü Ý Þ ß à á ? ( In what year is Yahoo founded ? ) "" "" , <<< he/she >>> wants to know only the year , rather than the organizer or the URL of Yahoo . So , the QA searching engine gives a higher score to â ã ( year ) than to ä å ( Yahoo ) in contrast to the ordinary IR searching engine . 1"
1458	2021_blackboxnlp_1_25	"overtalk ' label . Any non-overtalk transcript from a single speaker belong to ' non-overtalk ' label . Thus , overtalk detection too is a binary classification task . and you would like me to continue . In the example , the speaker intends to actually ask a question if <<< he/she >>> can continue further . To create question dataset , we follow a similar two step process : i ) candidate generation ; and ii ) manual annotation . For candidate generation , we two approaches : a ) question keyphrases based lookup ; and b ) using speaker replies that"
1459	C94_1074	"detect the linguistic pattern that is not accounted for in the grammar , and verify whether it can be reasonably accounted for , given the intrinsic limitations of the parsing mechanism adopted . If the linguist decides that/IN , indeed , adding a new rule is necessary and feasible , <<< he/she >>> implements the rule and test its effects . Grammar modifications are required to : * Select the esl types of interests ; * Define the heuristic rules ( TEST ON ) , as discussed in Section 2.3 . One positive aspect of SSA is that/IN its complexity is O(k )"
1460	W12_3501	", the title , the start and end time of the appointment and a possibility to set a reminder . The interface can be controlled by mouse and keyboard as well as via speech commands following a structured dialogue . By this , the used is free to chose if <<< he/she >>> wants to use mouse and keyboard as a fast way to enter an appointment or speech if he/she is not close enough to the robot ' s touch display and is either not willing or not capable to reach it . Speech Recognition Creating an automatic speech recognition ( ASR"
1461	W16_6501	"alia , defines CEFR proficiency levels through topics . For example , the CEFR document states that/IN one should be able to "" "" introduce him/herself and others and [ ... ] ask and answer questions about personal details such as where they live , people he/she knows and things <<< he/she >>> has "" "" ( Council of Europe , 2001 , page 24 ) . The verbs göra and heta are encountered very often at the beginner level as beginners learn to introduce themselves ( e. g. Jag heter Peter . ' My name is Peter . ' ) and talk"
1462	L16_1713	"format which is fully compatible with the Ellogon language engineering platform , along with all the formats supported by Ellogon for exporting data . The import of annotations performed from the Ellogon ' s annotation tool is also supported . When the user has created or managed his/her corpora , <<< he/she >>> can switch to the "" "" Annotation "" "" page , in order to annotate documents from the available corpora . Once in the annotation page , the user is asked to select an annotation schema , from the pool of annotation schemas uploaded by the user , or public"
1463	1995_mtsummit_1_27	"are marketed today leaves any potential user in a state of uncertainty . There never seems to be the right MT system for his/her needs and after the first few hours of using the system , any MT system , the only certainty there is , is the feeling that/IN <<< he/she >>> bought the wrong MT system and spent far too much money for it . Looking at NLP products and the way they are marketed today leaves any potential user in a state of uncertainty . There never seems to be the right MT system for his/her needs and after the"
1464	2022_naacl_main_430	", w 2 , ... , w k ) , where w j is an utterance token , we manipulate w j ⊂ P , where P is the set of pronouns , in the following manner : 1 ) We convert gender specific pronouns to object pronouns e. g. <<< he/she >>> to it/they and vice versa . 2 ) We convert singular pronouns it/this/I to the plural ones and vice versa . 3 ) We convert 1st person pronouns like I/we/our to a random 2nd/3rd person pronoun or vice versa . ( See Appendix A for example . ) Named Entities"
1465	2020_evalnlgeval_1_1	"by the same subject and one generated by a different subject . He/she may read the text samples as many times as necessary , before selecting one . This is a forced choice test , so even if a judge does not detect any difference between the three samples , <<< he/she >>> is forced to select one sample . Data Analysis As we will detail below , the analysis of the collected data depends on the type of test that was performed . In both cases , the analysis takes into account the number of correct answers , i. e. , the"
1466	C04_1158	". The system accepts a typed-text input as questions from users and outputs a result of the retrieval . The system interprets input sentences taking a syntactic dependency and synonymous expression into consideration for matching it with the knowledge base . The system can also navigate for the user when <<< he/she >>> makes vague questions based on scenarios ( dialog card ) that were described manually beforehand . Hundreds of the dialog cards have been prepared to ask questions back to the users . If a user question matches its input part , the system generates a question based on its description"
1467	P08_1071	"  looks "" "" good , this question further asks whether the judges would like to partner with the particular student . Survey Website We display one tutor-student utterance pair and the three utterance level questions on each web page . After the judges answer the three questions , <<< he/she >>> will be led to the next page which displays the next pair of tutor-student utterances in the dialog with the same three utterance level questions . The judge reads through the dialog in this manner and answers all utterance level questions . At the end of the dialog , three"
1468	L18_1359	"the annotation buttons when they found good relevant scenes based on the six evaluation points . In Step 3 , each student imported the annotation data , which was exported from an FWM server , and the video data to FW and then reflected on the annotated scenes in which <<< he/she >>> or members of his/her group presented . The teacher distributed the annotation data to students and the video 3 https : //www . nict . go . jp/JST/JST5 . html data on USB flash drives . The total data size was about 1.4GB . Results All the practices were completed"
1469	W19_8714	". Lexi Scanning Prior to being able to access alternate renditions of a given technical term , the translator is confronted by the related and practical problem of encountering words which are altogether out of his/her vocabulary . Thus , a platform through which a translator may submit a text <<< he/she >>> has to work on and which could provide indications of all the embedded terms in the database through highlighting would be very much welcome . Such a provision is made by PatentLex with 1 million entries of preloaded bilingual MWE ' s ( Tian et al. , 2014 ; Tsou"
1470	L16_1332	"been done by staff members of the center of Valladolid , with the aim of getting more user ' s recordings to be analyzed later . During game sessions , the role of the trainer ( a teacher or speech therapist ) is twofold : on the one hand , <<< he/she >>> evaluates the player ' s recordings and on the other hand , he/she helps players if necessary . The trainer has to sit next to the player . To evaluate the player ' s recordings , the trainer uses the keyboard of the same computer that/IN the player is using"
1471	Y13_1054	"i. e. those morphs which can be analyzed into more than one morpheme ( Crystal 1980 , Spencer 1991 ) . 8 The a ) cip-ey ka-nunkwuna/nunkwun . house-to go-Ending ' ( He/She ) does go home ! ' b ) cal mek-nunkwuna/nunkwun . well eat-Ending ' How well ( <<< he/she >>> ) eats ! ' c ) san-i khu/cak-kwuna/kwun . mountain-Nom be big/small-Ending ' How big/small the mountain is ! ' Compared with the endings after adjectives ( or descriptive verbs ) in ( c ) , those after verbs have the extra element -nun-in ( a-b ) . However ,"
1472	C12_1130	"-g(R-aN ) ( for adverbial phrase gaps ) , and -gS ( for e. g. topicalized sentential gaps ) , which follow the category label for each constituent . Similar transformations localize it-clefts ( it seems that ... ) , tough constructions ( tough to cut ) , parentheticals ( <<< he/she >>> said ) , and certain types of inversion ( ' it rained , ' she said ) , also using the gap operator -g . This is similar to the treatment of filler-gap constructions used in HPSG ( Pollard and Sag , 1994 ) . Then , specifiers of head"
1473	2020_lrec_1_87	listening to the speaker ' s utterance greeting acknowledgement of the speaker ' s presence and willingness to favorably interact with the speaker provoke memory listener ' s reaction that/IN his/her memory is provoked by the content of the speaker ' s utterance start thinking listener ' s reaction that/IN <<< he/she >>> is starting to think about the content of the speaker ' s utterance thinking process listener ' s status that/IN he/she is thinking about the content of the speaker ' s utterance Table 1 : Types of attentive listening responses and their roles attentive listening responses . The degree of
1474	W18_6540	"had perceived . One of their comments was that/IN they felt more confident looking for the target character if they knew at the beginning where to start looking for it . This confirms that/IN having the algorithm detail the distance of the observer to the target character and specifying if <<< he/she >>> was in the field of view of the observer has provided better indications for the users to find the described person . The change of the description in real time has helped the observers in a more realistic way , mimicking how a real person would be providing the description"
1475	2020_emnlp_main_56	"adoption should be empowered with de-biased legal content pretraining , which could avoid potential demographic bias . For instance , in order to remove gender/race bias , system could use ( Bolukbasi et al. , 2016 ) algorithm to debias the sensitive gender/race information , e. g. , replace ' <<< he/she >>> ' and ' asian/hispanic ' with gender/race neutral words for pretraining , which can be vital for legal domain . Conclusion and Future Work In this paper , we propose a novel Attentional and Counterfactual based Natural Language Genera-tion ( AC-NLG ) method to solve the task of court '"
1476	E93_1037	"one _position to the left ; we might call it empathy shifting/ Now consider the discourse : ( 17 ) 01&lt;/&gt; 02&lt;i&gt; hon -wo yatta -node , book acc favored because 01&lt;k&gt; 02&lt;a&gt; orei -wo iwareta . gratitude ace say cop ' Because he/she gave a book to him/her , <<< he/she >>> was thanked for it . ' ( 18 ) a empathy(01&lt;i&gt; , 02&lt;j&gt; , _ ) b empathy(01&lt;k&gt; , 02&lt;9 &gt; , _ ) 18(1 ) corresponds to the empathy hierarchy for the first clause in 17 ; 18(b ) corresponds to the hierarchy for the second clause . Unifying"
1477	W13_3714	"relevant cases of ellipsis . A second argument for a direct syntactic link between the VM and the root auxiliary comes from prosodic structure . As noted above , VMs immediately preceding their base verbs form a single phonological word with them ; for example , ' elutazik ' [ <<< he/she >>> ] travels away ' has a single stress assigned to the first syllable . Importantly , a similar situation holds when the VM is followed by an auxiliary . For example , in ' el fog ' utazni ' [ he/she ] will travel away ' , el and the"
1478	W19_8102	"person starts to tell stories from images , he/she may not understand the implications in those images and fail to write a proper story . However , if he/she had heard others telling stories , he/she may be able to tell a story from the stories of similar image sequences <<< he/she >>> previously heard . Motivated by such process , we propose to utilize the large corpus as an inventory and improve the visual storytelling model by including stories from similar image sequences in corpus as input to strengthen the encoder design . On building such models , two major problems need"
1479	U13_1005	"focused on the filler /e : / and the /e : / segment of the filler /e : to : / . Fillers are a sound or a word ( e. g. um , you know , like in English ) which is uttered by a speaker to signal that <<< he/she >>> is thinking or hesitating . We decided to use these fillers because 1 ) they are two of the most frequently used fillers ( thus many monologues contain at least ten of these fillers ) ( Ishihara 2010 ) , 2 ) the vowel /e/ reportedly has the strongest speaker-discriminatory"
1480	2020_wildre_1_9	". This is followed by determination of Active/Passive voice of the sentence using Dependencies of the sentence provided by Stanford Core NLP package ( Toutanova et al. , 2003 ) . After this , using the POS tags of the sentence generated before , a personal pronoun ( such as <<< he/she >>> ) is searched in the sentence . If a personal pronoun is found , we further search for a subject pronoun ( such as who ) in the same sentence . We also check the position of the personal pronoun in the sentence . After observation of different pronouns in"
1481	W11_0405	"eo-jeol is rising or falling . In order to reduce inconsistency derived from missing breaks , transcribers repeatedly practice while listening to similar patterns . ( 3 ) If only one annotator selects a different type of prosodic break than the others for the answer of the same place , <<< he/she >>> must change his approach in annotating prosodic breaks . ( 4 ) Wightman and Ostendorf ( 1994 ) and Ross and Ostendorf ( 1996 ) have revealed that/IN there is prosodic variability even for news speech data . The announcer showed variability in the location , strength or length ,"
1482	2020_vardial_1_9	"immigrated from Mush at the beginning of the 19 th century and the dialect originates from Western kə branch Mush dialect . However , being in contact with -um branch varieties for almost two centuries certain contact-induced changes are present . 16 E. g. հըվընդա1ցա1վ həvəndäc h äv ' [ <<< he/she >>> ] fell ill ' ( vs. the MEA wordform հիվանդացավ hivandac h av ) . 17 The orthography conversion was processed by the converter designed by Arak29 foundation available at 96 Methodology and results A number of tests were carried out to develop an RNN annotation model for three dialects"
1483	W09_3929	"the instructions and take your time to plan the directions you want to give to your partner . Phase 2 : Directing the follower In this phase your partner will be placed into the world in the start position . Your monitor will show his/her view of the world as <<< he/she >>> moves around . He/she has no knowledge of the tasks , and has not received a map . You have to direct him/her through speech in order to complete the tasks . The objective is to complete all 5 tasks , but the order does not matter . The tasks"
1484	W12_1815	"navigation assistant is trying to direct a driver to his destination , it should probably not give directions within the driver ' s own neighborhood , with which he is already familiar . However , it should inform the driver if there is road construction in the area of which <<< he/she >>> is unaware . Alternatively , if the driver is having an important conversation and the cost of the detour is outweighed by the cost of interrupting the conversation , perhaps the system should remain quiet . Understanding all the contexts that affect interaction is difficult and defining a set of"
1485	Y13_1035	"express from speaker ' s angle . The speakers tend to use more positive tweets to convey sarcasm , but more natural tweets to convey irony . Second , based on the underlying mechanism of sarcasm and irony , there is a divergence between what the speaker said and what <<< he/she >>> intended to mean , thus the positive words used in tweets seems to represent the aggressive intention . It has shown that/IN sarcasm is more aggressive than irony from speakers ' natural language performance . This result corresponds to the study on hearers ' comprehension conducted by Lee and Katz"
1486	2021_emnlp_main_179	"knowledge enhanced fine-tuning method , trying to understand semantic information of entities based on the context . For example , given the sentence "" "" I want to submit a paper to EMNLP "" "" , a person may not know what "" "" EMNLP "" "" is , but <<< he/she >>> can guess that/IN it should be a conference or a journal , based on the context . Similarly , we aim to enhance the semantic representation of unseen entities by guiding the model to learn the meaning of the words only based on the context information . To achieve this"
1487	A92_1008	". In our approach , we concentrate on the requirements for localising objects ill pictures . We assume that/IN the user can see the picture containing the objects to be localised and we do not deal with the problem of anticipating possibly wrong visualisations of the user in the case <<< he/she >>> cannot see the picture . We do not deal with possible intrinsic orientations of depicted objects ( c. f. [ Retz-Schlnidt , 1988 ] ) and assume the deictic reference frame of a common viewer ( c. f. figure 5 ) . Together with every localisation , we compute a"
1488	N10_2011	"of Portuguese . Section 4 presents final remarks with emphasis on why demonstrating this system is relevant . SIMPLIFICA authoring tool SIMLIFICA is a web-based WYSIWYG editor , based on TinyMCE web editor 3 . The user inputs a text in the editor and customizes the simplification settings , where <<< he/she >>> can choose : ( i ) strong simplification , where all the complex syntactic phenomena ( see details in Section 2.2 ) are treated for each sentence , or customized simplification , where the user chooses one or more syntactic simplification phenomena to be treated for each sentence , and"